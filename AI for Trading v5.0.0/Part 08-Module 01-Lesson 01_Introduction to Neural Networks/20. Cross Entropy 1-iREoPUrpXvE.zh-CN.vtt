WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.250
对 答案是对数

00:00:02.250 --> 00:00:06.389
因为对数具有良好的特性

00:00:06.389 --> 00:00:11.929
即 log(ab) 等于 log(a) 和 log(b) 的总和

00:00:11.929 --> 00:00:13.294
这就是我们要做的

00:00:13.294 --> 00:00:17.559
我们得到乘积 使用对数

00:00:17.559 --> 00:00:21.854
现在得到因子对数的总和

00:00:21.855 --> 00:00:28.219
所以 ln(0.6*0.2*0.1*0.7) 等于

00:00:28.219 --> 00:00:35.700
ln(0.6) 加 ln(0.2)  加 ln(0.1) 加 ln(0.7) 从现在开始到这节课结束

00:00:35.700 --> 00:00:40.040
我们都要使用底数为 e 的对数 （自然对数） 而不是底数为 10 的对数

00:00:40.039 --> 00:00:41.759
底数为 10 的对数并没有太大区别

00:00:41.759 --> 00:00:44.945
所有原理都是相同的 它只是自然对数的结果乘上一个因子

00:00:44.945 --> 00:00:46.770
这样做只是一种惯例

00:00:46.770 --> 00:00:51.330
我们计算这些值得到 -0.51 -1.61

00:00:51.329 --> 00:00:58.164
-0.23 等 注意这些都是负数 这也是符合实际的

00:00:58.164 --> 00:01:01.560
这是因为 0 到 1 之间数字的对数都是负值

00:01:01.560 --> 00:01:05.594
因为对 1 取对数才能得到 0

00:01:05.594 --> 00:01:07.789
所以 概率的对数都是负值 对它取相反数是行得通的

00:01:07.790 --> 00:01:11.260
这样会得到正数

00:01:11.260 --> 00:01:15.740
这就是我们要做的 我们得到的概率的对数为负值

00:01:15.739 --> 00:01:18.905
对它们的相反数进行求和

00:01:18.905 --> 00:01:23.180
我们称之为交叉熵 这也是这节课中非常重要的概念

00:01:23.180 --> 00:01:25.385
如果我们计算交叉熵

00:01:25.385 --> 00:01:30.255
我们看到左侧错误的模型的交叉熵是 4.8 这非常高

00:01:30.254 --> 00:01:35.229
右侧的更优的模型交叉熵较低 是 1.2

00:01:35.230 --> 00:01:37.454
实际上这是一个规律

00:01:37.454 --> 00:01:38.810
准确的模型可以让我们得到较低的交叉熵

00:01:38.810 --> 00:01:43.185
而误差较大的模型得到的交叉熵较高

00:01:43.185 --> 00:01:44.629
这纯粹因为

00:01:44.629 --> 00:01:47.390
好模型可以给我们较高的概率

00:01:47.390 --> 00:01:52.599
它的对数取相反数后是个较小的数字 反之亦然

00:01:52.599 --> 00:01:55.250
这种方法比我们想象的还要强大

00:01:55.250 --> 00:01:59.180
如果我们计算出概率 并且得到每个点所对应的对值

00:01:59.180 --> 00:02:01.470
我们实际上得到了每个点的误差

00:02:01.469 --> 00:02:06.539
那么这里我们有两个模型的概率和概率的乘积

00:02:06.540 --> 00:02:09.944
现在我们对每个对数取相反数并求和

00:02:09.944 --> 00:02:15.319
如果我们把每个对值放到对应的点上

00:02:15.319 --> 00:02:17.859
我们可以得到每个点的值

00:02:17.860 --> 00:02:19.565
我们计算了这些值

00:02:19.564 --> 00:02:22.185
就得到了这些东西 来看一下

00:02:22.185 --> 00:02:24.319
如果我们仔细观察值

00:02:24.319 --> 00:02:26.430
可以发现这些分类错误的点的值较大

00:02:26.430 --> 00:02:31.295
如这个点是 2.3 另一个点是 1.6

00:02:31.294 --> 00:02:36.544
然而正确分类的点对应值都较小

00:02:36.544 --> 00:02:38.719
这个原因还是在于

00:02:38.719 --> 00:02:42.604
分类正确点的概率更接近于 1

00:02:42.604 --> 00:02:44.989
如果对这个概率的对数取相反数

00:02:44.990 --> 00:02:46.915
就会得到较小的值

00:02:46.914 --> 00:02:51.215
因此我们可以把这些对数的相反数作为每个点的误差

00:02:51.215 --> 00:02:53.539
分类正确点的误差较小

00:02:53.539 --> 00:02:57.594
而分类错误点的误差较大

00:02:57.594 --> 00:03:02.530
现在我们得到结论 交叉熵可以告诉我们模型的好坏

00:03:02.530 --> 00:03:06.800
所以现在我们的目标从最大化概率转变为最小化交叉熵 

00:03:06.800 --> 00:03:12.580
从而使左侧模型转变为右侧模型

00:03:12.580 --> 00:03:14.655
我们所寻找的误差函数

00:03:14.655 --> 00:03:17.000
就是这个交叉熵

