WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:02.520
So, our goal is to train our neural network.

00:00:02.520 --> 00:00:03.715
In order to do this,

00:00:03.715 --> 00:00:05.950
we have to define the error function.

00:00:05.950 --> 00:00:10.375
So, let's look again at what the error function was for perceptrons.

00:00:10.375 --> 00:00:12.135
So, here's our perceptron.

00:00:12.135 --> 00:00:15.000
In the left, we have our input vector with

00:00:15.000 --> 00:00:18.900
entries x_1 up to x_n, and one for the bias unit.

00:00:18.900 --> 00:00:23.945
And the edges with weights W_1 up to W_n,

00:00:23.945 --> 00:00:26.360
and b for the bias unit.

00:00:26.360 --> 00:00:30.275
Finally, we can see that this perceptor uses a sigmoid function.

00:00:30.275 --> 00:00:37.008
And the prediction is defined as y-hat equals sigmoid of Wx plus b.

00:00:37.008 --> 00:00:39.750
And as we saw, this function gives us a measure of

00:00:39.750 --> 00:00:44.175
the error of how badly each point is being classified.

00:00:44.175 --> 00:00:48.565
Roughly, this is a very small number if the point is correctly classified,

00:00:48.565 --> 00:00:50.640
and a measure of how far the point is from

00:00:50.640 --> 00:00:53.415
the line and the point is incorrectly classified.

00:00:53.415 --> 00:00:57.840
So, what are we going to do to define the error function in a multilayer perceptron?

00:00:57.840 --> 00:01:00.000
Well, as we saw, our prediction is simply

00:01:00.000 --> 00:01:03.740
a combination of matrix multiplications and sigmoid functions.

00:01:03.740 --> 00:01:07.370
But the error function can be the exact same thing, right?

00:01:07.370 --> 00:01:08.817
It can be the exact same formula,

00:01:08.817 --> 00:01:12.000
except now, y-hat is just a bit more complicated.

00:01:12.000 --> 00:01:17.490
And still, this function will tell us how badly a point gets misclassified.

00:01:17.490 --> 00:01:20.000
Except now, it's looking at a more complicated boundary.

