WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.632
现在我们最好快速来复习下这几课

00:00:03.632 --> 00:00:05.640
我们这里有两个模型

00:00:05.639 --> 00:00:08.934
较差的模型位于左侧 较好的模型位于右侧

00:00:08.935 --> 00:00:13.440
对于每个模型 我们计算出了交叉熵

00:00:13.439 --> 00:00:19.259
即这些点颜色概率的负对数总和

00:00:19.260 --> 00:00:22.170
而且我们总结得出 右侧模型更好一些

00:00:22.170 --> 00:00:25.860
因为交叉熵更小

00:00:25.859 --> 00:00:29.269
那么我们实际上可以计算误差函数的公式

00:00:29.269 --> 00:00:31.559
我们来分成两种情况

00:00:31.559 --> 00:00:34.269
第一种情况是 y=1 时

00:00:34.270 --> 00:00:36.130
即这个点最初是蓝色的

00:00:36.130 --> 00:00:42.480
这个模型告诉我们 蓝色的概率是预测值 y-hat

00:00:42.479 --> 00:00:47.849
这两个点的概率分别是 0.6 和 0.2

00:00:47.850 --> 00:00:50.910
正如我们看到的 点位于蓝色的区域

00:00:50.909 --> 00:00:55.000
为蓝色的可能性 比位于红色区域的可能性更大

00:00:55.000 --> 00:01:00.500
而且我们的误差等于这个概率的负对数

00:01:00.500 --> 00:01:04.010
即 -ln(y-hat)

00:01:04.010 --> 00:01:09.665
用数字来表示的话 等于 -ln(0.6) 和 -ln(0.2)

00:01:09.665 --> 00:01:13.745
现在如果 y=0 那么点为红色时

00:01:13.745 --> 00:01:17.585
我们需要计算点为红色的概率

00:01:17.584 --> 00:01:22.339
点为红色的概率等于 1 减去点为蓝色的概率

00:01:22.340 --> 00:01:27.750
而点为蓝色的概率等于 1 减去预测 y-hat

00:01:27.750 --> 00:01:30.890
所以误差等于这个概率的负对数

00:01:30.890 --> 00:01:35.870
即 -ln(1- y-hat)

00:01:35.870 --> 00:01:42.040
在这个例子中我们得到 -ln(0.1) 和 -ln(0.7)

00:01:42.040 --> 00:01:46.605
所以我们得出结论 如果点为蓝色 误差等于 -ln(y-hat)

00:01:46.605 --> 00:01:50.635
并且 -ln(1-y-hat) 表示点为红色

00:01:50.635 --> 00:01:53.625
我们可以把这两个公式总结成一个

00:01:53.625 --> 00:02:02.159
Error = - (1-y)(ln(1-y-hat)) - y ln(y-hat)

00:02:02.159 --> 00:02:03.759
为什么这个公式有效呢？

00:02:03.760 --> 00:02:05.730
因为如果点为蓝色

00:02:05.730 --> 00:02:10.664
那么 y=1 即 1-y=0 这可以使第一项等于 0

00:02:10.664 --> 00:02:16.495
第二项是 y-hat 的对数

00:02:16.495 --> 00:02:20.219
同样点为红色 那么 y=0

00:02:20.219 --> 00:02:27.680
所以公式的第二项是 0 第一项是 y-hat 的对数

00:02:27.680 --> 00:02:31.145
现在误差函数的公式是所有点的

00:02:31.145 --> 00:02:35.510
误差函数总和 就是这里的求和

00:02:35.509 --> 00:02:38.564
这里我们得到 4.8

00:02:38.564 --> 00:02:41.469
按照惯例 我们实际上要考虑平均值

00:02:41.469 --> 00:02:45.330
而不是总和 所以这里要除以 n

00:02:45.330 --> 00:02:49.050
然后把 4.8 转变为 1.2

00:02:49.050 --> 00:02:53.330
从现在开始 我们使用这个公式作为误差函数

00:02:53.330 --> 00:02:58.860
既然通过 sigmoid 线性函数 wx + b 得到了 y-hat

00:02:58.860 --> 00:03:01.890
那么整个误差公式实际上

00:03:01.889 --> 00:03:05.094
是 w 和 b 作为模型的权重

00:03:05.094 --> 00:03:08.219
而且它是我们这里看到的求和

00:03:08.219 --> 00:03:14.449
在这个例子中 y_i 是点 xi (i 为上标) 的标签

00:03:14.449 --> 00:03:17.364
所以我们计算出它后 要对它进行最小化

00:03:17.365 --> 00:03:18.975
这是我们接下来要做的

00:03:18.974 --> 00:03:20.293
还有个小提示

00:03:20.294 --> 00:03:23.210
我们所做的是二元分类问题

00:03:23.210 --> 00:03:25.670
如果我们有多元分类问题

00:03:25.669 --> 00:03:28.490
那么通过多元分类交叉熵得到误差

00:03:28.491 --> 00:03:33.380
这里给出了一个公式 其中对于每个数据点 我们把

00:03:33.379 --> 00:03:39.139
标签乘以预测的对数 然后我们对所有值求出平均值

00:03:39.139 --> 00:03:41.539
对于只有两类的情况时 说服你自己两者是相同的

00:03:41.539 --> 00:03:45.000
这是很有意思的练习

