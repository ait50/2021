WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.464
Now I'm going to show you how to create these nonlinear models.

00:00:03.464 --> 00:00:06.058
What we're going to do is a very simple trick.

00:00:06.059 --> 00:00:12.060
We're going to combine two linear models into a nonlinear model as follows.

00:00:12.060 --> 00:00:13.769
Visually it looks like this.

00:00:13.769 --> 00:00:17.518
The two models over imposed creating the model on the right.

00:00:17.518 --> 00:00:20.084
It's almost like we're doing arithmetic on models.

00:00:20.085 --> 00:00:24.160
It's like saying "This line plus this line equals that curve."

00:00:24.160 --> 00:00:26.824
Let me show you how to do this mathematically.

00:00:26.824 --> 00:00:30.750
So a linear model as we know is a whole probability space.

00:00:30.750 --> 00:00:36.478
This means that for every point it gives us the probability of the point being blue.

00:00:36.478 --> 00:00:39.179
So, for example, this point over here is in

00:00:39.179 --> 00:00:43.890
the blue region so its probability of being blue is 0.7.

00:00:43.890 --> 00:00:47.250
The same point given by the second probability space is

00:00:47.250 --> 00:00:52.170
also in the blue region so it's probability of being blue is 0.8.

00:00:52.170 --> 00:00:53.353
Now the question is,

00:00:53.353 --> 00:00:55.890
how do we combine these two?

00:00:55.890 --> 00:01:00.225
Well, the simplest way to combine two numbers is to add them, right?

00:01:00.225 --> 00:01:05.409
So 0.8 plus 0.7 is 1.5.

00:01:05.409 --> 00:01:09.890
But now, this doesn't look like a probability anymore since it's bigger than one.

00:01:09.890 --> 00:01:15.915
And probabilities need to be between 0 and 1. So what can we do?

00:01:15.915 --> 00:01:20.980
How do we turn this number that is larger than 1 into something between 0 and 1?

00:01:20.980 --> 00:01:24.079
Well, we've been in this situation before and we have a pretty good tool that

00:01:24.078 --> 00:01:27.744
turns every number into something between 0 and 1.

00:01:27.745 --> 00:01:30.234
That's just a sigmoid function.

00:01:30.233 --> 00:01:32.780
So that's what we're going to do.

00:01:32.780 --> 00:01:36.858
We applied the sigmoid function to 1.5 to get the value

00:01:36.858 --> 00:01:40.188
0.82 and that's the probability of

00:01:40.188 --> 00:01:44.568
this point being blue in the resulting probability space.

00:01:44.569 --> 00:01:47.299
So now we've managed to create a probability function for

00:01:47.299 --> 00:01:51.243
every single point in the plane and that's how we combined two models.

00:01:51.243 --> 00:01:54.093
We calculate the probability for one of them,

00:01:54.093 --> 00:01:56.140
the probability for the other,

00:01:56.140 --> 00:01:59.334
then add them and then we apply the sigmoid function.

00:01:59.334 --> 00:02:01.340
Now, what if we wanted to weight this sum?

00:02:01.340 --> 00:02:04.370
What, if say, we wanted the model in the top to have

00:02:04.370 --> 00:02:07.849
more of a saying the resulting probability than the second?

00:02:07.849 --> 00:02:11.569
So something like this where the resulting model looks a lot more like the one in

00:02:11.568 --> 00:02:15.698
the top then like the one in the bottom. Well, we can add weights.

00:02:15.699 --> 00:02:22.355
For example, we can say "I want seven times the first model plus the second one."

00:02:22.354 --> 00:02:24.240
Actually, I can add the weights since I want.

00:02:24.241 --> 00:02:29.574
For example, I can say "Seven times the first one plus five times the second one."

00:02:29.574 --> 00:02:34.335
And when I do get the combine the model is I take the first probability,

00:02:34.335 --> 00:02:36.789
multiply it by seven,

00:02:36.788 --> 00:02:43.293
then take the second one and multiply it by five and I can even add a bias if I want.

00:02:43.294 --> 00:02:45.526
Say, the bias is minus 6,

00:02:45.526 --> 00:02:48.020
then we add it to the whole equation.

00:02:48.020 --> 00:02:52.735
So we'll have seven times this plus five times this minus six,

00:02:52.735 --> 00:02:54.914
which gives us 2.9.

00:02:54.913 --> 00:03:00.679
We then apply the sigmoid function and that gives us 0.95.

00:03:00.680 --> 00:03:02.680
So it's almost like we had before, isn't it?

00:03:02.680 --> 00:03:06.085
Before we had a line that is a linear combination

00:03:06.085 --> 00:03:10.240
of the input values times the weight plus a bias.

00:03:10.240 --> 00:03:13.300
Now we have that this model is a linear combination of

00:03:13.300 --> 00:03:17.650
the two previous model times the weights plus some bias.

00:03:17.650 --> 00:03:18.905
So it's almost the same thing.

00:03:18.905 --> 00:03:21.599
It's almost like this curved model in the right.

00:03:21.599 --> 00:03:25.818
It's a linear combination of the two linear models before

00:03:25.818 --> 00:03:30.573
or we can even think of it as the line between the two models.

00:03:30.574 --> 00:03:32.069
This is no coincidence.

00:03:32.068 --> 00:03:35.435
This is at the heart of how neural networks get built.

00:03:35.435 --> 00:03:38.628
Of course, we can imagine that we can keep doing this always obtaining

00:03:38.628 --> 00:03:43.228
more new complex models out of linear combinations of the existing ones.

00:03:43.229 --> 00:03:47.000
And this is what we're going to do to build our neural networks.

