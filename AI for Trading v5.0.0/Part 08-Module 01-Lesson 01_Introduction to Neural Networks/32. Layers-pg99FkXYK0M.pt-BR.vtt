WEBVTT
Kind: captions
Language: pt-BR

00:00:00.267 --> 00:00:03.067
Redes neurais possuem
arquitetura especial

00:00:03.101 --> 00:00:04.367
com camadas.

00:00:04.401 --> 00:00:07.167
A primeira é chamada
de camada de entrada,

00:00:07.201 --> 00:00:12.534
que contém as entradas,
neste caso, X1 e X2.

00:00:12.568 --> 00:00:14.400
A próxima é chamada
de camada oculta,

00:00:14.434 --> 00:00:16.267
que é um conjunto
de modelos lineares

00:00:16.301 --> 00:00:19.033
criados com esta
primeira entrada.

00:00:19.067 --> 00:00:21.968
As últimas camadas
são as de saída,

00:00:22.002 --> 00:00:24.200
nas quais os modelos lineares
se combinam

00:00:24.234 --> 00:00:26.267
para obter
um modelo não linear.

00:00:26.968 --> 00:00:29.234
Você pode ter
diferentes arquiteturas.

00:00:29.268 --> 00:00:31.634
Esta é uma com uma camada
oculta maior.

00:00:31.668 --> 00:00:33.567
Nós combinamos três
modelos lineares

00:00:33.601 --> 00:00:36.501
para obter o limite triangular
da camada de saída.

00:00:36.535 --> 00:00:39.567
O que ocorre se a camada
de entrada tiver mais nós?

00:00:39.601 --> 00:00:43.467
Esta rede neural possui
três nós na camada de entrada.

00:00:43.501 --> 00:00:46.667
Nós não estaremos mais
no espaço bidimensional,

00:00:46.701 --> 00:00:48.567
mas no espaço
tridimensional,

00:00:48.601 --> 00:00:51.634
e a camada oculta,
com modelos lineares,

00:00:51.668 --> 00:00:54.968
nos dá um monte
de planos em 3D,

00:00:55.002 --> 00:00:59.767
e a camada de saída ressalta
uma região não linear em 3D.

00:00:59.801 --> 00:01:03.000
Em geral, se tivermos N nós
na camada de entrada,

00:01:03.034 --> 00:01:06.734
os dados estarão
no espaço N dimensional.

00:01:06.768 --> 00:01:09.100
E se a camada de saída
tiver mais nós?

00:01:09.134 --> 00:01:10.801
Nós teremos mais resultados.

00:01:10.835 --> 00:01:14.234
Neste caso, teremos um modelo
de classificação multiclasse.

00:01:14.268 --> 00:01:17.367
Se o modelo informa que a imagem
é um gato, um cachorro

00:01:17.401 --> 00:01:20.901
um pássaro, cada nó
na camada de entrada

00:01:20.935 --> 00:01:23.934
terá uma pontuação
para cada uma das classes:

00:01:23.968 --> 00:01:26.367
uma para o gato,
uma para o cachorro

00:01:26.401 --> 00:01:27.868
e uma para o pássaro.

00:01:27.902 --> 00:01:31.067
Por fim, e é aqui
que as coisas ficam legais,

00:01:31.101 --> 00:01:32.968
e se tivermos mais camadas?

00:01:33.002 --> 00:01:35.734
Nós teremos uma rede
neural profunda.

00:01:35.768 --> 00:01:38.767
Os modelos lineares
se combinam

00:01:38.801 --> 00:01:40.834
para criar
modelos não lineares,

00:01:40.868 --> 00:01:45.501
que se combinam para criar
modelos ainda mais não lineares.

00:01:45.535 --> 00:01:47.634
Nós podemos fazer isso
muitas vezes

00:01:47.668 --> 00:01:51.100
para obter modelos complexos
com várias camadas ocultas.

00:01:51.134 --> 00:01:54.267
É aqui que a magia das redes
neurais acontece.

00:01:54.301 --> 00:01:56.334
Muitos modelos da vida real,

00:01:56.368 --> 00:01:57.634
de carros autônomos,

00:01:57.668 --> 00:01:59.100
para agentes jogadores,

00:01:59.134 --> 00:02:01.200
possuem muitas
camadas ocultas.

00:02:01.234 --> 00:02:04.167
A rede neural dividirá
o espaço N dimensional

00:02:04.201 --> 00:02:09.011
com o limite não linear,
talvez como o da direita.

