WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.580
现在我们终于得到了工具

00:00:02.580 --> 00:00:05.120
可以为梯度下降算法写伪代码了

00:00:05.120 --> 00:00:06.830
具体如下

00:00:06.830 --> 00:00:15.170
第一步是 随机权重 w1 到 wn 和 b 可以得到一条线段

00:00:15.170 --> 00:00:19.270
其实不只是线段 而是通过 wx+b 得到整个概率函数

00:00:19.270 --> 00:00:22.820
现在对每个点 我们计算误差

00:00:22.820 --> 00:00:25.150
正如我们所见 误分类的点误差很高

00:00:25.150 --> 00:00:29.230
正确分类的点误差很低

00:00:29.230 --> 00:00:32.545
现在对于坐标为 x1 到 xn 的每个点

00:00:32.545 --> 00:00:36.845
我们通过添加学习速率 α

00:00:36.845 --> 00:00:42.950
乘以 wi 误差函数的偏导数 更新 wi

00:00:42.950 --> 00:00:45.120
我们也添加 α 乘以 b 误差函数的偏导数

00:00:45.120 --> 00:00:48.440
乘以 b 误差函数的偏导数 更新 b

00:00:48.440 --> 00:00:49.920
这样我们得到新的权重

00:00:49.920 --> 00:00:52.610
wi’ 和新的偏差 b’

00:00:52.610 --> 00:00:55.330
我们已经计算了这些偏导数

00:00:55.330 --> 00:00:58.605
知道它们是 y-hat - y 乘以 xi

00:00:58.605 --> 00:01:01.295
对于 wi 导数的

00:01:01.295 --> 00:01:05.215
对于 b 的 y-hat - y

00:01:05.215 --> 00:01:08.840
这就是我们更新权重的方法

00:01:08.840 --> 00:01:13.350
现在重复这个过程 直到误差非常小

00:01:13.350 --> 00:01:15.765
或是我们重复固定数量的次数

00:01:15.765 --> 00:01:18.840
这个次数的数量叫做 epoch 我们随后会学习它们

00:01:18.840 --> 00:01:20.100
现在这看起来很眼熟

00:01:20.100 --> 00:01:21.935
我们之前是不是见过这些呢？

00:01:21.935 --> 00:01:24.300
我们观察这些点 每个点要做的是

00:01:24.300 --> 00:01:26.640
如果某个点被误分类 把几倍的自己加到这条线段的权重

00:01:26.640 --> 00:01:31.640
为了使这条线更加靠近

00:01:31.640 --> 00:01:34.435
这就是感知器算法的具体内容

00:01:34.435 --> 00:01:36.000
所以在下一个视频中我们要观察

00:01:36.000 --> 00:01:39.000
相似性 因为它们的相似程度值得怀疑

