WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.820
下面说说我是如何新建 train_words 列表的

00:00:04.820 --> 00:00:09.750
首先 我计算了词汇表中每个字词的出现频率

00:00:09.750 --> 00:00:13.970
将文本的总长度存储在变量 total_count 中

00:00:13.970 --> 00:00:16.590
然后创建一个频率字典

00:00:16.590 --> 00:00:20.675
对于字词计数器字典里的每个字词标记和数量

00:00:20.675 --> 00:00:22.939
我都向该字典里添加一个条目

00:00:22.939 --> 00:00:26.610
其中键 (key) 是字词 值 (value) 是该字词的频率

00:00:26.610 --> 00:00:30.500
频率为该字词的数量除以文本的总字数

00:00:30.500 --> 00:00:33.850
然后计算丢弃概率并放入变量 p_drop 中

00:00:33.850 --> 00:00:37.615
这是另一个字典 它将字词映射到丢弃概率

00:00:37.615 --> 00:00:40.705
我使用二次抽样公式算出丢弃概率

00:00:40.705 --> 00:00:45.120
即 1 减去阈值除以字词频率的平方根

00:00:45.120 --> 00:00:48.045
最终新建了 train_words 列表

00:00:48.045 --> 00:00:50.415
对于 int_words 列表中的每个字词

00:00:50.415 --> 00:00:53.420
将以某个概率保留该字词

00:00:53.420 --> 00:00:57.050
我生成了从 0 到 1 的某个随机值

00:00:57.050 --> 00:01:02.215
看看该值是否小于 1 减去该字词的丢弃概率

00:01:02.215 --> 00:01:03.595
也就是说

00:01:03.595 --> 00:01:08.055
我要保留该字词的概率是 1 - p_drop

00:01:08.055 --> 00:01:11.615
假设丢弃概率是 0.98

00:01:11.615 --> 00:01:15.265
那么保留概率是 1 减去这个 p_drop

00:01:15.265 --> 00:01:17.330
结果为 0.02

00:01:17.330 --> 00:01:20.675
如果生成的值小于 0.02（这不太可能）

00:01:20.675 --> 00:01:24.990
那么我将在 train_words 列表中保留该字词

00:01:24.990 --> 00:01:27.080
这道练习还有其他求解方式

00:01:27.080 --> 00:01:30.220
但是我想从该保留哪些字词的角度思考问题

00:01:30.220 --> 00:01:33.680
Ok输出这个训练数据的前 30 个字词

00:01:33.680 --> 00:01:37.665
看起来和 int_words 列表中的前 30 个标记相似

00:01:37.665 --> 00:01:41.375
但是大多数 0 和 1 消失了

00:01:41.375 --> 00:01:43.665
0 和 1 表示之前最常见的字词

00:01:43.665 --> 00:01:45.570
和我预期的效果一样

00:01:45.570 --> 00:01:47.325
接下来

00:01:47.325 --> 00:01:50.800
我们将定义上下文窗口并批处理数据

