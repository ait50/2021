WEBVTT
Kind: captions
Language: zh-CN

00:00:00.050 --> 00:00:03.270
在这节课 我将讨论

00:00:03.270 --> 00:00:06.150
如何使用神经网络处理自然语言

00:00:06.150 --> 00:00:08.404
我们将讨论词嵌入

00:00:08.404 --> 00:00:12.120
词嵌入是指模型学习将词汇表中的一组字词或短语

00:00:12.120 --> 00:00:16.005
映射到数字向量

00:00:16.005 --> 00:00:17.995
这些向量称为嵌入

00:00:17.995 --> 00:00:21.080
我们可以使用神经网络学习构建词嵌入

00:00:21.080 --> 00:00:25.330
通常 这种技巧可以降低文本数据的维数

00:00:25.330 --> 00:00:27.500
但是这些嵌入模型也能够学习

00:00:27.500 --> 00:00:30.290
关于词汇表中字词的有趣特性

00:00:30.290 --> 00:00:33.470
我们将重点讲解 Word2Vec 嵌入模型

00:00:33.470 --> 00:00:37.390
它会学习将字词映射到包含语义的嵌入

00:00:37.390 --> 00:00:39.920
例如 嵌入可以学习当前时态动词

00:00:39.920 --> 00:00:42.560
与过去时态动词之间的关系

00:00:42.560 --> 00:00:45.750
比如 walking 和 walked 的嵌入之间的关系

00:00:45.750 --> 00:00:49.775
应该与 swimming 和 swam 的嵌入之间的关系一样

00:00:49.775 --> 00:00:54.215
同理 嵌入可以学习字词和常见性别词之间的关系

00:00:54.215 --> 00:00:58.145
例如 woman 和 Queen 以及 man 和 King 之间的关系

00:00:58.145 --> 00:01:00.800
你可以将这些嵌入看做一种向量

00:01:00.800 --> 00:01:04.875
这些向量学会从数学角度表示词汇表中字词之间的关系

00:01:04.875 --> 00:01:09.200
注意嵌入是根据一段文本学习而来的

00:01:09.200 --> 00:01:14.065
因此源文本里的任何字词关系将体现到嵌入里

00:01:14.065 --> 00:01:18.665
如果文本包含错误信息或性别偏见关系

00:01:18.665 --> 00:01:21.415
这些特性将体现在嵌入里

00:01:21.415 --> 00:01:23.630
实际上 词嵌入消除偏见

00:01:23.630 --> 00:01:26.695
是一个很活跃的研究领域 你可以在下方了解详情

00:01:26.695 --> 00:01:30.590
在这节课 我们首先将讨论词嵌入的理论知识

00:01:30.590 --> 00:01:32.480
然后讲解一系列 notebook

00:01:32.480 --> 00:01:34.975
逐步指导你实现 Word2Vec 模型

00:01:34.975 --> 00:01:37.490
在开始编程之前

00:01:37.490 --> 00:01:41.080
我们了解下为何嵌入能够降低文本数据的维数

