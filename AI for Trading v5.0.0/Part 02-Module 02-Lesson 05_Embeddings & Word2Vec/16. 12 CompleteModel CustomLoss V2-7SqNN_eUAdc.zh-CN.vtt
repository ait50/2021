WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.270
我运行了 notebook 中的所有单元格

00:00:03.270 --> 00:00:07.040
下面说说我是如何定义 SkipGramNeg 模型的

00:00:07.040 --> 00:00:11.580
首先定义 in-embed 和 out-embed 这两个嵌入层

00:00:11.580 --> 00:00:13.380
它们的参数都包括词汇表大小

00:00:13.380 --> 00:00:17.030
并生成大小为 n_embed 的嵌入

00:00:17.030 --> 00:00:20.070
从而将词汇表映射到嵌入维度

00:00:20.070 --> 00:00:23.610
在这里用范围为 -1 到 1 的均匀权重

00:00:23.610 --> 00:00:27.755
初始化嵌入查询表

00:00:27.755 --> 00:00:30.150
我对这两个层级都执行了这一步

00:00:30.150 --> 00:00:32.725
这样可以帮助模型更快地达到最佳状态

00:00:32.725 --> 00:00:35.355
然后定义三个 forward 函数

00:00:35.355 --> 00:00:38.640
forward_input 将输入字词传入输入嵌入层

00:00:38.640 --> 00:00:41.810
并返回输入嵌入向量

00:00:41.810 --> 00:00:44.360
forward_output 也差不多

00:00:44.360 --> 00:00:47.165
不过传入的是输出嵌入层 并获得输出向量

00:00:47.165 --> 00:00:51.690
注意这里没有线性层级或 softmax 激活函数

00:00:51.690 --> 00:00:53.740
最后一个 forward 函数是 forward_noise

00:00:53.740 --> 00:00:56.565
它将返回一个噪点目标嵌入

00:00:56.565 --> 00:00:59.600
这些噪点样本字词来自噪点分布

00:00:59.600 --> 00:01:03.125
返回 (batch_size * n_samples) 个样本

00:01:03.125 --> 00:01:05.285
然后将这些噪点字词传入输出嵌入层

00:01:05.285 --> 00:01:08.185
来获得嵌入

00:01:08.185 --> 00:01:09.610
在同一行

00:01:09.610 --> 00:01:11.650
将这些向量变形为我想要的大小

00:01:11.650 --> 00:01:16.940
即 (batch_size, n_samples, n_embed) 然后返回这些向量

00:01:16.940 --> 00:01:20.080
这就是完整的 SkipGramNeg 模型

00:01:20.080 --> 00:01:23.790
接下来定义自定义负采样损失

00:01:23.790 --> 00:01:27.310
我根据公式定义了该损失函数

00:01:27.310 --> 00:01:30.610
虽然之前没有详细讲解如何定义自定义损失

00:01:30.610 --> 00:01:34.510
但是不用担心 它和定义 model 类很像

00:01:34.510 --> 00:01:36.970
只不过 init 函数留空了

00:01:36.970 --> 00:01:40.130
只需定义 forward 函数

00:01:40.130 --> 00:01:43.330
forward 函数会接受输入和目标参数

00:01:43.330 --> 00:01:47.460
我们可以在这里定义一些其他参数

00:01:47.460 --> 00:01:52.875
它应该返回一个值 表示一批数据的平均损失

00:01:52.875 --> 00:01:57.135
负采样损失需要查看输入嵌入向量、

00:01:57.135 --> 00:01:59.090
正确输出嵌入向量

00:01:59.090 --> 00:02:01.430
以及错误噪点向量

00:02:01.430 --> 00:02:03.700
在这里根据输入向量的形状

00:02:03.700 --> 00:02:06.310
获取批次大小和嵌入维度

00:02:06.310 --> 00:02:10.520
然后将输入向量变形为 batch_first 的形状

00:02:10.520 --> 00:02:13.670
在这里变形输出向量

00:02:13.670 --> 00:02:15.785
将维度 embed_size 和 1 调换过来

00:02:15.785 --> 00:02:20.260
变成输出向量转置矩阵

00:02:20.260 --> 00:02:23.030
这样便能够对这两个向量执行批量矩阵乘法运算

00:02:23.030 --> 00:02:26.765
从而计算这两个向量的点积

00:02:26.765 --> 00:02:28.930
也就是这一步的作用

00:02:28.930 --> 00:02:31.250
首先计算输入向量

00:02:31.250 --> 00:02:34.175
与正确目标向量之间的损失项

00:02:34.175 --> 00:02:38.990
在这里采用批量矩阵乘法运算 (bmm) 然后应用 S 型函数和对数函数

00:02:38.990 --> 00:02:43.370
在这里对输出运行 squeeze() 使输出中没有任何空的维度

00:02:43.370 --> 00:02:45.890
接下来对输入向量与否定的噪点向量

00:02:45.890 --> 00:02:49.375
执行相似的步骤

00:02:49.375 --> 00:02:51.540
这是损失函数的第二项

00:02:51.540 --> 00:02:54.165
在这里执行批量矩阵乘法运算

00:02:54.165 --> 00:02:56.285
并应用 S 型函数和对数函数

00:02:56.285 --> 00:03:00.015
然后对噪点向量样本的损失求和

00:03:00.015 --> 00:03:04.070
最后将这两个损失加起来并取负数

00:03:04.070 --> 00:03:08.560
因为我在计算过程中求得是正值 然后对总损失求平均值

00:03:08.560 --> 00:03:12.960
这样就能返回一批数据的平均负采样损失

00:03:12.960 --> 00:03:16.230
继续创建并训练该模型

00:03:16.230 --> 00:03:18.739
这个训练循环和之前的很像

00:03:18.739 --> 00:03:20.874
不过也有一些显著差别

00:03:20.874 --> 00:03:24.110
首先 在这里创建均匀噪点分布

00:03:24.110 --> 00:03:27.325
将噪点向量与出现频率关联起来

00:03:27.325 --> 00:03:29.980
我之前计算了这个值

00:03:29.980 --> 00:03:32.300
将噪点分布定义为均匀分布

00:03:32.300 --> 00:03:34.385
并根据论文中的说明

00:03:34.385 --> 00:03:37.030
将幂数设为 0.75

00:03:37.030 --> 00:03:39.890
然后在这里定义模型 传入词汇表长度

00:03:39.890 --> 00:03:43.600
并将嵌入维度设为 300

00:03:43.600 --> 00:03:45.710
并传入这个刚刚创建的噪点分布

00:03:45.710 --> 00:03:47.510
将数据全部移到 GPU 上

00:03:47.510 --> 00:03:49.245
另一个重要区别是

00:03:49.245 --> 00:03:51.320
我没有使用 NLLloss

00:03:51.320 --> 00:03:54.990
而是使用在上面定义的自定义负采样损失

00:03:54.990 --> 00:03:59.500
在训练循环里 需要向这个损失函数传入三个参数

00:03:59.500 --> 00:04:01.490
训练 5 个周期

00:04:01.490 --> 00:04:04.070
在这里获取批量输入和目标字词

00:04:04.070 --> 00:04:07.940
然后使用三个不同的 forward 函数

00:04:07.940 --> 00:04:09.470
获取输入嵌入向量、输出嵌入向量

00:04:09.470 --> 00:04:11.105
和噪点嵌入向量

00:04:11.105 --> 00:04:13.360
向 forward_input 中传入 inputs

00:04:13.360 --> 00:04:18.185
向 forward_output 中传入 targets

00:04:18.185 --> 00:04:21.980
forward_noise 有两个参数 一个是批次大小 另一个是要生成的噪点向量数量

00:04:21.980 --> 00:04:23.660
然后计算损失

00:04:23.660 --> 00:04:25.315
在这里传入输入向量、

00:04:25.315 --> 00:04:27.765
输出向量和噪点向量

00:04:27.765 --> 00:04:30.215
这些是和之前一样的代码

00:04:30.215 --> 00:04:34.000
执行反向传播和优化步骤

00:04:34.000 --> 00:04:36.590
在这里输出验证相似性

00:04:36.590 --> 00:04:40.000
以及周期和损失

00:04:40.000 --> 00:04:43.760
我定义了三个不同的 forward 函数

00:04:43.760 --> 00:04:48.275
目的是获得计算负采样损失所需的向量

00:04:48.275 --> 00:04:52.645
你可以自己试试训练该模型 看看训练速度提高了多少

00:04:52.645 --> 00:04:56.545
我输出数据的频率低了 因为数据生成速度更快

00:04:56.545 --> 00:04:58.575
在第 1 个周期之后

00:04:58.575 --> 00:05:01.755
字词之间的关系不太紧密

00:05:01.755 --> 00:05:03.295
但是在训练完毕后

00:05:03.295 --> 00:05:05.395
字词分组变得更加合理了

00:05:05.395 --> 00:05:07.285
例如 mathematics algebra,

00:05:07.285 --> 00:05:09.700
calculus 是一组

00:05:09.700 --> 00:05:12.000
ocean islands pacific atlantic 变成了一组

00:05:12.000 --> 00:05:15.125
一些小词也组合到了一起

00:05:15.125 --> 00:05:18.950
使用 T-SNE 可视化字词向量

00:05:18.950 --> 00:05:21.860
不过可视化的字词数量变少了

00:05:21.860 --> 00:05:24.820
并且仅从输入嵌入层获取嵌入

00:05:24.820 --> 00:05:29.690
将这些嵌入传入 T-SNE 模型 结果是这样的

00:05:29.690 --> 00:05:32.255
这些是整数词

00:05:32.255 --> 00:05:36.545
这些是教育术语 这些是战争和军事术语

00:05:36.545 --> 00:05:39.515
这些是政府术语 还有其他各种词汇

00:05:39.515 --> 00:05:42.845
这样的图表看起来比较有意思

00:05:42.845 --> 00:05:45.470
word2vec 模型总是让我觉得

00:05:45.470 --> 00:05:48.505
模型生成的向量空间很有趣

00:05:48.505 --> 00:05:52.370
例如我们可以嵌入图像并发现颜色和对象之间的关系

00:05:52.370 --> 00:05:56.885
例如使用向量运算转换字词

00:05:56.885 --> 00:06:01.430
这个模型构建和训练起来很复杂

00:06:01.430 --> 00:06:04.310
如果你能熟练编写模型代码

00:06:04.310 --> 00:06:07.189
并自己添加 forward 函数和自定义损失类型

00:06:07.189 --> 00:06:11.940
那么你已经熟练掌握 PyTorch 的 Python 特性和模型自定义方法了

00:06:11.940 --> 00:06:15.630
而且能自己构建非常高效的 word2vec 模型

00:06:15.630 --> 00:06:17.675
做得很好

00:06:17.675 --> 00:06:20.200
接下来内容更精彩哦

