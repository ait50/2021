WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.935
我们讨论过神经网络如何从数字数据中学习规律

00:00:04.935 --> 00:00:07.620
词嵌入的作用是

00:00:07.620 --> 00:00:11.200
提高网络从文本数据中学习规律的能力

00:00:11.200 --> 00:00:14.010
嵌入通过将数据表示为低维向量

00:00:14.010 --> 00:00:16.829
大大提高了网络

00:00:16.829 --> 00:00:19.785
从文本数据中学习规律的能力

00:00:19.785 --> 00:00:21.805
举个例子

00:00:21.805 --> 00:00:25.230
通常在处理文本时 我们会将文本拆分为字词

00:00:25.230 --> 00:00:28.960
一个大型数据集包含成千上万的不同字词

00:00:28.960 --> 00:00:32.490
在将这些字词当做输入传入 RNN 等网络前

00:00:32.490 --> 00:00:34.835
我们可以独热编码这些字词

00:00:34.835 --> 00:00:38.980
结果生成一个庞大的向量 其中包含约 50,000 个元素

00:00:38.980 --> 00:00:41.030
只有一个元素设为 1

00:00:41.030 --> 00:00:42.730
所有其他元素都设为 0

00:00:42.730 --> 00:00:46.895
然后将此长向量传入某个隐藏层

00:00:46.895 --> 00:00:49.880
通过将此输入向量乘以某个学习的权重矩阵

00:00:49.880 --> 00:00:52.960
算出隐藏层的输出

00:00:52.960 --> 00:00:55.490
结果是一个庞大的值矩阵

00:00:55.490 --> 00:00:58.625
大多数值都为 0 因为初始向量是一个独热向量

00:00:58.625 --> 00:01:03.080
计算资源浪费在了很多不包含任何信息的值上

00:01:03.080 --> 00:01:05.320
非常不高效

00:01:05.320 --> 00:01:07.855
为了解决此问题 我们可以使用嵌入

00:01:07.855 --> 00:01:11.745
它是这种矩阵乘法的便捷方式

00:01:11.745 --> 00:01:13.230
为了学习词嵌入

00:01:13.230 --> 00:01:16.600
我们使用一个之前见过的全连接线性层级

00:01:16.600 --> 00:01:18.455
我们称此层级为嵌入层

00:01:18.455 --> 00:01:20.455
它的权重是嵌入权重

00:01:20.455 --> 00:01:24.040
这些权重将是在训练此嵌入模型过程中学习的值

00:01:24.040 --> 00:01:26.260
这些值构成了有用的权重矩阵

00:01:26.260 --> 00:01:30.640
借助此矩阵 我们可以跳过之前的繁琐乘法步骤

00:01:30.640 --> 00:01:32.980
直接从权重矩阵中的一行里

00:01:32.980 --> 00:01:36.215
获取隐藏层的输出值

00:01:36.215 --> 00:01:38.410
这是因为

00:01:38.410 --> 00:01:41.290
独热编码向量与权重矩阵相乘

00:01:41.290 --> 00:01:43.960
仅返回值为 1 或开启的输入单元的索引

00:01:43.960 --> 00:01:46.660
对应的矩阵行

00:01:46.660 --> 00:01:49.510
我们不再进行矩阵乘法运算

00:01:49.510 --> 00:01:52.505
而是使用嵌入权重矩阵作为查询表

00:01:52.505 --> 00:01:55.540
并且不再将字词表示为独热向量

00:01:55.540 --> 00:01:58.225
而是将每个字词编码为唯一整数

00:01:58.225 --> 00:02:03.410
举个例子 假设我们将 heart 表示为整数 958

00:02:03.410 --> 00:02:06.160
要获取 heart 的隐藏层值

00:02:06.160 --> 00:02:10.235
我们只需获取嵌入权重矩阵的第 958 行

00:02:10.235 --> 00:02:12.980
这个流程称为嵌入查询

00:02:12.980 --> 00:02:15.770
隐藏单元的数量称为嵌入维度

00:02:15.770 --> 00:02:19.060
嵌入查询表是一个权重矩阵

00:02:19.060 --> 00:02:21.400
嵌入层是一个隐藏层

00:02:21.400 --> 00:02:24.200
注意 就像任何权重矩阵一样

00:02:24.200 --> 00:02:26.950
查询表存储的是在训练过程中学习的权重

00:02:26.950 --> 00:02:30.365
这就是嵌入的基本工作原理

00:02:30.365 --> 00:02:31.795
在接下来的几个部分

00:02:31.795 --> 00:02:34.700
你将学习 Word2Vec 如何使用嵌入层

00:02:34.700 --> 00:02:38.720
查找具有语义的字词向量表示法

