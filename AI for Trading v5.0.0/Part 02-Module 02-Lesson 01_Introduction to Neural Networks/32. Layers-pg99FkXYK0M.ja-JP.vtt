WEBVTT
Kind: captions
Language: ja-JP

00:00:00.000 --> 00:00:04.495
ニューラルネットワークには特殊なアーキテクチャーの層があります

00:00:04.495 --> 00:00:07.320
最初の層は入力層と呼ばれ

00:00:07.320 --> 00:00:08.934
入力

00:00:08.933 --> 00:00:11.931
この場合はx1とx2を含みます

00:00:11.932 --> 00:00:14.460
次の層は隠れ層と呼ばれ

00:00:14.460 --> 00:00:18.855
この最初の入力層で作成された一連の線形モデルです

00:00:18.855 --> 00:00:21.940
最後の層は出力層と呼ばれ

00:00:21.940 --> 00:00:26.614
線形モデルが結合されて非線形モデルになります

00:00:26.614 --> 00:00:28.644
別のアーキテクチャーを使用することもできます

00:00:28.643 --> 00:00:31.764
たとえば これは隠れ層が大きなものです

00:00:31.765 --> 00:00:33.689
3つの線形モデルを結合して

00:00:33.689 --> 00:00:36.600
出力層で三角形の境界が得られます

00:00:36.600 --> 00:00:39.649
入力層のノードが多い場合はどうなるでしょうか

00:00:39.649 --> 00:00:43.460
たとえば 個のニューラルネットワークの入力層には3つのノードがあります

00:00:43.460 --> 00:00:46.435
これは2次元空間に住んでいないことを意味します

00:00:46.435 --> 00:00:48.755
3次元空間に住んでいて

00:00:48.755 --> 00:00:50.045
隠れ層は

00:00:50.045 --> 00:00:51.689
線形モデルを持つそうですが

00:00:51.689 --> 00:00:54.795
3つの空間に多くの平面を与え

00:00:54.795 --> 00:00:59.820
出力層は3つの空間の非線形領域を結合します

00:00:59.820 --> 00:01:03.030
一般に入力層にn個のノードがある場合

00:01:03.030 --> 00:01:06.780
データはn次元空間にあると考えます

00:01:06.780 --> 00:01:08.983
出力層のノードが多い場合はどうなるでしょうか

00:01:08.983 --> 00:01:10.890
その場合は出力が多くなるだけです

00:01:10.890 --> 00:01:14.209
その場合 マルチクラス分類モデルを持つことになります

00:01:14.209 --> 00:01:18.329
画像が猫か 犬か それとも鳥かを尋ねるモデルの場合

00:01:18.328 --> 00:01:20.309
出力層の

00:01:20.310 --> 00:01:25.140
各ノードについて クラスごとのスコアを出力します猫の場合は1点

00:01:25.140 --> 00:01:27.930
犬の場合は1点 鳥の場合は1点です

00:01:27.930 --> 00:01:31.189
そして最後に ここで物事はかなりクールになります

00:01:31.188 --> 00:01:33.274
層が多くなったらどうなるでしょう

00:01:33.275 --> 00:01:36.090
その場合 ディープニューラルネットワークになります

00:01:36.090 --> 00:01:39.435
ここで何が起きるかというと 線形モデルが結合して

00:01:39.435 --> 00:01:45.364
非線形モデルになり これらが結合して さらに多くの非線形モデルになります

00:01:45.364 --> 00:01:48.150
一般に これを何度も繰り返すことで

00:01:48.150 --> 00:01:51.329
多くの隠れ層を持つ非常に複雑なモデルを得ることができます

00:01:51.328 --> 00:01:54.434
ここでニューラルネットワークのマジックが起こります

00:01:54.435 --> 00:01:56.406
実生活のモデルの多くには

00:01:56.406 --> 00:01:59.054
たとえば 自動運転車やゲームプレイエージェントの場合

00:01:59.055 --> 00:02:01.049
非常に多くの隠れ層があります

00:02:01.049 --> 00:02:02.879
ニューラルネットワークは

00:02:02.879 --> 00:02:07.091
おそらく右のように

00:02:07.090 --> 00:02:08.370
n次元の空間を非常に非線形な境界で分割するだけです

