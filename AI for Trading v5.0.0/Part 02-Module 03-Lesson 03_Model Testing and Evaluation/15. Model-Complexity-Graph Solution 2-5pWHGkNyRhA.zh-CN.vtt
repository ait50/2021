WEBVTT
Kind: captions
Language: zh-CN

00:00:00.300 --> 00:00:04.300
现在我们仔细看看下面获得的图表

00:00:04.300 --> 00:00:08.080
这称为模型复杂度图

00:00:08.080 --> 00:00:11.710
注意左侧是一个欠拟合模型

00:00:11.710 --> 00:00:14.620
它具有较高的训练误差和测试误差

00:00:14.620 --> 00:00:16.930
右边的模型过拟合

00:00:16.930 --> 00:00:21.330
它具有较低的训练误差和较高的测试误差

00:00:21.330 --> 00:00:24.330
中间的模型刚刚好

00:00:24.330 --> 00:00:27.830
它给我们相对较低的训练和测试误差

00:00:27.830 --> 00:00:29.730
这是我们应该选择的模型

00:00:29.730 --> 00:00:31.630
这里我们可以看得更清楚

00:00:31.630 --> 00:00:34.530
x 轴是模型的复杂度

00:00:35.800 --> 00:00:41.700
我们的模型从线性到一次多项式一直到四次多项式

00:00:41.700 --> 00:00:45.750
左侧模型显示了欠拟合或高偏差误差

00:00:45.760 --> 00:00:50.500
右侧的显示了过拟合或者说高方差误差

00:00:50.500 --> 00:00:53.870
而在中间 2 的位置是最佳点

00:00:53.870 --> 00:00:57.390
这里既不欠拟合 也不过拟合

00:00:57.390 --> 00:01:03.750
因此 可以确定我们数据的最佳模型是二次多项式

00:01:03.750 --> 00:01:05.330
目前一切都还不错 对吧？

00:01:05.330 --> 00:01:06.700
什么情况？

00:01:06.700 --> 00:01:06.710
这是怎么回事？发生什么了？

00:01:06.710 --> 00:01:07.270
啥情况？

00:01:08.450 --> 00:01:09.720
我们该怎么做？

00:01:09.720 --> 00:01:11.190
原来我们违背了一条黄金法则

00:01:11.190 --> 00:01:14.890
永远不能将测试数据用于训练

00:01:14.890 --> 00:01:17.030
我们犯了一个严重的错误

00:01:17.030 --> 00:01:19.470
但是来看看 我们到底做了什么？

00:01:19.470 --> 00:01:21.310
问题在这里

00:01:21.310 --> 00:01:24.760
我们用测试数据训练了模型

00:01:24.760 --> 00:01:29.120
除非到最后一步 我们不应该使用测试数据

00:01:29.120 --> 00:01:32.080
但我们却利用它决定了我们选择的模型

00:01:32.080 --> 00:01:33.640
这是完全禁止的

00:01:33.640 --> 00:01:36.200
你是不允许触碰测试数据的

00:01:36.200 --> 00:01:37.910
那么我们如何解决这个问题呢？

00:01:37.910 --> 00:01:41.420
我们如何在不使用测试数据的情况下 对模型做出正确的选择呢？

00:01:42.550 --> 00:01:43.810
不用慌

00:01:43.810 --> 00:01:47.000
我们可以进一步拆分数据集来解决这个问题

00:01:47.000 --> 00:01:48.800
现在 除了训练集和

00:01:48.810 --> 00:01:53.090
测试集 我们还将添加一个交叉验证集

00:01:53.090 --> 00:01:56.990
训练集将用于训练参数

00:01:56.990 --> 00:01:59.170
交叉验证集将用于

00:01:59.180 --> 00:02:03.780
对模型做出决定 例如多项式的次数

00:02:03.780 --> 00:02:08.030
测试集将用于模型的最终测试

00:02:08.030 --> 00:02:09.030
现在我们的图表看起来好多了

00:02:09.030 --> 00:02:12.900
包含交叉验证误差 而不是测试误差 

00:02:12.900 --> 00:02:14.310
我们来回顾一下

00:02:14.310 --> 00:02:18.160
这里我们将模型复杂性图和示例放在一起

00:02:18.160 --> 00:02:18.170
在左边 我们看到的是欠拟合 

00:02:18.170 --> 00:02:23.410
或者说过度简化问题

00:02:23.410 --> 00:02:27.780
这对训练集和交叉验证集来说都很糟

00:02:27.780 --> 00:02:31.980
因为我们的模型根本无法捕捉数据的复杂性

00:02:31.990 --> 00:02:36.910
在右侧 我们看到的是过拟合或过度复杂化问题

00:02:36.910 --> 00:02:36.920
在对训练集的拟合效果较好

00:02:36.920 --> 00:02:40.700
因为模型在记住它

00:02:40.710 --> 00:02:44.390
但对交叉验证的效果较差 因为模型不能很好地泛化

00:02:45.690 --> 00:02:49.540
中间是我们的完美模型 它在训练集

00:02:49.540 --> 00:02:51.160
和测试集上的拟合效果都很好

00:02:51.160 --> 00:02:54.710
我们可以将欠拟合想象成在无准备的情况下去参加考试

00:02:54.710 --> 00:02:57.530
无论你费多大的力 最终都考不好

00:02:57.530 --> 00:03:00.390
过拟合是做了准备 但是

00:03:00.390 --> 00:03:05.300
你没有去理解那些知识 只是将它一字一句地背下来了

00:03:05.300 --> 00:03:07.120
你可以回答得上试卷上所有重复的问题

00:03:07.120 --> 00:03:10.310
但遇到关于数据的新问题 就答不出来了

00:03:10.310 --> 00:03:13.080
而完美的模型就像是你学习了知识

00:03:13.080 --> 00:03:15.220
并准备好回答试卷中遇到的任何新问题

00:03:16.530 --> 00:03:19.500
这里是模型复杂度的一般图形

00:03:19.500 --> 00:03:22.370
当然 它们可能没这么漂亮 但在现实生活中的大多数时候

00:03:22.370 --> 00:03:25.000
你的模型都会表现出这样的行为

00:03:25.000 --> 00:03:29.560
模型越复杂 训练误差越来越小

00:03:29.560 --> 00:03:33.930
测试误差开始很大 然后减小 然后再变大

00:03:33.930 --> 00:03:36.440
左侧欠拟合

00:03:36.440 --> 00:03:38.790
右侧过拟合

00:03:38.790 --> 00:03:38.800
而完美点在这里

00:03:38.800 --> 00:03:40.420
从这里开始

00:03:40.430 --> 00:03:42.450
图形开始互相远离

