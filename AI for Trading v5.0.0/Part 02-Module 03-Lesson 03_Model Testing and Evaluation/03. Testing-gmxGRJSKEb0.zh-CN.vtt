WEBVTT
Kind: captions
Language: zh-CN

00:00:00.090 --> 00:00:02.290
在本课中 我们将重复使用回归和分类

00:00:02.290 --> 00:00:06.400
的概念 所以让我们先回顾一下它们的定义

00:00:06.400 --> 00:00:11.336
回归模型是一个预测值的模型 例如 4 -3 或 6.7

00:00:11.336 --> 00:00:15.910
在左边的图表中 我们绘制了一条紧密拟合数据的直线

00:00:15.910 --> 00:00:17.940
如果 x 轴上有一个新值

00:00:17.940 --> 00:00:21.750
则可以在直线上找到相应的 y 值来近似它

00:00:21.750 --> 00:00:24.980
分类问题主要用来确定状态

00:00:24.980 --> 00:00:29.210
例如 正/负 是/否 猫/狗

00:00:29.210 --> 00:00:34.020
在右边的图形中 我们有一些蓝色的点 标记为正

00:00:34.020 --> 00:00:35.940
以及一些红色的点 标记为负

00:00:35.939 --> 00:00:38.359
我们画了一条区分它们的直线

00:00:38.359 --> 00:00:40.269
当此平面上有一个新值时

00:00:40.270 --> 00:00:44.340
我们根据它属于这两个区域中的哪一个来猜测它的状态

00:00:44.340 --> 00:00:47.600
那么总结起来 就是回归返回的是值

00:00:47.600 --> 00:00:49.740
而分类返回的是状态

00:00:49.740 --> 00:00:53.310
那么 现在你建好了一个模型 你如何向自己

00:00:53.310 --> 00:00:55.500
和他人证明这个模型是良好的呢？

00:00:55.500 --> 00:00:56.969
方法就是测试

00:00:56.969 --> 00:01:00.250
我们来看 BUFF 的图片 它显示了一个简单的回归示例

00:01:00.250 --> 00:01:02.640
我们的数据与分数对应

00:01:02.640 --> 00:01:05.219
我们训练了两个模型来拟合该数据

00:01:05.219 --> 00:01:07.439
一个是直线 另一个是曲线

00:01:08.549 --> 00:01:11.920
现在的问题是 这两个模型哪个更好？

00:01:11.920 --> 00:01:14.120
右边这个完美拟合了数据

00:01:14.120 --> 00:01:16.042
而左边这个没有

00:01:16.042 --> 00:01:18.010
我们会忍不住说右边的更好

00:01:18.010 --> 00:01:22.350
要确定拟合性能 我们可以取一个新的点 这个红色点

00:01:22.349 --> 00:01:26.164
左边的模型对这点近似地较好 而右边的

00:01:26.165 --> 00:01:29.410
模型近似的效果较差

00:01:29.409 --> 00:01:32.500
所以最终来看 左侧的模型比

00:01:32.500 --> 00:01:33.680
右边的模型要好

00:01:33.680 --> 00:01:36.630
左侧模型的优点在于尽管它没有

00:01:36.629 --> 00:01:40.847
完美拟合数据 但它的泛化能力比右边的好

00:01:40.847 --> 00:01:43.480
右边的模型太过于完美拟合数据

00:01:43.480 --> 00:01:45.020
结果将这些数据记了下来

00:01:45.019 --> 00:01:48.839
这称为过拟合 我们将在后面的纳米学位课程中学习

00:01:48.840 --> 00:01:53.109
现在的问题是 我们如何找到一个泛化能力高的模型呢？

00:01:53.109 --> 00:01:56.250
在这里 我们就要引入测试的概念

00:01:56.250 --> 00:02:01.409
我们要在这里做的 是将数据分为两个集合 一个是训练集

00:02:01.409 --> 00:02:03.099
一个测试集

00:02:03.099 --> 00:02:07.449
在这个图中 训练集是灰色点的集合

00:02:07.450 --> 00:02:09.740
测试集是白色点的集合

00:02:09.740 --> 00:02:13.680
接下来 顾名思义 我们要用训练集

00:02:13.680 --> 00:02:17.875
来训练模型 然后在测试集中测试结果

00:02:17.875 --> 00:02:21.495
现在我们有两个数据集 由灰色点组成的训练集

00:02:21.495 --> 00:02:24.314
和用白色点组成的测试集

00:02:24.314 --> 00:02:27.974
可以看到训练了训练集的模型 即灰色点

00:02:27.974 --> 00:02:31.905
右边的模型看起来似乎比左边的模型好

00:02:31.905 --> 00:02:36.396
但是一旦我们在测试集上测试 即白色点 可以看到

00:02:36.395 --> 00:02:40.639
左侧的模型更好 因为红色所表示的误差更小

00:02:40.639 --> 00:02:43.189
因此可以得出结论 左侧的模型更好

00:02:43.189 --> 00:02:46.609
因为虽然它在训练集上的表现略弱

00:02:46.610 --> 00:02:48.885
但它在测试集上的效果更好

00:02:48.884 --> 00:02:51.894
我们可以将相同的过程用于分类问题 就像这里的

00:02:51.895 --> 00:02:52.835
这个

00:02:52.835 --> 00:02:56.795
我们训练了两个分类模型来分离蓝正点

00:02:56.794 --> 00:02:58.634
和红负点

00:02:58.634 --> 00:03:01.974
左边的这个模型还好 因为它仅犯了少数几个错误

00:03:01.974 --> 00:03:03.814
右侧的这个非常棒

00:03:03.814 --> 00:03:06.344
因为它准确区分了所有的点

00:03:06.344 --> 00:03:09.740
但直觉告诉我们左边的可能更好

00:03:09.740 --> 00:03:11.320
因为它更泛化

00:03:11.319 --> 00:03:15.150
同时 左边的模型将这些异常数值视为噪声

00:03:15.150 --> 00:03:19.099
并尝试以更简单和更一般的方式来拟合数据

00:03:19.099 --> 00:03:21.710
所以为了挑选一个好的模型 我们需要取一些点

00:03:21.710 --> 00:03:23.510
称之为测试集

00:03:23.509 --> 00:03:26.919
那么 训练集用实心点表示

00:03:26.919 --> 00:03:30.239
测试集用空心点表示

00:03:30.240 --> 00:03:32.010
现在我们训练这两个模型

00:03:32.009 --> 00:03:35.310
注意这两个点对训练集的拟合都不错

00:03:35.310 --> 00:03:39.030
但当我们引入测试集 左边的模型

00:03:39.030 --> 00:03:43.879
仅有一处错误 而右边的点有两处错误

00:03:43.879 --> 00:03:48.469
因此 通过测试 我们得出结论左边的模型更好

00:03:48.469 --> 00:03:51.046
在 sklearn 中这样做的方式很简单 使用

00:03:51.046 --> 00:03:54.359
模型选择包中的 train-test-split 函数即可

00:03:54.360 --> 00:03:56.816
首先 我们导入 train_test_split

00:03:56.816 --> 00:04:00.195
train_test_split 函数将以下作为参数

00:04:00.195 --> 00:04:04.280
输入、输出以及

00:04:04.280 --> 00:04:07.469
我们想留作测试数据的数据比例

00:04:07.469 --> 00:04:11.800
例如 test_size 等于 0.25 指将我们 25% 的数据

00:04:11.800 --> 00:04:14.400
用作测试集

00:04:14.400 --> 00:04:16.959
在这个例子中 我们有 16 个数据点

00:04:16.959 --> 00:04:19.420
所以其中 4 个将用作测试数据

00:04:19.420 --> 00:04:22.150
而剩下的 12 个用作训练数据

00:04:22.149 --> 00:04:25.459
有一条黄金法则我们永远都不能违背

00:04:25.459 --> 00:04:30.579
那就是 不能将测试数据用于训练

00:04:30.579 --> 00:04:33.000
这一点非常重要 当我们选择一些数据用于

00:04:33.000 --> 00:04:37.771
测试时 必须将它们放在一边 直到最后一步再用

00:04:37.771 --> 00:04:41.379
而且我们不能使用它们来训练模型

00:04:41.379 --> 00:04:44.719
如果不注意 我们很容易违反它

00:04:44.720 --> 00:04:45.640
你很快就会知道是怎么回事

