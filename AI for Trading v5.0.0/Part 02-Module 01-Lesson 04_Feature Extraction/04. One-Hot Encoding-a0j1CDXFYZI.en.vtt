WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:03.209
So far, we've looked at representations that tried to

00:00:03.209 --> 00:00:07.669
characterize an entire document or collection of words as one unit.

00:00:07.669 --> 00:00:13.155
As a result, the kinds of inferences we can make are also typically at a document level,

00:00:13.154 --> 00:00:15.239
mixture of topics in the document,

00:00:15.240 --> 00:00:18.059
documents similarity, documents sentiment, et cetera.

00:00:18.059 --> 00:00:20.324
For a deeper analysis of text,

00:00:20.324 --> 00:00:24.994
we need to come up with a numerical representation for each word.

00:00:24.995 --> 00:00:27.390
If you've dealt with categorical variables for

00:00:27.390 --> 00:00:31.170
data analysis or tried to perform multi-class classification,

00:00:31.170 --> 00:00:34.850
you may have come across this term, One-Hot Encoding.

00:00:34.850 --> 00:00:37.005
That is one way of representing words,

00:00:37.005 --> 00:00:39.234
treat each word like a class,

00:00:39.234 --> 00:00:42.359
assign it a vector that has one in

00:00:42.359 --> 00:00:46.679
a single pre-determined position for that word and zero everywhere else.

00:00:46.679 --> 00:00:48.219
Looks familiar?

00:00:48.219 --> 00:00:50.865
Yeah, it's just like the bag of words idea,

00:00:50.865 --> 00:00:55.000
only that we keep a single word in each bag and build a vector for it.

