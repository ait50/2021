WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.419
为了尽可能多地捕捉自然语言中的变化

00:00:03.419 --> 00:00:06.855
词嵌入需要有高维度性

00:00:06.855 --> 00:00:10.050
这使它们非常难以可视化

00:00:10.050 --> 00:00:14.475
T-SNE 代表 t 分布随机邻域嵌入

00:00:14.474 --> 00:00:17.339
它是一种降维技术

00:00:17.339 --> 00:00:20.839
可以将高维向量映射到低维空间

00:00:20.839 --> 00:00:22.094
有点像 PCA

00:00:22.094 --> 00:00:25.814
主成分分析 但是有一个非常强大的特性

00:00:25.815 --> 00:00:27.839
它在进行转换时

00:00:27.839 --> 00:00:31.364
尝试保持对象之间的相对距离

00:00:31.364 --> 00:00:37.320
使相似对象互相接近 不同对象互相远离

00:00:37.320 --> 00:00:41.664
因此 t-SNE 成为词嵌入可视化的绝佳选择

00:00:41.664 --> 00:00:44.494
它能有效保留词嵌入模型已经学习的

00:00:44.494 --> 00:00:48.390
线性子结构和关系

00:00:48.390 --> 00:00:50.895
我们看一个较大向量空间时

00:00:50.895 --> 00:00:54.609
会发现相关词形成的有意义的组

00:00:54.609 --> 00:00:58.320
有时需要花费一点时间思考为什么会形成特定集群

00:00:58.320 --> 00:01:01.435
但大多数集群是非常直观的

00:01:01.435 --> 00:01:05.829
T-SNE 还可用于其它类型的数据 例如 图像

00:01:05.829 --> 00:01:08.920
我们现在看到的是 Caltech 101 数据集中的照片

00:01:08.920 --> 00:01:12.625
这些照片形成集群 每个集群与类标签大致对应

00:01:12.625 --> 00:01:16.599
类标签包括蓝天中的飞机

00:01:16.599 --> 00:01:22.609
不同形状和大小的帆船 以及人脸

00:01:22.609 --> 00:01:26.359
这是一个非常有用的工具 有助于理解

00:01:26.359 --> 00:01:30.310
网络学习的表示法 有助于识别漏洞或其它问题

