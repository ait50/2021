{
  "data": {
    "lesson": {
      "id": 505107,
      "key": "3ed4c9c1-7495-45cd-9d1f-3c8e87291d95",
      "title": "Pandas",
      "semantic_type": "Lesson",
      "is_public": true,
      "version": "1.0.0",
      "locale": "en-us",
      "summary": "Learn the basics of Pandas Series and DataFrames and how to use them to load and process data.",
      "lesson_type": "Classroom",
      "display_workspace_project_only": false,
      "resources": {
        "files": [
          {
            "name": "Videos Zip File",
            "uri": "https://zips.udacity-data.com/3ed4c9c1-7495-45cd-9d1f-3c8e87291d95/505107/1544456415224/Pandas+Videos.zip"
          },
          {
            "name": "Transcripts Zip File",
            "uri": "https://zips.udacity-data.com/3ed4c9c1-7495-45cd-9d1f-3c8e87291d95/505107/1544456412132/Pandas+Subtitles.zip"
          }
        ],
        "google_plus_link": null,
        "career_resource_center_link": null,
        "coaching_appointments_link": null,
        "office_hours_link": null,
        "aws_provisioning_link": null
      },
      "project": null,
      "lab": null,
      "concepts": [
        {
          "id": 568686,
          "key": "08bfe507-6877-4d5c-9a16-6a0b743a65ac",
          "title": "Instructors",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "08bfe507-6877-4d5c-9a16-6a0b743a65ac",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 568687,
              "key": "9d47bbca-1c87-44dc-9b46-802d8668248a",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/March/5ab03a1f_screen-shot-2018-03-19-at-3.21.24-pm/screen-shot-2018-03-19-at-3.21.24-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/9d47bbca-1c87-44dc-9b46-802d8668248a",
              "caption": "_Juan Delgado_",
              "alt": "",
              "width": 300,
              "height": 320,
              "instructor_notes": null
            },
            {
              "id": 568688,
              "key": "eef2ee67-47d2-464e-8d9c-6a3223a9ce7d",
              "title": null,
              "semantic_type": "ImageAtom",
              "is_public": true,
              "url": "https://video.udacity-data.com/topher/2018/March/5ab03a2e_screen-shot-2018-03-19-at-2.30.59-pm/screen-shot-2018-03-19-at-2.30.59-pm.png",
              "non_google_url": "https://s3.cn-north-1.amazonaws.com.cn/u-img/eef2ee67-47d2-464e-8d9c-6a3223a9ce7d",
              "caption": "_Juno Lee_",
              "alt": "",
              "width": 300,
              "height": 300,
              "instructor_notes": null
            },
            {
              "id": 568690,
              "key": "43390530-caac-4c7b-a666-979d37bfcd39",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "We are on to the next Python library, **Pandas**,  a data manipulation and analysis tool, given to you by Juan and Juno!\n\n\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 552977,
          "key": "438855fc-f1ed-4e22-8a0b-732145a4d751",
          "title": "Introduction to pandas",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "438855fc-f1ed-4e22-8a0b-732145a4d751",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 552980,
              "key": "ddff031f-a4d3-45f8-aa25-be25ad5c9d02",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Introduction to Pandas\n\n**Pandas** is a  package for data manipulation and analysis in Python. The name Pandas is derived from the econometrics term *Panel Data*. Pandas incorporates two additional data structures into Python, namely **Pandas Series** and **Pandas DataFrame**. These data structures allow us to work with *labeled* and *relational* data in an easy and intuitive manner.  These lessons are intended as a basic overview of Pandas and introduces some of its most important features.\n\nIn the following lessons you will learn:\n* How to import Pandas\n* How to create Pandas Series and DataFrames using various methods\n* How to access and change elements in Series and DataFrames\n* How to perform arithmetic operations on Series\n* How to load data into  a DataFrame\n* How to deal with Not a Number (NaN) values\n\nThe following lessons assume that you are already familiar with NumPy and have gone over the previous NumPy lessons. Therefore, to avoid being repetitive we will omit a lot of details already given in the NumPy lessons. Consequently, if you haven't seen the NumPy lessons we suggest you go over them first. \n\n# Downloading Pandas\nPandas is included with  **Anaconda**. If you don't already have Anaconda installed on your computer, please refer to the Anaconda section to get clear instructions on how to install Anaconda on your PC or Mac.\n\n# Pandas Versions\nAs with many Python packages, Pandas is updated from time to time. The following lessons were created using Pandas version 0.22. You can check which version of Pandas you have by typing `!conda list pandas` in your Jupyter notebook or by typing `conda list pandas` in the Anaconda prompt. If you have another version of Pandas installed in your computer, you can update your version by typing `conda install pandas=0.22` in the Anaconda prompt.  As newer versions of Pandas are released, some functions may become obsolete or replaced, so make sure you have the correct Pandas version before running the code. This will guarantee your code will run smoothly.  \n\n# Pandas Documentation\nPandas is remarkable data analysis library and it has many functions and features. In these introductory lessons we will only scratch the surface of what Pandas can do. If you want to learn more about Pandas, make sure you check out the Pandas Documentation:\n\n[Pandas Documentation](https://pandas.pydata.org/pandas-docs/stable/)",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 552638,
          "key": "e0de2ca4-e95d-4e1e-bf87-6a52eba2bb0d",
          "title": "Why Use pandas?",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "e0de2ca4-e95d-4e1e-bf87-6a52eba2bb0d",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 552639,
              "key": "b37070ab-319f-42be-92f5-4ff55454a0fe",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Why Use Pandas?\n\nThe recent success of machine learning algorithms is partly due to the huge amounts of data that we have available to train our algorithms on. However, when it comes to data, quantity is not the only thing that matters, the quality of your data is just as important. It often happens that large datasets don’t come ready to be fed into your learning algorithms. More often than not, large datasets will often have missing values, outliers, incorrect values, etc…  Having data with a lot of missing or bad values, for example, is not going to allow your machine learning algorithms to perform well. Therefore, one very important step in machine learning is to look at your data first and make sure it is well suited for your training algorithm by doing some basic data analysis. This is where Pandas come in. Pandas Series and DataFrames are designed for fast data analysis and manipulation, as well as being flexible and easy to use. Below are just a few features that makes Pandas an excellent package for data analysis:\n\n* Allows the use of labels for rows and columns\n* Can calculate rolling statistics on time series data\n* Easy handling of NaN values\n* Is able to load data of different formats into DataFrames\n* Can join and merge different datasets together\n* It integrates with NumPy and Matplotlib\n\nFor these and other reasons, Pandas DataFrames have become one of the most commonly used Pandas object for data analysis in Python.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 552640,
          "key": "4be561ba-ff64-4764-bcfd-db6ccd7403b8",
          "title": "Creating pandas Series",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "4be561ba-ff64-4764-bcfd-db6ccd7403b8",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 570070,
              "key": "cbc913f9-f835-4c37-bd90-1b1e670418a6",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Creating Pandas Series",
              "instructor_notes": ""
            },
            {
              "id": 569116,
              "key": "a44f5540-6990-44d9-8dce-18941f7510e2",
              "title": "Pandas 1 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "iXnYN8cnhzs",
                "china_cdn_id": "iXnYN8cnhzs.mp4"
              }
            },
            {
              "id": 552641,
              "key": "5deae364-b4dc-4ae1-8026-8296f981e1e8",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "A Pandas series is a *one-dimensional* array-like object that can hold many data types, such as numbers or strings. One of the main differences between Pandas Series and NumPy ndarrays is that you can assign an index label to each element in the Pandas Series. In other words, you can name the indices of your Pandas Series anything you want. Another big difference between Pandas Series and NumPy ndarrays is that Pandas Series can hold data of different data types.\n\nLet's start by importing Pandas into Python. It has become a convention to import Pandas as `pd`, therefore, you can import Pandas by typing the following command in your Jupyter notebook:\n\n```python\nimport pandas as pd\n```\n\nLet's begin by creating a Pandas Series. You can create Pandas Series by using the command `pd.Series(data, index)`, where `index` is a list of index labels. Let's use a Pandas Series to store a grocery list. We will use the food items as index labels and the quantity we need to buy of each item as our data.\n\n```python\n# We import Pandas as pd into Python\nimport pandas as pd\n\n# We create a Pandas Series that stores a grocery list\ngroceries = pd.Series(data = [30, 6, 'Yes', 'No'], index = ['eggs', 'apples', 'milk', 'bread'])\n\n# We display the Groceries Pandas Series\ngroceries\n```\n\n> eggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No  \ndtype: object\n\nWe see that Pandas Series are displayed with the indices in the first column and the data in the second column. Notice that the data is not indexed 0 to 3 but rather it is indexed with the names of the food we put in, namely eggs, apples, etc... Also notice that the data in our Pandas Series has both integers and strings.\n\nJust like NumPy ndarrays, Pandas Series have attributes that allows us to get information from the series in an easy way. Let's see some of them:\n\n```python\n# We print some information about Groceries\nprint('Groceries has shape:', groceries.shape)\nprint('Groceries has dimension:', groceries.ndim)\nprint('Groceries has a total of', groceries.size, 'elements')\n```\n\n> Groceries has shape: (4,)  \nGroceries has dimension: 1  \nGroceries has a total of 4 elements\n\nWe can also print the index labels and the data of the Pandas Series separately. This is useful if you don't happen to know what the index labels of the Pandas Series are.\n\n```python\n# We print the index and data of Groceries\nprint('The data in Groceries is:', groceries.values)\nprint('The index of Groceries is:', groceries.index)\n```\n\n> The data in Groceries is: [30 6 'Yes' 'No']  \nThe index of Groceries is: Index(['eggs', 'apples', 'milk', 'bread'], dtype='object')\n\nIf you are dealing with a very large Pandas Series and if you are not sure whether an index label exists, you can check by using the `in` command\n\n```python\n# We check whether bananas is a food item (an index) in Groceries\nx = 'bananas' in groceries\n\n# We check whether bread is a food item (an index) in Groceries\ny = 'bread' in groceries\n\n# We print the results\nprint('Is bananas an index label in Groceries:', x)\nprint('Is bread an index label in Groceries:', y)\n```\n\n> Is bananas an index label in Groceries: False  \nIs bread an index label in Groceries: True",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 552642,
          "key": "dc825e65-032d-4cb8-b3ed-e8ef91af620c",
          "title": "Accessing and Deleting Elements in pandas Series",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "dc825e65-032d-4cb8-b3ed-e8ef91af620c",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 570071,
              "key": "ca7a8f26-dd76-4ef5-a267-99e9fd603cbf",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Accessing and Deleting Elements in Pandas Series",
              "instructor_notes": ""
            },
            {
              "id": 569117,
              "key": "37a282b2-4142-4f6e-9403-ab7b2ae354cd",
              "title": "Pandas 2 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "B7MuFIwboKU",
                "china_cdn_id": "B7MuFIwboKU.mp4"
              }
            },
            {
              "id": 552643,
              "key": "da882df9-39e0-40ed-b9a4-0d0d7afb650f",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Now let's look at how we can access or modify elements in a Pandas Series. One great advantage of Pandas Series is that it allows us to access data in many different ways. Elements can be accessed using index labels or numerical indices inside square brackets, [ ], similar to how we access elements in NumPy ndarrays. Since we can use numerical indices, we can use both positive and negative integers to access data from the beginning or from the end of the Series, respectively. Since we can access elements in various ways, in order to remove any ambiguity to whether we are referring to an index label or numerical index, Pandas Series have two attributes, `.loc` and `.iloc` to explicitly state what we mean. The attribute `.loc` stands for *location* and it is used to explicitly state that we are using a labeled index. Similarly, the attribute `.iloc` stands for *integer location* and it is used to explicitly state that we are using a numerical index. Let's see some examples:\n\n```python\n# We access elements in Groceries using index labels:\n\n# We use a single index label\nprint('How many eggs do we need to buy:', groceries['eggs'])\nprint()\n\n# we can access multiple index labels\nprint('Do we need milk and bread:\\n', groceries[['milk', 'bread']]) \nprint()\n\n# we use loc to access multiple index labels\nprint('How many eggs and apples do we need to buy:\\n', groceries.loc[['eggs', 'apples']]) \nprint()\n\n# We access elements in Groceries using numerical indices:\n\n# we use multiple numerical indices\nprint('How many eggs and apples do we need to buy:\\n',  groceries[[0, 1]]) \nprint()\n\n# We use a negative numerical index\nprint('Do we need bread:\\n', groceries[[-1]]) \nprint()\n\n# We use a single numerical index\nprint('How many eggs do we need to buy:', groceries[0]) \nprint()\n# we use iloc to access multiple numerical indices\nprint('Do we need milk and bread:\\n', groceries.iloc[[2, 3]]) \n```\n\n> How many eggs do we need to buy: 30\n\n> Do we need milk and bread:  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp; No  \ndtype: object\n\n> How many eggs and apples do we need to buy:  \neggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30  \napples &nbsp;&nbsp;&nbsp; 6  \ndtype: object\n\n> How many eggs and apples do we need to buy:  \neggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30  \napples &nbsp;&nbsp;&nbsp; 6  \ndtype: object\n\n> Do we need bread:  \nbread &nbsp;&nbsp;&nbsp; No  \ndtype: object\n\n> How many eggs do we need to buy: 30\n\n> Do we need milk and bread:  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp; No  \ndtype: object\n\nPandas Series are also mutable like NumPy ndarrays, which means we can change the elements of a Pandas Series after it has been created. For example, let's change the number of eggs we need to buy from our grocery list\n\n```python\n# We display the original grocery list\nprint('Original Grocery List:\\n', groceries)\n\n# We change the number of eggs to 2\ngroceries['eggs'] = 2\n\n# We display the changed grocery list\nprint()\nprint('Modified Grocery List:\\n', groceries)\n```\n\n> Original Grocery List:  \neggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No  \ndtype: object\n\n> Modified Grocery List:  \neggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No  \ndtype: object\n\nWe can also delete items from a Pandas Series by using the `.drop()` method. The `Series.drop(label)` method removes the given `label` from the given `Series`. We should note that the `Series.drop(label)` method drops elements from the Series out of place, meaning that it doesn't change the original Series being modified. Let's see how this works:\n\n```python\n# We display the original grocery list\nprint('Original Grocery List:\\n', groceries)\n\n# We remove apples from our grocery list. The drop function removes elements out of place\nprint()\nprint('We remove apples (out of place):\\n', groceries.drop('apples'))\n\n# When we remove elements out of place the original Series remains intact. To see this\n# we display our grocery list again\nprint()\nprint('Grocery List after removing apples out of place:\\n', groceries)\n```\n\n> Original Grocery List:  \neggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No  \ndtype: object\n\n> We remove apples (out of place):  \neggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No  \ndtype: object\n\n> Grocery List after removing apples out of place:  \neggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No  \ndtype: object\n\nWe can delete items from a Pandas Series in place by setting the keyword `inplace` to `True` in the `.drop()` method. Let's see an example:\n\n```python\n# We display the original grocery list\nprint('Original Grocery List:\\n', groceries)\n\n# We remove apples from our grocery list in place by setting the inplace keyword to True\ngroceries.drop('apples', inplace = True)\n\n# When we remove elements in place the original Series its modified. To see this\n# we display our grocery list again\nprint()\nprint('Grocery List after removing apples in place:\\n', groceries)\n```\n\n> Original Grocery List:  \neggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No  \ndtype: object\n\n> Grocery List after removing apples in place:  \neggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 30  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; Yes  \nbread &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; No  \ndtype: object",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 552644,
          "key": "b042b182-8f47-4b23-a7f9-1a276baea9c9",
          "title": "Arithmetic Operations on pandas Series",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "b042b182-8f47-4b23-a7f9-1a276baea9c9",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 570072,
              "key": "7e1ce3fc-4e54-4771-b47d-fb1a68c19330",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Arithmetic Operations on Pandas Series",
              "instructor_notes": ""
            },
            {
              "id": 569118,
              "key": "69380cfb-9d88-4155-967e-f8a05e1b4229",
              "title": "Pandas 3 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "yhMT0X6YPFA",
                "china_cdn_id": "yhMT0X6YPFA.mp4"
              }
            },
            {
              "id": 552645,
              "key": "ab6b327c-b830-45cd-9998-cc763f00e858",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Just like with NumPy ndarrays, we can perform element-wise arithmetic operations on Pandas Series. In this lesson we will look at arithmetic operations between Pandas Series and single numbers. Let's create a new Pandas Series that will hold a grocery list of just fruits.\n\n```python\n# We create a Pandas Series that stores a grocery list of just fruits\nfruits= pd.Series(data = [10, 6, 3,], index = ['apples', 'oranges', 'bananas'])\n\n# We display the fruits Pandas Series\nfruits\n```\n\n> apples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3  \ndtype: int64\n\nWe can now modify the data in fruits by performing basic arithmetic operations. Let's see some examples\n\n```python\n# We print fruits for reference\nprint('Original grocery list of fruits:\\n ', fruits)\n\n# We perform basic element-wise operations using arithmetic symbols\nprint()\nprint('fruits + 2:\\n', fruits + 2) # We add 2 to each item in fruits\nprint()\nprint('fruits - 2:\\n', fruits - 2) # We subtract 2 to each item in fruits\nprint()\nprint('fruits * 2:\\n', fruits * 2) # We multiply each item in fruits by 2 \nprint()\nprint('fruits / 2:\\n', fruits / 2) # We divide each item in fruits by 2\nprint()\n```\n\n> Original grocery list of fruits:  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3  \ndtype: int64\n\n> fruits + 2:  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 12  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5  \ndtype: int64\n\n> fruits - 2:  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 4  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1  \ndtype: int64\n\n> fruits * 2:  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 20  \noranges &nbsp;&nbsp;&nbsp;&nbsp; 12  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \ndtype: int64\n\n> fruits / 2:  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.0  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.0  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.5  \ndtype: float64\n\nYou can also apply mathematical functions from NumPy, such as`sqrt(x)`, to all elements of a Pandas Series.\n\n```python\n# We import NumPy as np to be able to use the mathematical functions\nimport numpy as np\n\n# We print fruits for reference\nprint('Original grocery list of fruits:\\n', fruits)\n\n# We apply different mathematical functions to all elements of fruits\nprint()\nprint('EXP(X) = \\n', np.exp(fruits))\nprint() \nprint('SQRT(X) =\\n', np.sqrt(fruits))\nprint()\nprint('POW(X,2) =\\n',np.power(fruits,2)) # We raise all elements of fruits to the power of 2\n```\n\n> Original grocery list of fruits:  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3  \ndtype: int64\n\n> EXP(X) =  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 22026.465795  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 403.428793  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 20.085537  \ndtype: float64\n\n> SQRT(X) =  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.162278  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2.449490  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1.732051  \ndtype: float64\n\n> POW(X,2) =  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 100  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 36  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 9  \ndtype: int64\n\nPandas also allows us to only apply arithmetic operations on selected items in our fruits grocery list. Let's see some examples\n\n```python\n# We print fruits for reference\nprint('Original grocery list of fruits:\\n ', fruits)\nprint()\n\n# We add 2 only to the bananas\nprint('Amount of bananas + 2 = ', fruits['bananas'] + 2)\nprint()\n\n# We subtract 2 from apples\nprint('Amount of apples - 2 = ', fruits.iloc[0] - 2)\nprint()\n\n# We multiply apples and oranges by 2\nprint('We double the amount of apples and oranges:\\n', fruits[['apples', 'oranges']] * 2)\nprint()\n\n# We divide apples and oranges by 2\nprint('We half the amount of apples and oranges:\\n', fruits.loc[['apples', 'oranges']] / 2)\n```\n\n> Original grocery list of fruits:  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 10  \noranges &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 6  \nbananas &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3  \ndtype: int64\n\n> Amount of bananas + 2 =  5\n\n> Amount of apples - 2 =  8\n\n> We double the amount of apples and oranges:  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 20  \noranges &nbsp;&nbsp;&nbsp;&nbsp; 12  \ndtype: int64\n\n> We half the amount of apples and oranges:  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 5.0  \noranges &nbsp;&nbsp;&nbsp;&nbsp; 3.0  \ndtype: float64\n\n\nYou can also apply arithmetic operations on Pandas Series of mixed data type provided that the arithmetic operation is defined for *all* data types in the Series, otherwise you will get an error. Let's see what happens when we multiply our grocery list by 2\n\n```python\n# We multiply our grocery list by 2\ngroceries * 2\n```\n\n> eggs &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 60  \napples &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 12  \nmilk &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; YesYes  \nbread &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; NoNo  \ndtype: object\n\nAs we can see, in this case, since we multiplied by 2, Pandas doubles the data of each item including the strings. Pandas can do this because the multiplication operation `*` is defined both for numbers and strings. If you were to apply an operation that was valid for numbers but not strings, say for instance, `/` you will get an error. So when you have mixed data types in your Pandas Series make sure the arithmetic operations are valid on *all* the data types of your elements.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 556090,
          "key": "dc35aed8-4c0f-4ede-903c-0243f45125c3",
          "title": "Manipulate a Series",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "dc35aed8-4c0f-4ede-903c-0243f45125c3",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 556091,
              "key": "1dc4a844-2c76-4115-844d-b9efe207ab40",
              "title": "",
              "semantic_type": "QuizAtom",
              "is_public": true,
              "instructor_notes": "",
              "user_state": {
                "node_key": "1dc4a844-2c76-4115-844d-b9efe207ab40",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "instruction": null,
              "question": {
                "title": "",
                "semantic_type": "ProgrammingQuestion",
                "evaluation_id": "6269910888611840",
                "initial_code_files": [
                  {
                    "text": "import pandas as pd\r\n\r\n# Create a Pandas Series that contains the distance of some planets from the Sun.\r\n# Use the name of the planets as the index to your Pandas Series, and the distance\r\n# from the Sun as your data. The distance from the Sun is in units of 10^6 km\r\n\r\ndistance_from_sun = [149.6, 1433.5, 227.9, 108.2, 778.6]\r\n\r\nplanets = ['Earth','Saturn', 'Mars','Venus', 'Jupiter']\r\n\r\n# Create a Pandas Series using the above data, with the name of the planets as\r\n# the index and the distance from the Sun as your data.\r\ndist_planets = \r\n\r\n# Calculate the number of minutes it takes sunlight to reach each planet. You can\r\n# do this by dividing the distance from the Sun for each planet by the speed of light.\r\n# Since in the data above the distance from the Sun is in units of 10^6 km, you can\r\n# use a value for the speed of light of c = 18, since light travels 18 x 10^6 km/minute.\r\ntime_light = \r\n\r\n# Use Boolean indexing to select only those planets for which sunlight takes less\r\n# than 40 minutes to reach them.\r\nclose_planets = ",
                    "name": "sun_planets.py"
                  },
                  {
                    "text": "import pandas as pd\r\n\r\ndistance_from_sun = [149.6, 1433.5, 227.9, 108.2, 778.6]\r\n\r\nplanets = ['Earth','Saturn', 'Mars','Venus', 'Jupiter']\r\n\r\ndist_planets = pd.Series(data = distance_from_sun, index = planets)\r\n\r\ntime_light = dist_planets / 18\r\n\r\nclose_planets = time_light[time_light < 40]",
                    "name": "solution.py"
                  }
                ]
              },
              "answer": null
            }
          ]
        },
        {
          "id": 552646,
          "key": "173bd81d-7717-4225-b3cb-16b1a8818b14",
          "title": "Creating pandas DataFrames",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "173bd81d-7717-4225-b3cb-16b1a8818b14",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 570073,
              "key": "2d8c7246-29f1-4279-91b7-90b5d54bdd89",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Creating Pandas DataFrames",
              "instructor_notes": ""
            },
            {
              "id": 569292,
              "key": "15f35a8c-97ed-42d1-851e-5b35d5f25a55",
              "title": "Pandas 4 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "eMHUn9v9dds",
                "china_cdn_id": "eMHUn9v9dds.mp4"
              }
            },
            {
              "id": 552647,
              "key": "714a6ced-450a-4d19-955a-d7f46b828f11",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "Pandas DataFrames are two-dimensional data structures with labeled rows and columns, that can hold many data types. If you are familiar with Excel, you can think of Pandas DataFrames as being similar to a spreadsheet. We can create Pandas DataFrames manually or by loading data from a file. In these lessons we will start by learning how to create Pandas DataFrames manually from dictionaries and later we will see how we can load data into a DataFrame from a data file.\n\nWe will start by creating a DataFrame manually from a dictionary of Pandas Series. In this case the first step is to create the dictionary of Pandas Series. After the dictionary is created we can then pass the dictionary to the `pd.DataFrame()` function.\n\nWe will create a dictionary that contains items purchased by two people, Alice and Bob, on an online store. The Pandas Series will use the price of the items purchased as *data*, and the purchased items will be used as the *index* labels to the Pandas Series. Let's see how this done in code:\n\n```python\n# We import Pandas as pd into Python\nimport pandas as pd\n\n# We create a dictionary of Pandas Series \nitems = {'Bob' : pd.Series(data = [245, 25, 55], index = ['bike', 'pants', 'watch']),\n         'Alice' : pd.Series(data = [40, 110, 500, 45], index = ['book', 'glasses', 'bike', 'pants'])}\n\n# We print the type of items to see that it is a dictionary\nprint(type(items))\n```\n\n> class 'dict'\n\nNow that we have a dictionary, we are ready to create a DataFrame by passing it to the `pd.DataFrame()` function. We will create a DataFrame that could represent the shopping carts of various users, in this case we have only two users, Alice and Bob.\n\n```python\n# We create a Pandas DataFrame by passing it a dictionary of Pandas Series\nshopping_carts = pd.DataFrame(items)\n\n# We display the DataFrame\nshopping_carts\n```\n\n>  |    |     ** Alice**      |  **Bob** |\n|----------|:-------------:|:------:|\n|**bike** | 500.0 | 245.0  |\n|**book** |40.0 | NaN  |\n|**glasses**|110.0|NaN  |\n|**pants**|45.0|25.0  |\n|**watch**|NaN|55.0|\n\nThere are several things to notice here that are worth pointing out. We see that DataFrames are displayed in tabular form, much like an Excel spreadsheet, with the labels of rows and columns in **bold**. Also notice that the row labels of the DataFrame are built from the union of the index labels of the two Pandas Series we used to construct the dictionary. And the column labels of the DataFrame are taken from the *keys* of the dictionary. Another thing to notice is that the columns are arranged alphabetically and not in the order given in the dictionary. We will see later that this won't happen when we load data into a DataFrame from a data file. The last thing we want to point out is that we see some `NaN` values appear in the DataFrame. `NaN` stands for *Not a Number*, and is Pandas way of indicating that it doesn't have a value for that particular row and column index. For example, if we look at the column of Alice, we see that it has `NaN` in the watch index. You can see why this is the case by looking at the dictionary we created at the beginning. We clearly see that the dictionary has no item for Alice labeled watches. So whenever a DataFrame is created, if a particular column doesn't have values for a particular row index, Pandas will put a `NaN` value there. If we were to feed this data into a machine learning algorithm we will have to remove these `NaN` values first. In a later lesson we will learn how to deal with `NaN` values and clean our data. For now, we will leave these values in our DataFrame.\n\nIn the above example we created a Pandas DataFrame from a dictionary of Pandas Series that had clearly defined indexes. If we don't provide index labels to the Pandas Series, Pandas will use numerical row indexes when it creates the DataFrame. Let's see an example:\n\n```python\n# We create a dictionary of Pandas Series without indexes\ndata = {'Bob' : pd.Series([245, 25, 55]),\n        'Alice' : pd.Series([40, 110, 500, 45])}\n\n# We create a DataFrame\ndf = pd.DataFrame(data)\n\n# We display the DataFrame\ndf\n```\n\n>  |    |     ** Alice**      |  **Bob** |\n|----------|:-------------:|:------:|\n|**0** | 40 | 245.0  |\n|**1** |110 | 25.0  |\n|**2**|500|55.0  |\n|**3**|45|NaN  |\n\n\nWe can see that Pandas indexes the rows of the DataFrame starting from 0, just like NumPy indexes ndarrays.\n\nNow, just like with Pandas Series we can also extract information from DataFrames using attributes. Let's print some information from our `shopping_carts` DataFrame\n\n```python\n# We print some information about shopping_carts\nprint('shopping_carts has shape:', shopping_carts.shape)\nprint('shopping_carts has dimension:', shopping_carts.ndim)\nprint('shopping_carts has a total of:', shopping_carts.size, 'elements')\nprint()\nprint('The data in shopping_carts is:\\n', shopping_carts.values)\nprint()\nprint('The row index in shopping_carts is:', shopping_carts.index)\nprint()\nprint('The column index in shopping_carts is:', shopping_carts.columns)\n```\n\n> shopping_carts has shape: (5, 2)  \nshopping_carts has dimension: 2  \nshopping_carts has a total of: 10 elements\n\n> The data in shopping_carts is:  \n[[ &nbsp;&nbsp; 500.  &nbsp;&nbsp; 245.]  \n[  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 40. &nbsp;&nbsp;&nbsp; nan]  \n[ &nbsp;&nbsp;&nbsp; 110. &nbsp;&nbsp;&nbsp; nan]  \n[  &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 45. &nbsp;&nbsp;&nbsp;&nbsp; 25.]  \n[  &nbsp;&nbsp;&nbsp; nan &nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 55.]]\n\n> The row index in shopping_carts is: Index(['bike', 'book', 'glasses', 'pants', 'watch'], dtype='object')\n\n> The column index in shopping_carts is: Index(['Alice', 'Bob'], dtype='object')\n\nWhen creating the `shopping_carts` DataFrame we passed the entire dictionary to the `pd.DataFrame()` function. However, there might be cases when you are only interested in a subset of the data. Pandas allows us to select which data we want to put into our DataFrame by means of the keywords `columns` and `index`. Let's see some examples:\n\n```python\n# We Create a DataFrame that only has Bob's data\nbob_shopping_cart = pd.DataFrame(items, columns=['Bob'])\n\n# We display bob_shopping_cart\nbob_shopping_cart\n```\n\n>  |    |      **Bob** |\n|----------|:-------------:|:------:|\n|**bike** |245  |\n|**pants** |25  |\n|**watch**|55  |\n\n```python\n# We Create a DataFrame that only has selected items for both Alice and Bob\nsel_shopping_cart = pd.DataFrame(items, index = ['pants', 'book'])\n\n# We display sel_shopping_cart\nsel_shopping_cart\n```\n\n>  |    |     ** Alice**      |  **Bob** |\n|----------|:-------------:|:------:|\n|**pants**|45|25.0  |\n|**book** |40| NaN  |\n\n\n```python\n# We Create a DataFrame that only has selected items for Alice\nalice_sel_shopping_cart = pd.DataFrame(items, index = ['glasses', 'bike'], columns = ['Alice'])\n\n# We display alice_sel_shopping_cart\nalice_sel_shopping_cart\n```\n\n>  |    |      **Alice** |\n|----------|:-------------:|:------:|\n|**glasses** |110  |\n|**bike** |500  |\n\nYou can also manually create DataFrames from a dictionary of lists (arrays). The procedure is the same as before, we start by creating the dictionary and then passing the dictionary to the `pd.DataFrame()` function. In this case, however, all the lists (arrays) in the dictionary must be of the same length. Let' see an example:\n\n```python\n# We create a dictionary of lists (arrays)\ndata = {'Integers' : [1,2,3],\n        'Floats' : [4.5, 8.2, 9.6]}\n\n# We create a DataFrame \ndf = pd.DataFrame(data)\n\n# We display the DataFrame\ndf\n```\n\n>  |    |     ** Floats**      |  **Integers** |\n|----------|:-------------:|:------:|\n|**0** | 4.5 | 1  |\n|**1** |8.2 | 2  |\n|**2**|9.6| 3  |\n\nNotice that since the `data` dictionary we created doesn't have label indices, Pandas automatically uses numerical row indexes when it creates the DataFrame. We can however, put labels to the row index by using the `index` keyword in the `pd.DataFrame()` function. Let's see an example\n\n```python\n# We create a dictionary of lists (arrays)\ndata = {'Integers' : [1,2,3],\n        'Floats' : [4.5, 8.2, 9.6]}\n\n# We create a DataFrame and provide the row index\ndf = pd.DataFrame(data, index = ['label 1', 'label 2', 'label 3'])\n\n# We display the DataFrame\ndf\n```\n\n>  |    |     ** Floats**      |  **Integers** |\n|----------|:-------------:|:------:|\n|**label 1** | 4.5 | 1  |\n|**label 2** |8.2 | 2  |\n|**label 3**|9.6| 3  |\n\nThe last method for manually creating Pandas DataFrames that we want to look at, is by using a list of Python dictionaries. The procedure is the same as before, we start by creating the dictionary and then passing the dictionary to the `pd.DataFrame()` function.\n\n```python\n# We create a list of Python dictionaries\nitems2 = [{'bikes': 20, 'pants': 30, 'watches': 35}, \n          {'watches': 10, 'glasses': 50, 'bikes': 15, 'pants':5}]\n\n# We create a DataFrame \nstore_items = pd.DataFrame(items2)\n\n# We display the DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|\n|**0** |20 | NaN  |30 | 35 |\n|**1** |15 | 50.0 | 5 |10 |\n\nAgain, notice that since the `items2` dictionary we created doesn't have label indices, Pandas automatically uses numerical row indexes when it creates the DataFrame. As before, we can put labels to the row index by using the `index` keyword in the `pd.DataFrame()` function. Let's assume we are going to use this DataFrame to hold the number of items a particular store has in stock. So, we will label the row indices as **store 1** and **store 2**.\n\n```python\n# We create a list of Python dictionaries\nitems2 = [{'bikes': 20, 'pants': 30, 'watches': 35}, \n          {'watches': 10, 'glasses': 50, 'bikes': 15, 'pants':5}]\n\n# We create a DataFrame  and provide the row index\nstore_items = pd.DataFrame(items2, index = ['store 1', 'store 2'])\n\n# We display the DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 35 |\n|**store 2** |15 | 50.0 | 5 |10 |",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 552648,
          "key": "1018da7f-6b26-4b71-9e27-679dfe799e79",
          "title": "Accessing Elements in pandas DataFrames",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "1018da7f-6b26-4b71-9e27-679dfe799e79",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 570075,
              "key": "030e7adf-ab8b-4ee6-abd8-b453896f352f",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Accessing Elements in Pandas DataFrames",
              "instructor_notes": ""
            },
            {
              "id": 569242,
              "key": "6f6c7d65-76ac-4a11-9888-a1d51abe2a4f",
              "title": "Pandas 5 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "lClsJnZn_7w",
                "china_cdn_id": "lClsJnZn_7w.mp4"
              }
            },
            {
              "id": 552649,
              "key": "9e083ac8-395d-4fc9-b2d5-8fbf7417e038",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "We can access elements in Pandas DataFrames in many different ways. In general, we can access rows, columns, or individual elements of the DataFrame by using the row and column labels. We will use the same `store_items` DataFrame created in the previous lesson. Let's see some examples:\n\n```python\n# We print the store_items DataFrame\nprint(store_items)\n\n# We access rows, columns and elements using labels\nprint()\nprint('How many bikes are in each store:\\n', store_items[['bikes']])\nprint()\nprint('How many bikes and pants are in each store:\\n', store_items[['bikes', 'pants']])\nprint()\nprint('What items are in Store 1:\\n', store_items.loc[['store 1']])\nprint()\nprint('How many bikes are in Store 2:', store_items['bikes']['store 2'])\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 35 |\n|**store 2** |15 | 50.0 | 5 |10 |\n\n> How many bikes are in each store:  \n\n>  |    |     ** bikes**      |  \n|----------|:-------------:|\n|**store 1** |20 | \n|**store 2** |15 |\n\n\n> How many bikes and pants are in each store:  \n\n>  |    |     ** bikes**      |  **pants** | \n|----------|:-------------:|:------:|\n|**store 1** |20  |30 |\n|**store 2** |15  | 5 |\n\n\n> What items are in Store 1:  \n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 35 |\n\n> How many bikes are in Store 2: 15\n\nIt is important to know that when accessing individual elements in a DataFrame, as we did in the last example above, the labels should always be provided with the column label first, i.e. in the form `dataframe[column][row]`. For example, when retrieving the number bikes in store 2, we first used the column label **bikes** and then the row label **store 2**. If you provide the row label first you will get an error.\n\nWe can also modify our DataFrames by adding rows or columns. Let's start by learning how to add new columns to our DataFrames. Let's suppose we decided to add **shirts** to the items we have in stock at each store. To do this, we will need to add a new column to our `store_items` DataFrame indicating how many shirts are in each store. Let's do that:\n\n```python\n# We add a new column named shirts to our store_items DataFrame indicating the number of\n# shirts in stock at each store. We will put 15 shirts in store 1 and 2 shirts in store 2\nstore_items['shirts'] = [15,2]\n\n# We display the modified DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **watches** | **shirts** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 35 | 15|\n|**store 2** |15 | 50.0 | 5 |10 | 2|\n\nWe can see that when we add a new column, the new column is added at the end of our DataFrame.\n\nWe can also add new columns to our DataFrame by using arithmetic operations between other columns in our DataFrame. Let's see an example:\n\n```python\n# We make a new column called suits by adding the number of shirts and pants\nstore_items['suits'] = store_items['pants'] + store_items['shirts']\n\n# We display the modified DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **watches** | **shirts** | **suits** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 35 | 15| 45 |\n|**store 2** |15 | 50.0 | 5 |10 | 2| 7 |\n\nSuppose now, that you opened a new store and you need to add the number of items in stock of that new store into your DataFrame. We can do this by adding a new row to the `store_items` Dataframe. To add rows to our DataFrame we first have to create a new Dataframe and then append it to the original DataFrame. Let's see how this works\n\n```python\n# We create a dictionary from a list of Python dictionaries that will number of items at the new store\nnew_items = [{'bikes': 20, 'pants': 30, 'watches': 35, 'glasses': 4}]\n\n# We create new DataFrame with the new_items and provide and index labeled store 3\nnew_store = pd.DataFrame(new_items, index = ['store 3'])\n\n# We display the items at the new store\nnew_store\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **watches** | \n|----------|:-------------:|:------:|:------:|:------:|\n|**store 3** |20 | 4  |30 | 35 | \n\n\nWe now add this row to our `store_items` DataFrame by using the `.append()` method.\n\n```python\n# We append store 3 to our store_items DataFrame\nstore_items = store_items.append(new_store)\n\n# We display the modified DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 15.0| 45.0| 35 |\n|**store 2** |15 | 50.0 | 5 |2.0 | 7.0| 10 |\n|**store 3** |20 | 4.0  |30 | NaN | NaN | 35 | \n\nNotice that by appending a new row to the DataFrame, the columns have been put in alphabetical order.\n\nWe can also add new columns of our DataFrame by using only data from particular rows in particular columns. For example, suppose that you want to stock stores 2 and 3 with **new watches** and you want the quantity of the **new watches** to be the same as the watches already in stock for those stores. Let's see how we can do this\n\n```python\n# We add a new column using data from particular rows in the watches column\nstore_items['new watches'] = store_items['watches'][1:]\n\n# We display the modified DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **suits** | **watches** | **new watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 15.0| 45.0| 35 | NaN |\n|**store 2** |15 | 50.0 | 5 |2.0 | 7.0| 10 | 10.0 |\n|**store 3** |20 | 4.0  |30 | NaN | NaN | 35 | 35.0 |\n\nIt is also possible, to insert new columns into the DataFrames anywhere we want. The `dataframe.insert(loc,label,data)` method allows us to insert a new column in the `dataframe` at location `loc`, with the given column `label`, and given `data`. Let's add new column named **shoes** right before the **suits** column. Since **suits** has numerical index value 4 then we will use this value as `loc`. Let's see how this works:\n\n```python\n# We insert a new column with label shoes right before the column with numerical index 4\nstore_items.insert(4, 'shoes', [8,5,0])\n\n# we display the modified DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** | **new watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 15.0| 8 | 45.0| 35 | NaN |\n|**store 2** |15 | 50.0 | 5 |2.0 | 5 |7.0| 10 | 10.0 |\n|**store 3** |20 | 4.0  |30 | NaN | 0 | NaN | 35 | 35.0 |\n\nJust as we can add rows and columns we can also delete them. To delete rows and columns from our DataFrame we will use the `.pop()` and `.drop()` methods. The `.pop()` method only allows us to delete columns, while the `.drop()` method can be used to delete both rows and columns by use of the `axis` keyword. Let's see some examples\n\n```python\n# We remove the new watches column\nstore_items.pop('new watches')\n\n# we display the modified DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 15.0| 8 | 45.0| 35 | \n|**store 2** |15 | 50.0 | 5 |2.0 | 5 |7.0| 10 | \n|**store 3** |20 | 4.0  |30 | NaN | 0 | NaN | 35 | \n\n\n```python\n# We remove the watches and shoes columns\nstore_items = store_items.drop(['watches', 'shoes'], axis = 1)\n\n# we display the modified DataFrame\nstore_items\n```\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **suits** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 15.0| 45.0| \n|**store 2** |15 | 50.0 | 5 |2.0 | 7.0|\n|**store 3** |20 | 4.0  |30 | NaN |NaN | \n\n```python\n# We remove the store 2 and store 1 rows\nstore_items = store_items.drop(['store 2', 'store 1'], axis = 0)\n\n# we display the modified DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **suits** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|\n|**store 3** |20 | 4.0  |30 | NaN |NaN | \n\nSometimes we might need to change the row and column labels. Let's change the **bikes** column label to **hats** using the `.rename()` method\n\n```python\n# We change the column label bikes to hats\nstore_items = store_items.rename(columns = {'bikes': 'hats'})\n\n# we display the modified DataFrame\nstore_items\n```\n\n>  |    |     ** hats**      |  **glasses** | **pants** | **shirts** | **suits** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|\n|**store 3** |20 | 4.0  |30 | NaN |NaN | \n\nNow let's change the row label using the `.rename()` method again.\n\n```python\n# We change the row label from store 3 to last store\nstore_items = store_items.rename(index = {'store 3': 'last store'})\n\n# we display the modified DataFrame\nstore_items\n```\n\n>  |    |     ** hats**      |  **glasses** | **pants** | **shirts** | **suits** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|\n|**last store** |20 | 4.0  |30 | NaN |NaN | \n\nYou can also change the index to be one of the columns in the DataFrame.\n\n```python\n# We change the row index to be the data in the pants column\nstore_items = store_items.set_index('pants')\n\n# we display the modified DataFrame\nstore_items\n```\n\n>  |  **pants**   |     ** hats**      |  **glasses** | **shirts** | **suits** |\n|----------|:-------------:|:------:|:------:|:------:|\n|**30** |20 | 4.0  | NaN |NaN | ",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 552650,
          "key": "9463bfe0-5181-4a87-8635-bb24a01ec246",
          "title": "Dealing with NaN",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "9463bfe0-5181-4a87-8635-bb24a01ec246",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 570077,
              "key": "1f02338d-cb26-45f1-a935-fa14ef887ed0",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Dealing with NaN",
              "instructor_notes": ""
            },
            {
              "id": 569293,
              "key": "7ad67a78-c72c-4dd2-989b-0be4bd2da050",
              "title": "Pandas 6 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "GS1kj04XQcM",
                "china_cdn_id": "GS1kj04XQcM.mp4"
              }
            },
            {
              "id": 552652,
              "key": "52023cc4-d512-4355-b391-2f50e9e68a30",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "As mentioned earlier, before we can begin training our learning algorithms with large datasets, we usually need to clean the data first. This means we need to have a method for detecting and correcting errors in our data. While any given dataset can have many types of bad data, such as outliers or incorrect values, the type of bad data we encounter almost always is missing values. As we saw earlier, Pandas assigns `NaN` values to missing data. In this lesson we will learn how to detect and deal with `NaN` values.\n\nWe will begin by creating a DataFrame with some `NaN` values in it.\n\n```python\n# We create a list of Python dictionaries\nitems2 = [{'bikes': 20, 'pants': 30, 'watches': 35, 'shirts': 15, 'shoes':8, 'suits':45},\n{'watches': 10, 'glasses': 50, 'bikes': 15, 'pants':5, 'shirts': 2, 'shoes':5, 'suits':7},\n{'bikes': 20, 'pants': 30, 'watches': 35, 'glasses': 4, 'shoes':10}]\n\n# We create a DataFrame  and provide the row index\nstore_items = pd.DataFrame(items2, index = ['store 1', 'store 2', 'store 3'])\n\n# We display the DataFrame\nstore_items\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 15.0| 8 | 45.0| 35 |\n|**store 2** |15 | 50.0 | 5 |2.0 | 5 | 7.0| 10 |\n|**store 3** |20 | 4.0  |30 | NaN | 10 |NaN | 35 | \n\nWe can clearly see that the DataFrame we created has 3 `NaN` values: one in store 1 and two in store 3. However, in cases where we load very large datasets into a DataFrame, possibly with millions of items, the number of `NaN` values is not easily visualized. For these cases, we can use a combination of methods to count the number of `NaN` values in our data. The following example combines the `.isnull()` and the `sum()` methods to count the number of `NaN` values in our DataFrame\n\n```python\n# We count the number of NaN values in store_items\nx =  store_items.isnull().sum().sum()\n\n# We print x\nprint('Number of NaN values in our DataFrame:', x)\n```\n\n> Number of NaN values in our DataFrame: 3\n\nIn the above example, the `.isnull()` method returns a *Boolean* DataFrame of the same size as `store_items` and indicates with `True` the elements that have `NaN` values and with `False` the elements that are not. Let's see an example:\n\n```python\nstore_items.isnull()\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |False | True  |False | False| False | False| False |\n|**store 2** |False | False | False |False | False | False| False |\n|**store 3** |False | False  |False | True | False |True | False | \n\nIn Pandas, logical `True` values have numerical value 1 and logical `False` values have numerical value 0. Therefore, we can count the number of `NaN` values by counting the number of logical `True` values. In order to count the total number of logical `True` values we use the `.sum()` method twice. We have to use it twice because the first sum returns a Pandas Series with the sums of logical `True` values along columns, as we see below:\n\n```python\nstore_items.isnull().sum()\n```\n\n> bikes &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0  \nglasses &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1  \npants &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0  \nshirts &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1  \nshoes &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 0  \nsuits &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 1  \nwatches &nbsp;&nbsp;&nbsp;&nbsp; 0  \ndtype: int64\n\nThe second sum will then add up the 1s in the above Pandas Series.\n\nInstead of counting the number of `NaN` values we can also do the opposite, we can count the number of *non-NaN* values. We can do this by using the `.count()` method as shown below:\n\n```python\n# We print the number of non-NaN values in our DataFrame\nprint()\nprint('Number of non-NaN values in the columns of our DataFrame:\\n', store_items.count())\n```\n\n> Number of non-NaN values in the columns of our DataFrame:  \nbikes &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3  \nglasses &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2  \npants &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3  \nshirts &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2  \nshoes &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3  \nsuits &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2  \nwatches &nbsp;&nbsp;&nbsp;&nbsp; 3  \ndtype: int64\n\nNow that we learned how to know if our dataset has any `NaN` values in it, the next step is to decide what to do with them. In general we have two options, we can either *delete* or *replace* the `NaN` values. In the following examples we will show you how to do both.\n\nWe will start by learning how to eliminate rows or columns from our DataFrame that contain any `NaN` values. The `.dropna(axis)` method eliminates any *rows* with `NaN` values when `axis = 0` is used and will eliminate any *columns* with `NaN` values when `axis = 1` is used. Let's see some examples\n\n```python\n# We drop any rows with NaN values\nstore_items.dropna(axis = 0)\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 2** |15 | 50.0 | 5 |2.0 | 5 | 7.0| 10 |\n\n```python\n# We drop any columns with NaN values\nstore_items.dropna(axis = 1)\n```\n\n>  |    |     ** bikes**     |  **pants** |  **shoes** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | 30 | 8 |  35 |\n|**store 2** |15 |  5 | 5 |  10 |\n|**store 3** |20 | 30 |  10 | 35 | \n\nNotice that the `.dropna()` method eliminates (drops) the rows or columns with `NaN` values out of place. This means that the original DataFrame is not modified. You can always remove the desired rows or columns in place by setting the keyword `inplace = True` inside the `dropna()` function.\n\nNow, instead of eliminating `NaN` values, we can replace them with suitable values. We could choose for example to replace all `NaN` values with the value 0. We can do this by using the `.fillna()` method as shown below.\n\n```python\n# We replace all NaN values with 0\nstore_items.fillna(0)\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | 0.0  |30 | 15.0| 8 | 45.0| 35 |\n|**store 2** |15 | 50.0 | 5 |2.0 | 5 | 7.0| 10 |\n|**store 3** |20 | 4.0  |30 |0.0 | 10 |0.0 | 35 | \n\nWe can also use the `.fillna()` method to replace `NaN` values with previous values in the DataFrame, this is known as *forward filling*. When replacing `NaN` values with forward filling, we can use previous values taken from columns or rows. The `.fillna(method = 'ffill', axis)` will use the forward filling (`ffill`) method to replace `NaN` values using the previous known value along the given `axis`. Let's see some examples:\n\n```python\n# We replace NaN values with the previous value in the column\nstore_items.fillna(method = 'ffill', axis = 0)\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 15.0| 8 | 45.0| 35 |\n|**store 2** |15 | 50.0 | 5 |2.0 | 5 | 7.0| 10 |\n|**store 3** |20 | 4.0  |30 | 2.0 | 10 |7.0 | 35 | \n\nNotice that the two `NaN` values in **store 3** have been replaced with previous values in their columns. However, notice that the `NaN` value in **store 1** didn't get replaced. That's because there are no previous values in this column, since the `NaN` value is the first value in that column. However, if we do forward fill using the previous row values, this won't happen. Let's take a look:\n\n```python\n# We replace NaN values with the previous value in the row\nstore_items.fillna(method = 'ffill', axis = 1)\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20.0 | 20.0  |30.0 | 15.0| 8.0 | 45.0| 35.0 |\n|**store 2** |15.0 | 50.0 | 5.0 |2.0 | 5.0 | 7.0| 10.0 |\n|**store 3** |20.0 | 4.0  |30.0 | 30.0 | 10.0 |10.0 | 35.0 | \n\nWe see that in this case all the `NaN` values have been replaced with the previous row values.\n\nSimilarly, you can choose to replace the `NaN` values with the values that go after them in the DataFrame, this is known as *backward filling*. The `.fillna(method = 'backfill', axis)` will use the backward filling (`backfill`) method to replace `NaN` values using the next known value along the given `axis`. Just like with forward filling we can choose to use row or column values. Let's see some examples:\n\n```python\n# We replace NaN values with the next value in the column\nstore_items.fillna(method = 'backfill', axis = 0)\n```\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | 50.0  |30 | 15.0| 8 | 45.0| 35 |\n|**store 2** |15 | 50.0 | 5 |2.0 | 5 | 7.0| 10 |\n|**store 3** |20 | 4.0  |30 | NaN | 10 |NaN | 35 | \n\nNotice that the `NaN` value in **store 1** has been replaced with the next value in its column. However, notice that the two `NaN` values in **store 3** didn't get replaced. That's because there are no next values in these columns, since these `NaN` values are the last values in those columns. However, if we do backward fill using the next row values, this won't happen. Let's take a look:\n\n```python\n# We replace NaN values with the next value in the row\nstore_items.fillna(method = 'backfill', axis = 1)\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20.0 | 30.0 |30.0 | 15.0| 8.0 | 45.0| 35.0 |\n|**store 2** |15.0 | 50.0 | 5.0 |2.0 | 5.0 | 7.0| 10.0 |\n|**store 3** |20.0 | 4.0  |30.0 | 10.0 | 10.0 |35.0 | 35.0 | \n\nNotice that the `.fillna()` method replaces (fills) the `NaN` values out of place. This means that the original DataFrame is not modified. You can always replace the `NaN` values in place by setting the keyword `inplace = True` inside the `fillna()` function.\n\nWe can also choose to replace `NaN` values by using different interpolation methods. For example, the `.interpolate(method = 'linear', axis)` method will use `linear` interpolation to replace `NaN` values using the values along the given `axis`. Let's see some examples:\n\n```python\n# We replace NaN values by using linear interpolation using column values\nstore_items.interpolate(method = 'linear', axis = 0)\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20 | NaN  |30 | 15.0| 8 | 45.0| 35 |\n|**store 2** |15 | 50.0 | 5 |2.0 | 5 | 7.0| 10 |\n|**store 3** |20 | 4.0  |30 | 2.0 | 10 |7.0| 35 | \n\nNotice that the two `NaN` values in **store 3** have been replaced with linear interpolated values. However, notice that the `NaN` value in **store 1** didn't get replaced. That's because the `NaN` value is the first value in that column, and since there is no data before it, the interpolation function can't calculate a value.  Now, let's interpolate using row values instead:\n\n```python\n# We replace NaN values by using linear interpolation using row values\nstore_items.interpolate(method = 'linear', axis = 1)\n```\n\n>  |    |     ** bikes**      |  **glasses** | **pants** | **shirts** | **shoes** | **suits** | **watches** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**store 1** |20.0 | 25.0  |30.0 | 15.0| 8.0 | 45.0| 35.0 |\n|**store 2** |15.0 | 50.0 | 5.0 |2.0 | 5.0 | 7.0| 10.0 |\n|**store 3** |20.0 | 4.0  |30.0 | 20.0 | 10.0 |22.5 | 35.0 | \n\nJust as with the other methods we saw, the `.interpolate()` method replaces `NaN` values out of place.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 556114,
          "key": "869394af-48c8-416d-97db-d0709f52d82b",
          "title": "Manipulate a DataFrame",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "869394af-48c8-416d-97db-d0709f52d82b",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 556115,
              "key": "bfe151fa-2c5d-4b23-bc83-2f456a5f9d5a",
              "title": "",
              "semantic_type": "QuizAtom",
              "is_public": true,
              "instructor_notes": "From the DataFrame above you can now pick all the books that had a rating of 5.  You can do this in just one line of code. Try to do it yourself first, you'll find the answer below:\n\n`best_rated = book_ratings[(book_ratings == 5).any(axis = 1)]['Book Title'].values`\n\nThe code above returns a NumPy ndarray that only contains the names of the books that had a rating of 5.",
              "user_state": {
                "node_key": "bfe151fa-2c5d-4b23-bc83-2f456a5f9d5a",
                "completed_at": null,
                "last_viewed_at": null,
                "unstructured": null
              },
              "instruction": null,
              "question": {
                "title": "",
                "semantic_type": "ProgrammingQuestion",
                "evaluation_id": "6488286621728768",
                "initial_code_files": [
                  {
                    "text": "import pandas as pd\r\nimport numpy as np\r\n\r\n# Since we will be working with ratings, we will set the precision of our \r\n# dataframes to one decimal place.\r\npd.set_option('precision', 1)\r\n\r\n# Create a Pandas DataFrame that contains the ratings some users have given to a\r\n# series of books. The ratings given are in the range from 1 to 5, with 5 being\r\n# the best score. The names of the books, the authors, and the ratings of each user\r\n# are given below:\r\n\r\nbooks = pd.Series(data = ['Great Expectations', 'Of Mice and Men', 'Romeo and Juliet', 'The Time Machine', 'Alice in Wonderland' ])\r\nauthors = pd.Series(data = ['Charles Dickens', 'John Steinbeck', 'William Shakespeare', ' H. G. Wells', 'Lewis Carroll' ])\r\n\r\nuser_1 = pd.Series(data = [3.2, np.nan ,2.5])\r\nuser_2 = pd.Series(data = [5., 1.3, 4.0, 3.8])\r\nuser_3 = pd.Series(data = [2.0, 2.3, np.nan, 4])\r\nuser_4 = pd.Series(data = [4, 3.5, 4, 5, 4.2])\r\n\r\n# Users that have np.nan values means that the user has not yet rated that book.\r\n# Use the data above to create a Pandas DataFrame that has the following column\r\n# labels: 'Author', 'Book Title', 'User 1', 'User 2', 'User 3', 'User 4'. Let Pandas\r\n# automatically assign numerical row indices to the DataFrame. \r\n\r\n# Create a dictionary with the data given above\r\ndat = \r\n\r\n# Use the dictionary to create a Pandas DataFrame\r\nbook_ratings = \r\n\r\n# If you created the dictionary correctly you should have a Pandas DataFrame\r\n# that has column labels: 'Author', 'Book Title', 'User 1', 'User 2', 'User 3',\r\n# 'User 4' and row indices 0 through 4.\r\n\r\n# Now replace all the NaN values in your DataFrame with the average rating in\r\n# each column. Replace the NaN values in place. HINT: you can use the fillna()\r\n# function with the keyword inplace = True, to do this. Write your code below:\r\n\r\n\r\n\r\n",
                    "name": "book_r.py"
                  },
                  {
                    "text": "import pandas as pd\r\nimport numpy as np\r\n\r\npd.set_option('precision', 1)\r\n\r\nbooks = pd.Series(data = ['Great Expectations', 'Of Mice and Men', 'Romeo and Juliet', 'The Time Machine', 'Alice in Wonderland' ])\r\nauthors = pd.Series(data = ['Charles Dickens', 'John Steinbeck', 'William Shakespeare', ' H. G. Wells', 'Lewis Carroll' ])\r\nuser_1 = pd.Series(data = [3.2, np.nan ,2.5])\r\nuser_2 = pd.Series(data = [5., 1.3, 4.0, 3.8])\r\nuser_3 = pd.Series(data = [2.0, 2.3, np.nan, 4])\r\nuser_4 = pd.Series(data = [4, 3.5, 4, 5, 4.2])\r\n\r\ndat = {'Book Title' : books,\r\n       'Author' : authors,\r\n       'User 1' : user_1,\r\n       'User 2' : user_2,\r\n       'User 3' : user_3,\r\n       'User 4' : user_4}\r\n\r\nbook_ratings = pd.DataFrame(dat)\r\n\r\nbook_ratings.fillna(book_ratings.mean(), inplace = True)\r\n",
                    "name": "solution.py"
                  }
                ]
              },
              "answer": null
            }
          ]
        },
        {
          "id": 552653,
          "key": "5129486a-40be-4660-b91f-f42522efdd5b",
          "title": "Loading Data into a pandas DataFrame",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "5129486a-40be-4660-b91f-f42522efdd5b",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": {
            "files": [
              {
                "name": "GOOG.csv",
                "uri": "https://video.udacity-data.com/topher/2018/May/5b08e099_goog-1/goog-1.csv"
              }
            ],
            "google_plus_link": null,
            "career_resource_center_link": null,
            "coaching_appointments_link": null,
            "office_hours_link": null,
            "aws_provisioning_link": null
          },
          "atoms": [
            {
              "id": 570078,
              "key": "b2a5fd09-0acf-44e6-b501-b1afb0d4555e",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Loading Data into a pandas DataFrame",
              "instructor_notes": ""
            },
            {
              "id": 569294,
              "key": "5525ff9b-cd5e-43fe-9f0d-d6d9757c1a50",
              "title": "Pandas 7 V1",
              "semantic_type": "VideoAtom",
              "is_public": true,
              "instructor_notes": "",
              "video": {
                "youtube_id": "ruTYp-twXO0",
                "china_cdn_id": "ruTYp-twXO0.mp4"
              }
            },
            {
              "id": 552654,
              "key": "d8a5c649-cc7b-4eda-900c-80e0199ba734",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "In machine learning you will most likely use databases from many sources to train your learning algorithms. Pandas allows us to load databases of different formats into DataFrames. One of the most popular data formats used to store databases is csv. CSV stands for *Comma Separated Values* and offers a simple format to store data. We can load CSV files into Pandas DataFrames using the `pd.read_csv()` function. Let's load Google stock data into a Pandas DataFrame. The GOOG.csv file contains Google stock data from 8/19/2004 till 10/13/2017 taken from Yahoo Finance.\n\n```python\n# We load Google stock data in a DataFrame\nGoogle_stock = pd.read_csv('./GOOG.csv')\n\n# We print some information about Google_stock\nprint('Google_stock is of type:', type(Google_stock))\nprint('Google_stock has shape:', Google_stock.shape)\n```\n\n> Google_stock is of type: class 'pandas.core.frame.DataFrame'  \nGoogle_stock has shape: (3313, 7)\n\nWe see that we have loaded the GOOG.csv file into a Pandas DataFrame and it consists of 3,313 rows and 7 columns. Now let's look at the stock data\n\n```python\nGoogle_stock\n```\n\n> |   |  **Date** | **Open** |\t**High** | **Low** | **Close** | \t**Adj Close** | **Volume** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**0** | 2004-08-19 | 49.676899 | 51.693783 | 47.669952 | 49.845802 | 49.845802 | 44994500 |\n|**1** | 2004-08-20 | 50.178635 | 54.187561 | 49.925285 | 53.805050 | 53.805050 | 23005800 |  \n|**2** | 2004-08-23 | 55.017166 | 56.373344 | 54.172661 | 54.346527 | 54.346527 | 18393200 |\n|... \t... |\n|**3311** | 2017-10-12 | 987.450012 | 994.119995 | 985.000000 | 987.830017 | 987.830017 | 1262400 |  \n|**3312** | 2017-10-13 | 992.000000 | 997.210022 | 989.000000 | 989.679993 | 989.679993 | 1157700  |\n\n> 3313 rows × 7 columns\n\nWe see that it is quite a large dataset and that Pandas has automatically assigned numerical row indices to the DataFrame. Pandas also used the labels that appear in the data in the CSV file to assign the column labels.\n\nWhen dealing with large datasets like this one, it is often useful just to take a look at the first few rows of data instead of the whole dataset. We can take a look at the first 5 rows of data using the `.head()` method, as shown below\n\n```python\nGoogle_stock.head()\n```\n\n> |   |  **Date** | **Open** |\t**High** | **Low** | **Close** | \t**Adj Close** | **Volume** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**0** | 2004-08-19 | 49.676899 | 51.693783 | 47.669952 | 49.845802 | 49.845802 | 44994500 |\n|**1** | 2004-08-20 | 50.178635 | 54.187561 | 49.925285 | 53.805050 | 53.805050 | 23005800 |  \n|**2** | 2004-08-23 | 55.017166 | 56.373344 | 54.172661 | 54.346527 | 54.346527 | 18393200 |\n|**3** | 2004-08-24 | 55.260582 | 55.439419 | 51.450363 | 52.096165 | 52.096165 | 15361800 | \n|**4** | 2004-08-25 | 52.140873 | 53.651051 | 51.604362 | 52.657513 | 52.657513 | 9257400 |\n\nWe can also take a look at the last 5 rows of data by using the `.tail()` method:\n\n```python\nGoogle_stock.tail()\n```\n\n> |   |  **Date** | **Open** |\t**High** | **Low** | **Close** | \t**Adj Close** | **Volume** |\n|----------|:-------------:|:------:|:------:|:------:|:------:|:------:|:------:|\n|**3308** | 2017-10-09 | 980.000000 | 985.424988 | 976.109985 | 977.000000 | 977.000000 | 891400 |  \n|**3309** | 2017-10-10 | 980.000000 | 981.570007 | 966.080017 | 972.599976 | 972.599976 | 968400 |  \n|**3310** | 2017-10-11 | 973.719971 | 990.710022 | 972.250000 | 989.250000 | 989.250000 | 1693300  | \n|**3311** | 2017-10-12 | 987.450012 | 994.119995 | 985.000000 | 987.830017 | 987.830017 | 1262400 |  \n|**3312** | 2017-10-13 | 992.000000 | 997.210022 | 989.000000 | 989.679993 | 989.679993 | 1157700  |\n\nWe can also optionally use `.head(N)` or `.tail(N)` to display the first and last `N` rows of data, respectively.\n\nLet's do a quick check to see whether we have any `NaN` values in our dataset. To do this, we will use the `.isnull()` method followed by the `.any()` method to check whether any of the columns contain `NaN` values.\n\n```python\nGoogle_stock.isnull().any()\n```\n\n> Date &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; False  \nOpen &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; False  \nHigh &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; False  \nLow &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; False  \nClose &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; False  \nAdj Close &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; False  \nVolume &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; False  \ndtype: bool\n\nWe see that we have no `NaN` values.\n\nWhen dealing with large datasets, it is often useful to get statistical information from them. Pandas provides the `.describe()` method to get descriptive statistics on each column of the DataFrame. Let's see how this works:\n\n```python\n# We get descriptive statistics on our stock data\nGoogle_stock.describe()\n```\n\n> |   |   **Open** |\t**High** | **Low** | **Close** | \t**Adj Close** | **Volume** |\n|----------|:------:|:------:|:------:|:------:|:------:|:------:|\n|**count** | 3313.000000 | 3313.000000 | 3313.000000 | 3313.000000 | 3313.000000 | 3.313000e+03 |  \n|**mean** | 380.186092 | 383.493740 | 376.519309 | 380.072458 | 380.072458 | 8.038476e+06 |  \n|**std** | 223.818650 | 224.974534 | 222.473232 | 223.853780 | 223.853780 | 8.399521e+06 |  \n|**min** | 49.274517 | 50.541279 | 47.669952 | 49.681866 | 49.681866 | 7.900000e+03 | \n|**25%** | 226.556473 | 228.394516 | 224.003082 | 226.407440 | 226.407440 | 2.584900e+06 |\n|**50%** | 293.312286 | 295.433502 | 289.929291 | 293.029114 | 293.029114 | 5.281300e+06 |  \n|**75%** | 536.650024 | 540.000000 | 532.409973 | 536.690002 | 536.690002 | 1.065370e+07 | \n|**max** | 992.000000 | 997.210022 | 989.000000 | 989.679993 | 989.679993 | 8.276810e+07 | \n\nIf desired, we can apply the `.describe()` method on a single column as shown below:\n\n```python\n# We get descriptive statistics on a single column of our DataFrame\nGoogle_stock['Adj Close'].describe()\n```\n\n> count &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3313.000000  \nmean &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 380.072458  \nstd &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 223.853780  \nmin &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 49.681866  \n25% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 226.407440  \n50% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 293.029114  \n75% &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 536.690002  \nmax &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 989.679993  \nName: Adj Close, dtype: float64\n\nSimilarly, you can also look at one statistic by using one of the many statistical functions Pandas provides. Let's look at some examples:\n\n```python\n# We print information about our DataFrame  \nprint()\nprint('Maximum values of each column:\\n', Google_stock.max())\nprint()\nprint('Minimum Close value:', Google_stock['Close'].min())\nprint()\nprint('Average value of each column:\\n', Google_stock.mean())\n```\n\n> Maximum values of each column:  \nDate &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 2017-10-13   \nOpen &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 992  \nHigh &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 997.21  \nLow &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 989  \nClose &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 989.68  \nAdj Close &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 989.68  \nVolume &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 82768100  \ndtype: object\n\n> Minimum Close value: 49.681866\n\n> Average value of each column:  \nOpen &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.801861e+02  \nHigh &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.834937e+02  \nLow &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.765193e+02  \nClose &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 3.800725e+02  \nAdj Close &nbsp;&nbsp;&nbsp; 3.800725e+02  \nVolume &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 8.038476e+06  \ndtype: float64\n\nAnother important statistical measure is data correlation. Data correlation can tell us, for example, if the data in different columns are correlated. We can use the `.corr()` method to get the correlation between different columns, as shown below:\n\n```python\n# We display the correlation between columns\nGoogle_stock.corr()\n```\n\n> |   |   **Open** |\t**High** | **Low** | **Close** | \t**Adj Close** | **Volume** |\n|----------|:------:|:------:|:------:|:------:|:------:|:------:|\n|**Open** | 1.000000 | 0.999904 | 0.999845 | 0.999745 | 0.999745 | -0.564258 |\n|**High** | 0.999904 | 1.000000 | 0.999834 | 0.999868 | 0.999868 | -0.562749 |  \n|**Low** | 0.999845 | 0.999834 | 1.000000 | 0.999899 | 0.999899 | -0.567007 | \n|**Close** | 0.999745 | 0.999868 | 0.999899 | 1.000000 | 1.000000 | -0.564967 |   \n|**Adj Close** | 0.999745 | 0.999868 | 0.999899 | 1.000000 | 1.000000 | -0.564967 |   \n|**Volume** | -0.564258 | -0.562749 | -0.567007 | -0.564967 | -0.564967 | 1.000000 | \n\nA correlation value of 1 tells us there is a high correlation and a correlation of 0 tells us that the data is not correlated at all.\n\nWe will end this Introduction to Pandas by taking a look at the `.groupby()` method. The `.groupby()` method allows us to group data in different ways. Let's see how we can group data to get different types of information. For the next examples we are going to load fake data about a fictitious company.\n\n```python\n# We load fake Company data in a DataFrame\ndata = pd.read_csv('./fake_company.csv')\n\ndata\n```\n\n> |   |   **Year** | **Name** | **Department** | **Age** | **Salary** | \n|----------|:------:|:------:|:------:|:------:|:------:|\n|**0** | 1990 | Alice | HR | 25 | 50000 |  \n|**1** | 1990 | Bob | RD | 30 | 48000 | \n|**2** | 1990 | Charlie | Admin | 45 | 55000 | \n|**3** | 1991 | Alice | HR | 26 | 52000 | \n|**4** | 1991 | Bob | RD | 31 | 50000 |  \n|**5** | 1991 | Charlie | Admin | 46 | 60000 |   \n|**6** | 1992 | Alice | Admin | 27 | 60000 | \n|**7** | 1992 | Bob | RD | 32 | 52000 | \n|**8** | 1992 | Charlie | Admin | 28 | 62000|\n\nWe see that the data contains information for the year 1990 through 1992. For each year we see name of the employees, the department they work for, their age, and their annual salary. Now, let's use the `.groupby()` method to get information.\n\nLet's calculate how much money the company spent in salaries each year. To do this, we will group the data by *Year* using the `.groupby()` method and then we will add up the salaries of all the employees by using the `.sum()` method.\n\n```python\n# We display the total amount of money spent in salaries each year\ndata.groupby(['Year'])['Salary'].sum()\n```\n\n> Year  \n1990 &nbsp;&nbsp;&nbsp; 153000  \n1991 &nbsp;&nbsp;&nbsp; 162000  \n1992 &nbsp;&nbsp;&nbsp; 174000  \nName: Salary, dtype: int64\n\nWe see that the company spent a total of 153,000 dollars in 1990, 162,000 in 1991, and 174,000 in 1992.\n\nNow, let's suppose I want to know what was the average salary for each year. In this case, we will group the data by *Year* using the `.groupby()` method, just as we did before, and then we use the `.mean()` method to get the average salary. Let's see how this works\n\n```python\n# We display the average salary per year\ndata.groupby(['Year'])['Salary'].mean()\n```\n\n> Year  \n1990 &nbsp;&nbsp;&nbsp; 51000  \n1991 &nbsp;&nbsp;&nbsp; 54000  \n1992 &nbsp;&nbsp;&nbsp; 58000  \nName: Salary, dtype: int64\n\nWe see that the average salary in 1990 was 51,000 dollars, 54,000 in 1991, and 58,000 in 1992.\n\nNow let's see how much did each employee get paid in those three years. In this case, we will group the data by *Name* using the `.groupby()` method and then we will add up the salaries for each year. Let's see the result\n\n```python\n# We display the total salary each employee received in all the years they worked for the company\ndata.groupby(['Name'])['Salary'].sum()\n```\n> Name  \nAlice &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 162000  \nBob &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 150000  \nCharlie &nbsp;&nbsp;&nbsp; 177000  \nName: Salary, dtype: int64\n\nWe see that Alice received a total of 162,000 dollars in the three years she worked for the company, Bob received 150,000, and Charlie received 177,000.\n\nNow let's see what was the salary distribution per department per year. In this case we will group the data by *Year* and by *Department* using the `.groupby()` method and then we will add up the salaries for each department. Let's see the result\n\n```python\n# We display the salary distribution per department per year.\ndata.groupby(['Year', 'Department'])['Salary'].sum()\n```\n\n> Year &nbsp;&nbsp;&nbsp; Department  \n1990 &nbsp;&nbsp; Admin &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 55000  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; HR &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 50000  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RD &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 48000  \n1991 &nbsp;&nbsp; Admin &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 60000  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; HR &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 52000  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RD &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 50000  \n1992 &nbsp;&nbsp; Admin &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 122000  \n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; RD &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; 52000  \nName: Salary, dtype: int64\n\nWe see that in 1990 the Admin department paid 55,000 dollars in salaries,the HR department paid 50,000, and the RD department 48,0000. While in 1992 the Admin department paid 122,000 dollars in salaries and the RD department paid 52,000.",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 552975,
          "key": "e6b14f11-0b6f-47e0-8002-b3c7df08eb55",
          "title": "Getting Set Up for the Mini-Project",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "e6b14f11-0b6f-47e0-8002-b3c7df08eb55",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 552976,
              "key": "ec233b68-2646-4c49-9a07-98dbd1b312bc",
              "title": null,
              "semantic_type": "TextAtom",
              "is_public": true,
              "text": "# Getting Set Up for the Mini-Project\n\nIf you are not running the Mini-Project in the *Workspace*, to complete the following Mini-Project you will need to have  **Anaconda** installed on your computer and you will need to download the three CSV files with the Google, Apple, and Amazon stock data. These data files can be found in the Mini-Project Workspace and can be downloaded to your computer. If you don't already have Anaconda installed on your computer, please refer to the Anaconda section to get clear instructions on how to install Anaconda on your PC or Mac.\n\nIf you'd like to work through the notebooks on your own machine or otherwise outside the classroom, you can find the code in this [GitHub repo](https://github.com/udacity/AIPND).\n",
              "instructor_notes": ""
            }
          ]
        },
        {
          "id": 560544,
          "key": "ecca7776-29fe-48a9-864c-33a447f3f47a",
          "title": "Mini-Project: Statistics From Stock Data",
          "semantic_type": "Concept",
          "is_public": true,
          "user_state": {
            "node_key": "ecca7776-29fe-48a9-864c-33a447f3f47a",
            "completed_at": null,
            "last_viewed_at": null,
            "unstructured": null
          },
          "resources": null,
          "atoms": [
            {
              "id": 587329,
              "key": "2944ec0f-949d-459e-b309-2e5430a121e5",
              "title": null,
              "semantic_type": "WorkspaceAtom",
              "is_public": true,
              "workspace_id": "viewc0bd3e92",
              "pool_id": "jupyter",
              "view_id": "c0bd3e92-326c-46c0-b102-e40403ceb70c",
              "gpu_capable": false,
              "configuration": {
                "id": "reserved",
                "blueprint": {
                  "conf": {
                    "disk": null,
                    "ports": [],
                    "allowSubmit": false,
                    "defaultPath": "/notebooks/Statistics from Stock Data.ipynb"
                  },
                  "kind": "jupyter"
                },
                "workspaceId": "reserved"
              },
              "starter_files": null
            }
          ]
        }
      ]
    }
  },
  "_deprecated": [
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    },
    {
      "name": "non_google_url",
      "reason": "(2016/8/18) Not sure, ask i18n team for reason"
    }
  ]
}