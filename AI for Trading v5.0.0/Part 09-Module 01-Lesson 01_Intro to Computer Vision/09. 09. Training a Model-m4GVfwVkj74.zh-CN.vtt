WEBVTT
Kind: captions
Language: zh-CN

00:00:00.320 --> 00:00:05.309
我已经描述了计算机视觉接受一系列图像的流程

00:00:05.309 --> 00:00:07.378
通过几个步骤可以

00:00:07.378 --> 00:00:10.455
识别不同的面部表情和情感

00:00:10.455 --> 00:00:12.804
不过它看起来还是有些神秘

00:00:12.804 --> 00:00:15.300
你可以再讲解一下 像这样的模型

00:00:15.300 --> 00:00:18.535
如何经过训练 识别不同面部表情吗？

00:00:18.535 --> 00:00:23.300
当然 这个过程类似于你刚才描述的流程

00:00:23.300 --> 00:00:28.710
我们拥有 45 个面部肌肉 可以产生上千种不同的表情

00:00:28.710 --> 00:00:31.109
我们来看个具体例子

00:00:31.109 --> 00:00:37.795
假如我们要训练一个区分微笑和傻笑的算法

00:00:37.795 --> 00:00:41.840
我们收集了几万个人们微笑的案例 为了更加多样和更好的结果

00:00:41.840 --> 00:00:46.600
然后是几万个人们傻笑的案例

00:00:46.600 --> 00:00:51.384
我们把预先记录的图像及其标签填充到系统中

00:00:51.384 --> 00:00:55.780
然后算法就寻找两种表情在视觉上的不同

00:00:55.780 --> 00:00:57.509
例如你微笑时

00:00:57.509 --> 00:00:58.634
会露出牙齿

00:00:58.634 --> 00:01:00.879
但是傻笑时不会露出牙齿

00:01:00.880 --> 00:01:04.049
所以你要给模型大量微笑和傻笑

00:01:04.049 --> 00:01:08.125
以及其他面部表情的示例  直到学会识别它们

00:01:08.125 --> 00:01:09.620
这听起来像是宝宝学习的过程

00:01:09.620 --> 00:01:11.284
通过大量示例

00:01:11.284 --> 00:01:12.487
没错

00:01:12.486 --> 00:01:14.369
这类似于人类学习的过程

00:01:14.370 --> 00:01:16.230
在训练的初始阶段

00:01:16.230 --> 00:01:18.810
模型一般表现很差

00:01:18.810 --> 00:01:22.349
不过它监测自己出现的错误

00:01:22.349 --> 00:01:26.353
每次见到更多图像时 使用这些改进表现

00:01:26.353 --> 00:01:29.670
经过多次迭代后

00:01:29.670 --> 00:01:33.765
一旦错误率可以接受 模型汇集了正确的参数

00:01:33.765 --> 00:01:37.545
这时候我们要考虑全面训练这个模型

00:01:37.545 --> 00:01:41.871
这是如何训练任何机器学习模型的高级观点

00:01:41.871 --> 00:01:43.828
根据你使用的模型类型

00:01:43.828 --> 00:01:46.949
和选择的训练算法 细节也各有不同

00:01:46.950 --> 00:01:52.265
例如你可以使用卷积神经网络 使用梯度下降训练

00:01:52.265 --> 00:01:57.480
接下来我们来看计算机视觉流程如何在实时应用中发挥作用

