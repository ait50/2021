WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.510
我们想要定义一个字符 RNN 它有两个 LSTM 层级

00:00:04.510 --> 00:00:07.200
在我的答案中 我在 GPU 上运行代码

00:00:07.200 --> 00:00:11.275
下面说说我是如何定义字符级 RNN 的

00:00:11.275 --> 00:00:15.255
首先定义一个 LSTM 层级 self.lstm

00:00:15.255 --> 00:00:17.020
第一个参数是输入大小

00:00:17.020 --> 00:00:18.555
该大小是独热编码的

00:00:18.555 --> 00:00:20.700
输入字符的长度

00:00:20.700 --> 00:00:23.365
也就是所有唯一字符的长度

00:00:23.365 --> 00:00:25.940
后面的参数是隐藏维度

00:00:25.940 --> 00:00:29.030
层级数量以及指定的丢弃概率

00:00:29.030 --> 00:00:33.685
此参数将在多个 LSTM 层级之间创建丢弃层

00:00:33.685 --> 00:00:36.335
在创建 RNN 时 会将所有这些参数

00:00:36.335 --> 00:00:39.190
传入该 RNN 中

00:00:39.190 --> 00:00:43.340
将 batch_first 设为 True 因为在创建批次数据时

00:00:43.340 --> 00:00:45.270
第一个维度是批次大小

00:00:45.270 --> 00:00:47.215
而不是序列长度

00:00:47.215 --> 00:00:49.835
Ok接下来 我在 LSTM 和最终线性层级之间

00:00:49.835 --> 00:00:52.940
定义了丢弃层

00:00:52.940 --> 00:00:56.510
接着是 fc 即最终全连接线性层级

00:00:56.510 --> 00:00:59.120
它的参数是 LSTM 输入

00:00:59.120 --> 00:01:01.045
维度是 n_hidden

00:01:01.045 --> 00:01:05.555
输出最有可能的下个字符的字符类别分数

00:01:05.555 --> 00:01:08.970
这些是每个潜在下个字符的类别分数

00:01:08.970 --> 00:01:11.480
这个输出大小和输入大小一样

00:01:11.480 --> 00:01:13.605
即字符词汇表的长度

00:01:13.605 --> 00:01:15.935
然后是 forward 函数

00:01:15.935 --> 00:01:20.275
向这里的 LSTM 层级传入输入 x 和隐藏状态

00:01:20.275 --> 00:01:23.810
生成 LSTM 输出和新的隐藏状态

00:01:23.810 --> 00:01:26.270
将 LSTM 输出

00:01:26.270 --> 00:01:29.120
传入在这里定义的丢弃层并获得新的输出

00:01:29.120 --> 00:01:31.345
然后变形此输出

00:01:31.345 --> 00:01:33.845
使最后一个维度是隐藏维度

00:01:33.845 --> 00:01:38.610
这个 -1 表示我将堆叠 LSTM 的输出

00:01:38.610 --> 00:01:42.735
最后 将这个变形后的输出传入最终全连接层

00:01:42.735 --> 00:01:45.080
然后返回此最终输出

00:01:45.080 --> 00:01:47.595
以及 LSTM 生成的隐藏状态

00:01:47.595 --> 00:01:51.915
这两个函数以及 init_hidden 函数构成了我的模型

00:01:51.915 --> 00:01:57.475
接下来训练模型 我们看看提供的训练循环

00:01:57.475 --> 00:02:00.740
这个函数的参数是要训练的模型、数据

00:02:00.740 --> 00:02:02.320
训练周期数

00:02:02.320 --> 00:02:03.650
以及批次大小

00:02:03.650 --> 00:02:06.330
和定义迷你批次大小的序列长度

00:02:06.330 --> 00:02:09.140
还有其他几个训练参数

00:02:09.140 --> 00:02:13.140
首先在这里定义优化器和损失函数

00:02:13.140 --> 00:02:16.055
优化器是标准 Adam 优化器

00:02:16.055 --> 00:02:19.070
学习速率设为在这里传入的学习速率

00:02:19.070 --> 00:02:21.360
最后一个函数是交叉熵损失

00:02:21.360 --> 00:02:24.775
用于输出字符类别分数

00:02:24.775 --> 00:02:26.960
这部分代码用于创建验证数据

00:02:26.960 --> 00:02:31.105
并将模型移到 GPU 上（如果有）

00:02:31.105 --> 00:02:33.775
这是周期循环的开头

00:02:33.775 --> 00:02:35.460
在每个周期开始时 

00:02:35.460 --> 00:02:38.255
我将初始化 LSTM 的隐藏状态

00:02:38.255 --> 00:02:41.750
参数是数据的批次大小 用于定义隐藏状态的大小

00:02:41.750 --> 00:02:45.970
返回全为 0 的隐藏单元状态

00:02:45.970 --> 00:02:47.695
在此周期循环里

00:02:47.695 --> 00:02:49.105
是批次循环

00:02:49.105 --> 00:02:53.335
从 get_batches 生成器中获取 x y 迷你批次

00:02:53.335 --> 00:02:57.090
此函数会遍历编码数据

00:02:57.090 --> 00:02:59.810
并返回批次输入 x 和目标 y

00:02:59.810 --> 00:03:04.390
然后将输入转换为独热编码表示法

00:03:04.390 --> 00:03:06.925
将输入 x 和目标 y 转换为

00:03:06.925 --> 00:03:10.335
能够传入模型中的张量

00:03:10.335 --> 00:03:14.920
如果有 GPU 则将这些输入和目标转移到 GPU 设备上

00:03:14.920 --> 00:03:17.875
下一步是确保将传入的隐藏状态

00:03:17.875 --> 00:03:20.590
与其历史记录分离

00:03:20.590 --> 00:03:23.530
LSTM 层级的隐藏状态是一个元组

00:03:23.530 --> 00:03:25.630
所以这里的数据是元组

00:03:25.630 --> 00:03:28.815
然后执行反向传播

00:03:28.815 --> 00:03:34.615
清零积累的梯度并将输入张量传入模型中

00:03:34.615 --> 00:03:37.090
并且在这里传入最新的隐藏状态

00:03:37.090 --> 00:03:40.820
返回最终输出和新的隐藏状态

00:03:40.820 --> 00:03:44.885
然后通过查看预测输出和目标来计算损失

00:03:44.885 --> 00:03:47.420
在模型的 forward 函数中

00:03:47.420 --> 00:03:52.460
我将 LSTM 输出的批次大小和序列长度变成了一个维度

00:03:52.460 --> 00:03:55.150
在这里也针对目标执行相同的处理流程

00:03:55.150 --> 00:03:57.575
然后进行反向传播

00:03:57.575 --> 00:04:00.690
朝着右侧方向移动一个步长并更新网络权重

00:04:00.690 --> 00:04:02.420
在优化步骤之前

00:04:02.420 --> 00:04:05.045
我添加了一行新的代码

00:04:05.045 --> 00:04:07.105
即调用 clip_grad_norm_

00:04:07.105 --> 00:04:10.970
这种 LSTM 模型在梯度方面有一个主要问题

00:04:10.970 --> 00:04:13.220
梯度可能会爆炸并变得非常非常大

00:04:13.220 --> 00:04:15.490
因此我们可以截断梯度

00:04:15.490 --> 00:04:17.570
设置一个截断阈值

00:04:17.570 --> 00:04:20.305
如果梯度大于该阈值

00:04:20.305 --> 00:04:22.530
则将梯度设为该截断阈值

00:04:22.530 --> 00:04:24.530
在这里 我们只需传入参数

00:04:24.530 --> 00:04:27.840
以及梯度截断阈值

00:04:27.840 --> 00:04:29.990
我们已经在 train 函数中

00:04:29.990 --> 00:04:32.485
传入这个值 值为 5

00:04:32.485 --> 00:04:34.205
执行反向传播步骤后

00:04:34.205 --> 00:04:35.510
截断梯度

00:04:35.510 --> 00:04:37.520
执行优化步骤

00:04:37.520 --> 00:04:40.445
最后对验证数据执行很相似的流程

00:04:40.445 --> 00:04:43.860
但是不执行反向传播步骤

00:04:43.860 --> 00:04:46.900
然后输出损失值

00:04:46.900 --> 00:04:48.955
定义好 train 函数后

00:04:48.955 --> 00:04:51.740
实例化并训练模型

00:04:51.740 --> 00:04:53.275
在练习 notebook 中

00:04:53.275 --> 00:04:55.930
你需要定义这些超参数

00:04:55.930 --> 00:05:00.660
我将隐藏维度设为 512

00:05:00.660 --> 00:05:02.040
并将层数设为 2

00:05:02.040 --> 00:05:04.520
然后实例化模型并输出该模型

00:05:04.520 --> 00:05:07.580
可以看出输入有 83 个唯一字符

00:05:07.580 --> 00:05:09.290
隐藏维度是 512

00:05:09.290 --> 00:05:11.420
有两个 LSTM 层级

00:05:11.420 --> 00:05:12.800
对于丢弃层

00:05:12.800 --> 00:05:17.855
默认丢弃概率是 0.5 对于最终全连接层

00:05:17.855 --> 00:05:19.055
参数包括输入特征数

00:05:19.055 --> 00:05:22.195
它和这个隐藏维度一样 然后是输出特征数

00:05:22.195 --> 00:05:23.610
等于字符数

00:05:23.610 --> 00:05:26.210
其他超参数包括

00:05:26.210 --> 00:05:29.565
批次大小、序列长度和训练周期数

00:05:29.565 --> 00:05:31.845
我将序列长度设为 100

00:05:31.845 --> 00:05:33.365
包含很多字符

00:05:33.365 --> 00:05:36.740
但是为模型提供了大量上下文信息

00:05:36.740 --> 00:05:39.020
注意 隐藏维度是

00:05:39.020 --> 00:05:41.840
模型能够检测的特征数量

00:05:41.840 --> 00:05:46.190
更大的值使网络能够学习更多文本特征

00:05:46.190 --> 00:05:50.830
下面还有更多定义超参数的信息

00:05:50.830 --> 00:05:55.050
通常 我会先建立这样的大型模型

00:05:55.050 --> 00:05:58.105
有多个 LSTM 层级和很大的隐藏维度

00:05:58.105 --> 00:06:01.115
然后看看模型的训练损失

00:06:01.115 --> 00:06:04.475
如果损失降低了 则继续

00:06:04.475 --> 00:06:06.285
如果不像预期得那样降低

00:06:06.285 --> 00:06:08.780
则更改某些超参数

00:06:08.780 --> 00:06:11.330
我们的文本数据很庞大

00:06:11.330 --> 00:06:14.930
我在 GPU 上训练整个模型 20 个周期

00:06:14.930 --> 00:06:19.300
可以看到训练和验证损失逐渐降低了

00:06:19.300 --> 00:06:23.430
在第 15 个周期左右 看到损失降低速度变慢了

00:06:23.430 --> 00:06:25.520
但是即使在第 20 个周期之后

00:06:25.520 --> 00:06:28.470
验证和训练损失还在降低

00:06:28.470 --> 00:06:31.810
还可以训练更长时间

00:06:31.810 --> 00:06:34.670
这部分是关于如何设置模型超参数

00:06:34.670 --> 00:06:38.135
以及获得最佳模型的信息 建议阅读一下

00:06:38.135 --> 00:06:40.760
然后 像我这样训练模型之后

00:06:40.760 --> 00:06:43.280
你可以保存模型并设定名称

00:06:43.280 --> 00:06:47.055
最后还有一步 使用模型做出预测并生成一些新的文本

00:06:47.055 --> 00:06:48.600
接下来我将讲解这方面的知识

