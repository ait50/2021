WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:02.294
现在我们来看看决策树中潜在的问题

00:00:02.294 --> 00:00:05.549
比如说我们有一张极大的表格 其中行列很多

00:00:05.549 --> 00:00:08.580
然后我们建立了决策树  比如说是这个样子的

00:00:08.580 --> 00:00:11.339
这只是一个例子 并不是真实的决策树 

00:00:11.339 --> 00:00:13.619
然后我们得到了如下结论

00:00:13.619 --> 00:00:17.160
如果一位客户为男性 年龄在 15 到 25 之间 居住在美国

00:00:17.160 --> 00:00:18.359
使用 Android 还在上学

00:00:18.359 --> 00:00:20.925
喜欢网球和披萨 但不喜欢长时间在沙滩上长散步

00:00:20.925 --> 00:00:23.255
那么他很可能下载 Pokemon Go

00:00:23.254 --> 00:00:27.144
这种做法很不理想 看起来似乎只是在记忆数据

00:00:27.144 --> 00:00:31.195
这种情况称为过拟合 决策树经常会过拟合

00:00:31.195 --> 00:00:34.420
如果我们选用连续特征也会出现这种问题

00:00:34.420 --> 00:00:37.179
决策树有许多结点 它最终会呈现给我们多个几乎与点相接的小方块

00:00:37.179 --> 00:00:41.304
这些小方块将不同颜色的点分开

00:00:41.304 --> 00:00:45.009
这也是过拟合现象 因为它对数据不具备普适性

00:00:45.009 --> 00:00:49.164
那么如何解决这一问题呢  方法很简单

00:00:49.164 --> 00:00:51.310
我们可以这样操作

00:00:51.310 --> 00:00:53.245
随机从数据中挑选几列

00:00:53.244 --> 00:00:55.929
并根据这些列建构决策树

00:00:55.929 --> 00:00:58.269
然后随机选取其它几列

00:00:58.270 --> 00:01:01.175
再次构建决策树

00:01:01.174 --> 00:01:03.754
然后让决策树进行选择

00:01:03.755 --> 00:01:05.629
当我们有新的数据时

00:01:05.629 --> 00:01:07.414
比如说出现了一个新用户

00:01:07.415 --> 00:01:12.620
就只需让所有的决策树做出预测 并选取结果中显示最多的

00:01:12.620 --> 00:01:15.410
比如 这些决策树觉得

00:01:15.409 --> 00:01:18.935
这个人会下载 Snapchat WhatsApp 和 WhatsApp

00:01:18.935 --> 00:01:22.129
因此 决策树的集成会推荐此人下载 WhatsApp

00:01:22.129 --> 00:01:25.670
由于我们利用随机的列建构的多个决策树做出了预测

00:01:25.670 --> 00:01:28.280
这种方法称为随机森林

00:01:28.280 --> 00:01:31.159
其实还有比随机选取列更好的方法

00:01:31.159 --> 00:01:34.269
我们将在该纳米课程的集成方法部分进行学习

