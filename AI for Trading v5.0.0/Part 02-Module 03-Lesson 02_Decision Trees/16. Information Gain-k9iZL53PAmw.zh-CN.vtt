WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.524
没错 第一种分法完全没用

00:00:03.524 --> 00:00:05.370
分割后的数据与原数据都包含相似的红点和蓝点

00:00:05.370 --> 00:00:08.085
对于我们了解数据没有帮助

00:00:08.085 --> 00:00:09.915
第二种分法就比较好了

00:00:09.914 --> 00:00:11.819
我们可以把大多数蓝点分在一边

00:00:11.820 --> 00:00:14.669
而把大多数红点分在另一边

00:00:14.669 --> 00:00:16.980
所以 我们对于数据有了一定了解

00:00:16.980 --> 00:00:18.690
第三种分法就更棒了

00:00:18.690 --> 00:00:20.490
它把所有的蓝点分在一边

00:00:20.489 --> 00:00:23.039
并把所有的红点分在另一边

00:00:23.039 --> 00:00:24.914
现在 我们对于数据的了解就更多了

00:00:24.914 --> 00:00:28.750
接下来 我们将学习如何计算信息增益

00:00:28.750 --> 00:00:31.300
第一种分法的信息增益为 0 

00:00:31.300 --> 00:00:34.299
第二种为 0.28 第三种为 1

00:00:34.299 --> 00:00:36.820
信息增益的计算公式很简单

00:00:36.820 --> 00:00:38.500
等于熵的变化值

00:00:38.500 --> 00:00:40.203
更具体点说

00:00:40.203 --> 00:00:42.190
在决策树中的每一个结点处

00:00:42.189 --> 00:00:45.714
我们可以计算父结点处数据的熵

00:00:45.715 --> 00:00:49.630
然后计算两个子结点的熵

00:00:49.630 --> 00:00:52.630
父结点的熵与子结点熵平均值之间的差值

00:00:52.630 --> 00:00:56.890
即为信息增益

00:00:56.890 --> 00:00:58.420
因此 在第二个例子中

00:00:58.420 --> 00:01:01.454
我们计算得到其父结点的熵为 1

00:01:01.454 --> 00:01:04.504
各子结点的熵为 0.72

00:01:04.504 --> 00:01:08.342
故子结点的熵的平均值也为 0.72

00:01:08.343 --> 00:01:14.060
因此 熵的变化值为 1 减 0.72 即0.28

00:01:14.060 --> 00:01:18.125
而在这个例子中 我们可以计算得到各自子结点的熵均为 1

00:01:18.125 --> 00:01:22.099
因此 熵的变化为 1 减 1 即 0

00:01:22.099 --> 00:01:25.399
这个分法很糟糕 因为它没有提供任何信息

00:01:25.400 --> 00:01:26.870
而在第三种分法中

00:01:26.870 --> 00:01:29.000
两个子结点的熵均为零

00:01:29.000 --> 00:01:30.349
正如我们所见

00:01:30.349 --> 00:01:33.664
一个集合中点的颜色一致时 其熵为 0

00:01:33.665 --> 00:01:37.315
因此 其信息增益为 1 减 0 即 1

00:01:37.314 --> 00:01:41.174
这种分法给我们的信息增益最大

00:01:41.174 --> 00:01:43.784
它完美地将蓝点和红点分开

00:01:43.784 --> 00:01:47.054
因此这是最好的分法

00:01:47.055 --> 00:01:51.116
我们做一下总结 以下是三种分法以及其信息增益值

00:01:51.115 --> 00:01:52.694
如果决策树必须做出选择

00:01:52.694 --> 00:01:54.389
它将选择第三种分法

00:01:54.390 --> 00:01:58.200
因为第三种分法提供的信息增益最大

