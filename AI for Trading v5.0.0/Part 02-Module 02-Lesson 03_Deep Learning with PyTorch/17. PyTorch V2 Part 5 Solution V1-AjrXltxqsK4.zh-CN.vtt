WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:03.930
欢迎回来下面说说我的验证流程实现方法

00:00:03.930 --> 00:00:06.870
在这里定义模型

00:00:06.870 --> 00:00:10.125
损失 优化器等等

00:00:10.125 --> 00:00:16.980
我将周期设成了 30   可以更清晰地看到训练效果

00:00:16.980 --> 00:00:19.800
损失如何下降 验证损失如何变化 等等

00:00:19.800 --> 00:00:23.205
原理是 每个周期之后

00:00:23.205 --> 00:00:25.620
即 每次经过训练集之后

00:00:25.620 --> 00:00:28.155
我们将执行训练流程

00:00:28.155 --> 00:00:29.820
这就是这个 else 的作用

00:00:29.820 --> 00:00:33.120
这是 for 循环

00:00:33.120 --> 00:00:36.750
for 循环之后

00:00:36.750 --> 00:00:38.060
运行此代码

00:00:38.060 --> 00:00:40.150
这就是 else 的含义

00:00:40.150 --> 00:00:45.090
我们要关闭梯度 所以使用 with torch.no_grad

00:00:45.090 --> 00:00:47.990
然后从测试集获取图像和标签

00:00:47.990 --> 00:00:53.725
将图像传入模型 获取对数概率 计算损失

00:00:53.725 --> 00:00:57.080
在这里更新 test_loss

00:00:57.080 --> 00:00:59.990
test_loss 是一个整数

00:00:59.990 --> 00:01:03.230
当我们在训练时 或者说 在执行验证流程时

00:01:03.230 --> 00:01:05.120
test_loss 会计数

00:01:05.120 --> 00:01:06.650
这样就能够跟踪

00:01:06.650 --> 00:01:10.100
所有训练周期的测试损失

00:01:10.100 --> 00:01:12.080
使用 torch.exp

00:01:12.080 --> 00:01:17.030
从对数概率中获得实际概率分布

00:01:17.030 --> 00:01:23.160
运行 topk(1, dim=1) 其中前面的 1表示预测类别

00:01:23.160 --> 00:01:25.965
我们可以衡量相等性

00:01:25.965 --> 00:01:30.550
我们在这里使用 torch.exp 从对数概率中获取概率

00:01:30.550 --> 00:01:34.285
用对数计算指数可以得出概率

00:01:34.285 --> 00:01:38.115
然后运行 ps.topk(1, dim=1)

00:01:38.115 --> 00:01:43.110
前面的 1 表示概率最高的类别或预测类别

00:01:43.110 --> 00:01:47.520
然后使用 ==

00:01:47.520 --> 00:01:52.535
检测预测类别与标签的真实类别是否匹配

00:01:52.535 --> 00:01:55.670
使用 torch.mean 计算准确率

00:01:55.670 --> 00:01:59.125
并将 equals 变成浮点数张量

00:01:59.125 --> 00:02:02.470
运行此单元格

00:02:02.470 --> 00:02:05.315
看看在训练此网络时

00:02:05.315 --> 00:02:08.965
实际训练损失和验证损失是多少

00:02:08.965 --> 00:02:10.880
网络训练过后

00:02:10.880 --> 00:02:12.590
可以看出当我们继续用更多数据训练网络时

00:02:12.590 --> 00:02:16.985
验证损失和训练损失是如何逐渐改变的

00:02:16.985 --> 00:02:19.790
训练损失降低了

00:02:19.790 --> 00:02:23.270
但是验证损失开始上升了

00:02:23.270 --> 00:02:26.340
很明显地表现出过拟合了

00:02:26.340 --> 00:02:29.270
网络在训练数据上的效果越来越好

00:02:29.270 --> 00:02:32.530
但是在验证数据上的效果开始变差

00:02:32.530 --> 00:02:35.330
这是因为它在学习训练数据中的细节

00:02:35.330 --> 00:02:38.795
但无法泛化到训练数据之外的数据上

00:02:38.795 --> 00:02:43.645
Ok这就是过拟合现象

00:02:43.645 --> 00:02:45.480
要避免或者防止过拟合

00:02:45.480 --> 00:02:47.960
我们将使用正则化

00:02:47.960 --> 00:02:51.560
例如丢弃

00:02:51.560 --> 00:02:56.245
丢弃是指在层级之间随机丢弃输入单元

00:02:56.245 --> 00:03:00.185
这样可以强制网络在权重之间共享信息

00:03:00.185 --> 00:03:03.965
并提高网络泛化到新数据上的能力

00:03:03.965 --> 00:03:06.350
在 PyTorch 中添加丢弃很简单

00:03:06.350 --> 00:03:08.815
直接使用 nn.Dropout 模块

00:03:08.815 --> 00:03:12.125
像之前一样创建分类器

00:03:12.125 --> 00:03:16.385
在隐藏层使用线性转换

00:03:16.385 --> 00:03:18.260
然后设置为 self.dropout = nn.Dropout

00:03:18.260 --> 00:03:21.685
并设定丢弃概率

00:03:21.685 --> 00:03:23.460
我们设为 20%

00:03:23.460 --> 00:03:26.720
表示丢弃某个单元的概率

00:03:26.720 --> 00:03:28.655
forward 方法很相似

00:03:28.655 --> 00:03:30.260
传入 x

00:03:30.260 --> 00:03:32.135
x 是输入张量

00:03:32.135 --> 00:03:33.605
我们需要先扁平化 x

00:03:33.605 --> 00:03:37.590
然后将此张量传入每个全连接层

00:03:37.590 --> 00:03:41.910
传入 ReLu 激活函数

00:03:41.910 --> 00:03:44.265
再传入 dropout

00:03:44.265 --> 00:03:48.630
最后一层是输出层 因此不使用丢弃

00:03:48.630 --> 00:03:50.760
还有一点要注意

00:03:50.760 --> 00:03:53.800
在进行推理时

00:03:53.800 --> 00:03:55.700
就是 在使用网络做出预测时

00:03:55.700 --> 00:03:59.390
我们需要使用所有单元

00:03:59.390 --> 00:04:00.840
因此 在进行验证时、

00:04:00.840 --> 00:04:03.719
在网络尝试做出预测时

00:04:03.719 --> 00:04:05.970
我们都必须关闭丢弃

00:04:05.970 --> 00:04:09.440
运行 model.eval

00:04:09.440 --> 00:04:16.270
model.eval 将关闭丢弃

00:04:16.270 --> 00:04:19.715
才能在进行推理时充分利用网络的强大功能

00:04:19.715 --> 00:04:22.610
要回到训练模式 则使用 model.train

00:04:22.610 --> 00:04:25.780
现在验证流程看起来是这样的

00:04:25.780 --> 00:04:27.700
首先使用 with torch.no_grad 关闭梯度

00:04:27.700 --> 00:04:32.360
然后将模型设为验证模式

00:04:32.360 --> 00:04:36.720
对测试数据执行验证流程

00:04:36.720 --> 00:04:38.070
结束后

00:04:38.070 --> 00:04:42.545
我们可以用 model.train 将模型设回训练模式

00:04:42.545 --> 00:04:48.585
Ok.下面你的任务是创建新的模型

00:04:48.585 --> 00:04:52.050
向模型中添加丢弃并训练模型

00:04:52.050 --> 00:04:58.470
然后使用丢弃通过验证流程检查训练进度加油！

