WEBVTT
Kind: captions
Language: pt-BR

00:00:00.000 --> 00:00:01.340
Olá, bem-vindo de volta!

00:00:01.640 --> 00:00:05.474
Agora vamos usar uma rede
pré-treinada

00:00:05.507 --> 00:00:08.937
Para resolver o difícil problema
de criar um classificador

00:00:08.970 --> 00:00:10.869
para suas imagens
de gatos e cães.

00:00:11.550 --> 00:00:14.385
Essas redes pré-treinadas
foram treinadas na ImageNet,

00:00:14.418 --> 00:00:17.745
que é um enorme conjunto de dados
com mais de 1 milhão de imagens

00:00:17.778 --> 00:00:19.435
e 1000 categorias diferentes.

00:00:19.699 --> 00:00:22.403
Elas estão disponíveis
no Torchvision

00:00:22.731 --> 00:00:23.820
e...

00:00:25.062 --> 00:00:27.184
neste módulo,
torchvision.models.

00:00:27.217 --> 00:00:32.106
Repare que temos 6 arquiteturas
diferentes para usar.

00:00:32.749 --> 00:00:35.796
E aqui temos um bom resumo
do desempenho

00:00:35.829 --> 00:00:37.151
de cada um desses modelos.

00:00:37.184 --> 00:00:40.559
Veja aqui, AlexNet...
tem o erro de top-1 e de top-5.

00:00:40.593 --> 00:00:42.343
Como você pode ver,

00:00:42.376 --> 00:00:45.935
essas redes
e esses números aqui,

00:00:45.968 --> 00:00:48.326
tipo 19, 11, 34
e assim por diante,

00:00:48.359 --> 00:00:51.400
geralmente indicam
o número de camadas do modelo.

00:00:51.433 --> 00:00:54.150
Quanto maior o número,
maior o modelo.

00:00:54.183 --> 00:00:56.465
Consequentemente,
quanto maior o modelo,

00:00:56.499 --> 00:00:58.704
melhor será a sua precisão.

00:00:58.737 --> 00:00:59.960
Os erros são menores.

00:01:00.569 --> 00:01:03.278
Mas, ao mesmo tempo,
quanto maior for o modelo,

00:01:03.311 --> 00:01:06.785
mais tempo ele vai levar
para computar suas previsões,

00:01:06.818 --> 00:01:08.500
para treinar, e tudo mais.

00:01:08.534 --> 00:01:09.860
Quando você usar isso,

00:01:09.893 --> 00:01:14.332
vai ter que considerar concessões
entre precisão e velocidade.

00:01:15.383 --> 00:01:16.967
Todas essas redes

00:01:17.360 --> 00:01:20.184
usam uma arquitetura chamada
"camadas convolucionais".

00:01:20.217 --> 00:01:24.080
Elas exploram padrões,
regularidades e imagens.

00:01:24.114 --> 00:01:27.297
Não vou entrar em detalhes,
mas se você quiser saber mais,

00:01:27.330 --> 00:01:28.709
assista esse vídeo.

00:01:29.224 --> 00:01:31.256
Mas essas redes
de aprendizado profundo

00:01:31.289 --> 00:01:33.475
geralmente
são muito profundas.

00:01:33.508 --> 00:01:37.592
Ou seja, elas têm dezenas
ou centenas de camadas diferentes

00:01:37.626 --> 00:01:41.061
e todas foram treinadas no enorme
conjunto de dados da ImageNet.

00:01:41.094 --> 00:01:44.572
Ocorre que elas se saíram muito bem
como detectoras de características

00:01:44.605 --> 00:01:46.979
de imagens as quais
não foram treinadas.

00:01:47.013 --> 00:01:48.825
Então usar uma rede
pré-treinada

00:01:48.858 --> 00:01:51.352
em um conjunto de treinamento
que ela nunca viu

00:01:51.385 --> 00:01:53.388
se chama
"transferência de aprendizado".

00:01:53.421 --> 00:01:55.682
O que foi aprendido
no conjunto da ImageNet

00:01:55.715 --> 00:01:58.521
será transferido
para o seu conjunto de dados.

00:01:59.003 --> 00:02:01.260
Aqui vamos usar
a transferência de aprendizado

00:02:01.293 --> 00:02:04.877
para treinar nossa rede para
classificar fotos de gatos e cães.

00:02:04.910 --> 00:02:07.397
Você verá que teremos
um desempenho muito bom

00:02:07.430 --> 00:02:09.142
com pouco trabalho.

00:02:09.604 --> 00:02:12.977
Você pode baixar esses modelos
de torchvision.models,

00:02:13.011 --> 00:02:14.175
esse modelo aqui,

00:02:14.208 --> 00:02:17.005
e podemos incluir
em nossas importações, bem aqui.

00:02:17.523 --> 00:02:21.561
Esses modelos pré-treinados
exigem imagens de 224 por 224

00:02:21.594 --> 00:02:22.727
como input.

00:02:22.760 --> 00:02:25.098
Você também terá que usar
a mesma normalização

00:02:25.131 --> 00:02:26.912
que os modelos usaram
para treinar.

00:02:26.945 --> 00:02:28.973
Quando treinaram
esses modelos,

00:02:29.006 --> 00:02:32.377
cada canal de cor e cada imagem
foram normalizados separadamente.

00:02:32.410 --> 00:02:36.175
Veja aqui as médias
e os desvios-padrão.

00:02:36.777 --> 00:02:39.398
Vou deixar para você definir
as transformações

00:02:39.431 --> 00:02:41.928
para os dados de treinamento
e de teste.

00:02:42.308 --> 00:02:44.440
Depois disso vamos prosseguir.

00:02:45.153 --> 00:02:48.119
Agora vamos ver
como se carrega um modelo desses.

00:02:49.233 --> 00:02:52.763
Aqui eu vou usar o modelo
Densenet-121.

00:02:53.091 --> 00:02:55.271
Repare que ele tem uma precisão
muito alta

00:02:55.304 --> 00:02:57.791
no conjunto de dados
da ImageNet

00:02:58.132 --> 00:03:02.937
e esse número indica
que ele tem 121 camadas diferentes.

00:03:03.600 --> 00:03:06.201
Para carregar isso
em nosso código, para usar,

00:03:06.234 --> 00:03:11.726
basta digitar
model = models.densenet.121

00:03:11.759 --> 00:03:14.377
e depois (pretrained=True).

00:03:14.410 --> 00:03:17.367
isso vai baixar a rede
pré-treinada,

00:03:17.400 --> 00:03:19.383
os pesos,
os próprios parâmetros,

00:03:19.416 --> 00:03:21.290
em nosso modelo.

00:03:22.125 --> 00:03:23.717
Agora vamos fazer isso

00:03:23.750 --> 00:03:26.735
e depois podemos conferir
a arquitetura do modelo.

00:03:27.939 --> 00:03:31.419
Essa é a cara da arquitetura
do Densenet.

00:03:31.761 --> 00:03:35.067
Repare que tem uma parte aqui
de características

00:03:35.100 --> 00:03:36.617
e um monte de camadas.

00:03:36.650 --> 00:03:39.917
Aqui temos uma camada convolucional.
Não vou falar disso aqui,

00:03:39.950 --> 00:03:43.283
mas você não precisa entender
para usar isso.

00:03:44.838 --> 00:03:46.601
Há duas partes
que nos interessam.

00:03:46.634 --> 00:03:48.375
Primeiro, aqui em Features,

00:03:48.408 --> 00:03:52.790
e depois, rolando até lá embaixo,
essa parte Classifier.

00:03:53.385 --> 00:03:55.686
Ou seja, aqui temos
o classificador.

00:03:56.316 --> 00:03:59.385
Ele foi definido como uma camada
de combinação linear.

00:03:59.418 --> 00:04:01.043
É uma camada densa
totalmente conexa

00:04:01.076 --> 00:04:03.343
que tem 1024 características
de input

00:04:03.376 --> 00:04:05.430
e 1000 características
de output.

00:04:05.463 --> 00:04:09.225
Lembre que a ImageNet
tem 1000 classes diferentes.

00:04:09.259 --> 00:04:12.996
E assim, o número de saídas
dessa rede

00:04:13.427 --> 00:04:15.401
deve ser 1000
para cada classe.

00:04:15.839 --> 00:04:19.615
Lembre que essa coisa toda
foi treinada na ImageNet.

00:04:20.073 --> 00:04:23.557
As características vão funcionar
para outros conjuntos de dados,

00:04:23.591 --> 00:04:26.675
mas o classificador
foi treinado para a ImageNet.

00:04:26.708 --> 00:04:29.776
Essa é a parte que temos que
treinar de novo, o classificador.

00:04:29.809 --> 00:04:33.318
A parte de características permanece
sem atualizações,

00:04:33.989 --> 00:04:36.166
mas temos que atualizar
o classificador.

00:04:36.598 --> 00:04:38.633
A primeira coisa
que temos que fazer

00:04:38.666 --> 00:04:41.209
é congelar nossos parâmetros
de características.

00:04:41.242 --> 00:04:44.251
Para fazer isso,
vasculhamos nossos parâmetros,

00:04:44.755 --> 00:04:47.498
em nosso modelo.

00:04:47.879 --> 00:04:49.276
Aqui digitamos:

00:04:49.309 --> 00:04:53.869
requires_grad = False

00:04:54.163 --> 00:04:59.795
Isso faz com que, ao rodarmos
nossos tensores pelo modelo,

00:04:59.828 --> 00:05:03.369
não vamos calcular
os gradientes.

00:05:03.402 --> 00:05:05.754
Não vamos rastrear
todas essas operações.

00:05:05.788 --> 00:05:08.203
Primeiro, isso vai garantir

00:05:08.236 --> 00:05:11.557
que nossos parâmetros
de características não se atualizem,

00:05:12.179 --> 00:05:14.974
mas também vai acelerar
o treinamento,

00:05:15.007 --> 00:05:19.400
porque não vamos rastrear
as operações das características.

00:05:19.889 --> 00:05:23.020
Agora temos que substituir
o classificador pelo nosso.

00:05:23.766 --> 00:05:26.376
Aqui eu vou usar
duas coisas novas.

00:05:26.699 --> 00:05:30.440
Vou usar o módulo sequencial
disponível no PyTorch.

00:05:30.473 --> 00:05:35.214
Ele dá uma lista de operações
diferentes que você pode fazer

00:05:35.247 --> 00:05:39.535
e automaticamente passa um tensor
por elas, sequencialmente.

00:05:40.302 --> 00:05:45.287
Você pode passar OrderedDict
para nomear cada uma dessas camadas.

00:05:45.321 --> 00:05:46.932
Vou mostrar como funciona.

00:05:47.475 --> 00:05:49.754
Queremos uma camada
completamente conectada.

00:05:49.787 --> 00:05:51.479
Vou chamá-la de FC1.

00:05:51.817 --> 00:05:54.175
É uma camada completamente
conectada

00:05:54.208 --> 00:05:56.331
que vem de 1024 inputs

00:05:56.364 --> 00:05:58.995
e, digamos,
500 para essa camada oculta.

00:05:59.886 --> 00:06:03.832
Agora vamos passar isso
pela ativação ReLu

00:06:04.773 --> 00:06:08.386
e depois vai passar por outra
camada completamente conectada

00:06:09.094 --> 00:06:13.104
que será nossa camada de saída.
Fazemos (500,2)

00:06:13.137 --> 00:06:14.480
para ter gato e cão.

00:06:14.513 --> 00:06:16.111
Precisamos de duas saídas.

00:06:16.144 --> 00:06:20.230
Por fim, a saída vai ser
o LogSoftmax, como antes.

00:06:21.301 --> 00:06:23.819
Pronto, é assim que definimos
o classificador.

00:06:24.457 --> 00:06:26.150
Agora vamos pegar
o classificador,

00:06:26.183 --> 00:06:29.824
que foi construído a partir de
camadas completamente conectadas,

00:06:30.828 --> 00:06:33.892
e podemos anexá-lo
ao nosso modelo,

00:06:34.846 --> 00:06:37.289
fazendo
model.classifier = classifier.

00:06:37.322 --> 00:06:41.074
Agora esse novo classificador,
que não está treinado,

00:06:41.704 --> 00:06:43.253
foi anexado ao nosso modelo,

00:06:43.286 --> 00:06:45.999
que também contém
a parte de características.

00:06:46.538 --> 00:06:48.671
Essa parte
vai ficar congelada.

00:06:48.704 --> 00:06:50.382
Não vamos atualizar
esses pesos,

00:06:50.415 --> 00:06:53.082
mas precisamos treinar
o novo classificador.

00:06:53.115 --> 00:06:55.960
Agora, se quisermos treinar
a rede que usamos,

00:06:55.993 --> 00:06:58.356
essa Densenet-121
é muito profunda,

00:06:58.389 --> 00:06:59.884
com 121 camadas.

00:07:00.122 --> 00:07:03.183
Se tentarmos treinar tudo isso
na CPU, como é normal,

00:07:03.216 --> 00:07:04.688
vai levar uma eternidade.

00:07:04.722 --> 00:07:07.532
Em vez disso,
vamos usar a GPU.

00:07:07.834 --> 00:07:13.451
GPUs podem fazer vários cálculos
de álgebra linear em paralelo

00:07:13.484 --> 00:07:17.829
e redes neurais são, basicamente,
cálculos de álgebra linear.

00:07:18.316 --> 00:07:20.321
Se rodarmos isso na GPU,

00:07:20.354 --> 00:07:24.753
tudo é feito em paralelo
e a velocidade é 100 vezes maior.

00:07:25.451 --> 00:07:30.387
No PyTorch é muito simples
usar a GPU, se você tiver o modelo.

00:07:30.420 --> 00:07:31.594
O modelo...

00:07:31.627 --> 00:07:36.057
A ideia é que seu modelo tenha
vários parâmetros e tensores,

00:07:36.090 --> 00:07:38.957
que estão lá na memória
do seu computador.

00:07:39.186 --> 00:07:41.822
Mas dá para movê-los
para a sua GPU.

00:07:42.213 --> 00:07:43.911
É só fazer model.cuda.

00:07:44.364 --> 00:07:48.696
Isso move os parâmetros
do seu modelo para a GPU

00:07:48.960 --> 00:07:53.578
e agora todos os cálculos
e processamento serão feitos na GPU.

00:07:54.240 --> 00:07:59.112
Se você tiver um tensor,
como as suas imagens,

00:07:59.177 --> 00:08:01.640
e se quiser rodar suas imagens
pelo modelo,

00:08:01.674 --> 00:08:06.252
é preciso garantir que os tensores
que passam pelo modelo estão na GPU,

00:08:06.285 --> 00:08:07.876
se o modelo também estiver.

00:08:07.909 --> 00:08:09.424
Precisam estar no mesmo lugar.

00:08:09.457 --> 00:08:13.285
Para mover um tensor do computador
para a GPU,

00:08:13.318 --> 00:08:15.783
basta fazer, novamente,
images.cuda.

00:08:16.383 --> 00:08:19.618
Isso vai mover o tensor images
para a GPU.

00:08:20.079 --> 00:08:24.315
Frequentemente você vai mover
modelos e tensores

00:08:24.348 --> 00:08:28.359
de volta para a CPU,
tirando da GPU.

00:08:28.392 --> 00:08:32.799
Para fazer isso, basta entrar com:
model.cpu

00:08:33.361 --> 00:08:35.278
ou images.cpu.

00:08:36.579 --> 00:08:40.568
Isso vai tirar
seus tensores da GPU

00:08:40.836 --> 00:08:43.711
e os coloca no seu computador,
para rodar na CPU.

00:08:44.241 --> 00:08:47.370
Agora vou fazer uma demonstração
de como isso funciona

00:08:47.430 --> 00:08:51.746
e do incrível aumento
de velocidade que temos

00:08:51.779 --> 00:08:53.167
ao usar a GPU.

00:08:54.774 --> 00:08:58.831
Aqui eu vou fazer:
for cuda in [False, True].

00:08:58.865 --> 00:09:01.685
Com isso eu vou criar um loop

00:09:01.718 --> 00:09:04.265
para rodar uma vez
quando não estiver usando a GPU

00:09:04.298 --> 00:09:06.226
e outra quando
a estiver usando.

00:09:06.260 --> 00:09:09.184
Vou definir meus critérios,
que serão...

00:09:09.217 --> 00:09:11.185
natural log_loss,
como normalmente

00:09:12.040 --> 00:09:13.729
e definimos o otimizador.

00:09:14.059 --> 00:09:15.281
Lembre que aqui

00:09:15.314 --> 00:09:19.024
só queremos atualizar os parâmetros
do classificador.

00:09:19.394 --> 00:09:22.768
Então vamos fazer só:
model.classifier.parameters.

00:09:23.552 --> 00:09:27.682
Isso vai funcionar e vai atualizar
os parâmetros do classificador,

00:09:27.715 --> 00:09:31.853
mas não vai mexer nos parâmetros
do detector de características.

00:09:32.659 --> 00:09:34.630
Tipicamente vamos fazer:
"se cuda,

00:09:34.663 --> 00:09:38.309
então mova nosso modelo
para a GPU.

00:09:39.553 --> 00:09:42.158
Caso contrário,
deixe-o na CPU."

00:09:42.839 --> 00:09:46.406
Agora vou escrever
um loop de treinamento.

00:09:47.453 --> 00:09:50.755
Temos nossos inputs
e nossos rótulos

00:09:51.308 --> 00:09:53.800
mudando para variáveis,
como é o normal...

00:09:54.648 --> 00:09:58.153
Mas se o cuda estiver ativado,

00:09:58.186 --> 00:09:59.641
se tivermos uma GPU,

00:10:00.196 --> 00:10:02.795
podemos pegar
os inputs e os rótulos

00:10:02.828 --> 00:10:06.207
e colocar tudo na GPU.

00:10:06.972 --> 00:10:10.061
Agora estamos usando a GPU
e a rede pré-treinada também,

00:10:10.095 --> 00:10:11.549
mas em geral,

00:10:11.582 --> 00:10:14.144
vamos fazer o loop
de treinamento

00:10:14.177 --> 00:10:16.124
exatamente do mesmo jeito
que antes,

00:10:16.157 --> 00:10:19.075
como nas redes de feedforward
que você já fez.

00:10:19.395 --> 00:10:22.809
Primeiro eu vou definir
um tempo inicial,

00:10:22.842 --> 00:10:24.081
só para cronometrar,

00:10:24.606 --> 00:10:28.264
e depois você pode mandar treinar,
como sempre.

00:10:28.298 --> 00:10:30.904
Você dá um passo para frente
com seu modelo,

00:10:31.583 --> 00:10:32.943
depois calcula a perda,

00:10:33.500 --> 00:10:35.294
depois faz o passo para trás

00:10:35.327 --> 00:10:38.655
e por fim atualiza os pesos
com o otimizador.

00:10:39.037 --> 00:10:43.837
O que vou fazer aqui
será quebrar o loop de treinamento

00:10:44.283 --> 00:10:47.558
depois das primeiras
três iterações.

00:10:48.345 --> 00:10:53.726
Quero cronometrar a diferença
entre usar a GPU e a CPU.

00:10:53.760 --> 00:10:57.285
O que acontece é que o 1º lote
que passa pelo loop de treinamento

00:10:57.318 --> 00:10:59.210
tende a demorar mais
que os outros,

00:10:59.243 --> 00:11:01.931
então vou pegar
só três ou quatro loops

00:11:01.964 --> 00:11:03.051
e tirar a média,

00:11:03.084 --> 00:11:05.690
só para ter uma ideia
de quanto tempo demora

00:11:05.919 --> 00:11:07.462
para processar um lote.

00:11:10.309 --> 00:11:14.121
Isso vai exibir nossos tempos
de treinamento.

00:11:14.796 --> 00:11:17.561
Dá para ver que,
se não usarmos a GPU,

00:11:17.787 --> 00:11:23.240
cada lote leva 5,5 segundos
para passar pelo treinamento.

00:11:24.147 --> 00:11:26.315
Mas com a GPU

00:11:26.547 --> 00:11:29.212
só leva 0,012 segundos.

00:11:29.599 --> 00:11:32.544
A velocidade
é mais de 100 vezes maior.

00:11:33.619 --> 00:11:36.010
Aqui eu basicamente ajustei
o cuda manualmente,

00:11:36.043 --> 00:11:39.656
mas também dá para ver
se há uma GPU disponível.

00:11:39.689 --> 00:11:42.822
É só fazer:
torch.cuda.is_available

00:11:43.172 --> 00:11:47.953
e a saída vai ser "True" ou "False",
dependendo de você ter uma GPU

00:11:47.986 --> 00:11:49.651
que possa usar o cuda.

00:11:50.452 --> 00:11:54.964
Muito bem, agora vou deixar
você terminar de treinar o modelo.

00:11:55.767 --> 00:11:57.864
Você pode continuar
com o modelo Densenet

00:11:57.897 --> 00:11:59.312
que já carregamos,

00:11:59.345 --> 00:12:02.591
ou pode experimentar o ResNet,
que também é bom.

00:12:02.987 --> 00:12:05.877
Também gosto muito da VGGNet,
acho que é ótimo.

00:12:06.191 --> 00:12:07.585
Você é quem sabe. Abraços!

