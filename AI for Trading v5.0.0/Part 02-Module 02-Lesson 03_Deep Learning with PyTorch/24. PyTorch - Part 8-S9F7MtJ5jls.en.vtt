WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.485
Hello everyone, welcome back.

00:00:01.485 --> 00:00:06.060
So in this network, we will be using a pre-trained network to solve

00:00:06.059 --> 00:00:11.079
this challenging problem of creating a classifier for your cat and dog images.

00:00:11.080 --> 00:00:14.730
These pre-trained networks were trained on ImageNet which is

00:00:14.730 --> 00:00:19.605
a massive dataset of over one million labeled images from 1,000 different categories.

00:00:19.605 --> 00:00:27.105
These are available from torchvision and this module, torchvision.models.

00:00:27.105 --> 00:00:32.560
And so, we see we have six different architectures that we can use,

00:00:32.560 --> 00:00:36.790
and here's a nice breakdown of the performance of each of these different models.

00:00:36.789 --> 00:00:40.644
So, AlexNet gives us the top one error and the top five error.

00:00:40.645 --> 00:00:42.520
So basically, as you see,

00:00:42.520 --> 00:00:45.820
some of these networks and these numbers here,

00:00:45.820 --> 00:00:48.335
19, 11, 34, and so on,

00:00:48.335 --> 00:00:51.429
they usually indicate the number of layers in this model.

00:00:51.429 --> 00:00:52.600
So, the larger this number,

00:00:52.600 --> 00:00:54.085
the larger the model is.

00:00:54.085 --> 00:00:56.634
And accordingly, the larger the model is,

00:00:56.634 --> 00:00:58.734
you get better accuracy,

00:00:58.734 --> 00:01:00.005
you get lower errors.

00:01:00.005 --> 00:01:01.664
At the same time,

00:01:01.664 --> 00:01:03.255
again, the larger the model is,

00:01:03.255 --> 00:01:08.310
the longer it's going to take to compute your predictions and to train and all that.

00:01:08.310 --> 00:01:09.945
So when you're using these,

00:01:09.944 --> 00:01:14.879
you need to think about the tradeoff between accuracy and speed.

00:01:14.879 --> 00:01:20.015
So, all these networks use an architecture called convolutional layers.

00:01:20.015 --> 00:01:24.269
What these do, they exploit patterns and regularities in images.

00:01:24.269 --> 00:01:27.104
I'm not going to get into the details but if you want to learn more about them,

00:01:27.105 --> 00:01:28.760
you can watch this video.

00:01:28.760 --> 00:01:33.359
So we're saying, these deep learning networks are typically very deep.

00:01:33.359 --> 00:01:37.489
So that means, they have dozens or even hundreds of different layers,

00:01:37.489 --> 00:01:40.659
and they were trained on this massive ImageNet dataset.

00:01:40.659 --> 00:01:43.369
It turns out that they were astonishingly well

00:01:43.370 --> 00:01:46.715
as future detectors for images that they weren't trained on.

00:01:46.715 --> 00:01:49.445
So using a pre-trained network like this on

00:01:49.444 --> 00:01:52.524
a training set that it hasn't seen before is called transfer learning.

00:01:52.525 --> 00:01:54.620
So basically, what's learned from

00:01:54.620 --> 00:01:58.730
the ImageNet dataset is being transferred to your dataset.

00:01:58.730 --> 00:02:01.549
So here, we're going to use transfer learning to train

00:02:01.549 --> 00:02:04.774
our own network to classify our cat and dog photos.

00:02:04.775 --> 00:02:09.375
What you'll see is you'll get really good performance with very little work on our side.

00:02:09.375 --> 00:02:13.145
So again, you can download these models from torchvision.models,

00:02:13.145 --> 00:02:17.170
this model here, so we can include this in our imports, right here.

00:02:17.169 --> 00:02:22.459
Most of these pre-trained models require a 224 by 224 image as the input.

00:02:22.460 --> 00:02:24.500
You'll also need to match a normalization

00:02:24.500 --> 00:02:26.719
used when these models were trained on ImageNet.

00:02:26.719 --> 00:02:29.109
So when they train these models,

00:02:29.110 --> 00:02:32.370
each color channel and images were normalized separately.

00:02:32.370 --> 00:02:36.500
And you can see the means here and the standard deviations here.

00:02:36.500 --> 00:02:38.629
So, I'm going to leave it up to you to define

00:02:38.629 --> 00:02:42.115
the transformations for the training data and the testing data now.

00:02:42.115 --> 00:02:44.745
And if you're done, we can get to a new one.

00:02:44.745 --> 00:02:48.560
Now, let's see how we can actually load in one of these models.

00:02:48.560 --> 00:02:52.879
So here, I'm going to use the Densenet-121 model.

00:02:52.879 --> 00:02:56.085
So you see, it has very high accuracy on

00:02:56.085 --> 00:03:03.375
the ImageNet dataset and it's one 121 tells us that it has 121 layers.

00:03:03.375 --> 00:03:06.064
To load this in our code and use it,

00:03:06.064 --> 00:03:14.280
so we just say model models.densenet121 and then we say pretrained equals true.

00:03:14.280 --> 00:03:17.360
So this is going to download the pre-trained network,

00:03:17.360 --> 00:03:19.534
the weights, the parameters themselves,

00:03:19.533 --> 00:03:21.594
and then load it into our model.

00:03:21.594 --> 00:03:27.335
So now, we can do that and then we can look at what the architecture of this model.

00:03:27.335 --> 00:03:31.515
And this is what our DenseNet architecture looks like.

00:03:31.514 --> 00:03:36.500
So, you'll notice that we have this features part here and then a bunch of these layer.

00:03:36.500 --> 00:03:39.409
So this is like a convolutional layer which again I'm not going to talk about

00:03:39.409 --> 00:03:44.025
here but you don't really need to understand it to be able to actually use this thing.

00:03:44.025 --> 00:03:46.500
There's two main parts that we're interested in.

00:03:46.500 --> 00:03:48.314
So firstly, again, this features part,

00:03:48.314 --> 00:03:50.370
but then if we scroll all the way to the bottom,

00:03:50.370 --> 00:03:53.025
we also see this classifier part.

00:03:53.025 --> 00:03:56.010
So we see here is that we have the classifier.

00:03:56.009 --> 00:03:59.399
This has been defined as a linear combination layer,

00:03:59.400 --> 00:04:01.004
it's a fully connected dense layer,

00:04:01.004 --> 00:04:05.324
and it has 1,024 input features and then 1,000 output features.

00:04:05.324 --> 00:04:09.329
So again, the ImageNet dataset has 1,000 different classes.

00:04:09.330 --> 00:04:12.420
And so, the the number of outputs of

00:04:12.419 --> 00:04:15.629
this network should be 1,000 for each of those classes.

00:04:15.629 --> 00:04:19.540
So, the thing to know is that this whole thing was trained on ImageNet.

00:04:19.540 --> 00:04:22.060
Now, the features will work for

00:04:22.060 --> 00:04:26.740
other datasets but the classifier itself has been trained for ImageNet.

00:04:26.740 --> 00:04:29.829
So this is the part that we need to retrain, the classifier.

00:04:29.829 --> 00:04:32.199
We want to keep the feature part static.

00:04:32.199 --> 00:04:33.670
We don't want to update that,

00:04:33.670 --> 00:04:36.225
but we just need to update the classifier part.

00:04:36.225 --> 00:04:41.035
So then, the first thing we need to do is freeze our feature parameters.

00:04:41.035 --> 00:04:47.675
To do that, we go through our parameters in our model.

00:04:47.675 --> 00:04:54.000
And then, we just say, requires_grad equals false.

00:04:54.000 --> 00:04:59.964
So what this will do is that when we run our tensors through the model,

00:04:59.964 --> 00:05:03.250
it's not going to calculate the gradients.

00:05:03.250 --> 00:05:05.860
It's not going to keep track of all these operations.

00:05:05.860 --> 00:05:08.230
So firstly, this is going to ensure that

00:05:08.230 --> 00:05:12.415
our our feature parameters don't get updated but it

00:05:12.415 --> 00:05:15.835
also will speed up training because

00:05:15.834 --> 00:05:19.689
we're not keeping track of these operations for the features.

00:05:19.689 --> 00:05:23.394
Now, we need to replace the classifier with our own classifier.

00:05:23.394 --> 00:05:26.410
So here, I'm going to use a couple of new things.

00:05:26.410 --> 00:05:30.525
I'm going to use the sequential module available from PyTorch.

00:05:30.524 --> 00:05:32.334
And so, what this does, you basically just give it

00:05:32.334 --> 00:05:34.899
a list of different operations you want to

00:05:34.899 --> 00:05:39.608
do and then it will automatically pass a tensor through them sequentially.

00:05:39.608 --> 00:05:45.375
So, you can pass in an ordered dict to name each of these layers.

00:05:45.375 --> 00:05:47.115
So I'll show you how this works.

00:05:47.115 --> 00:05:49.704
So we want a fully connected layer,

00:05:49.704 --> 00:05:51.534
so I'll just name it FC1,

00:05:51.535 --> 00:05:54.939
and then that is a fully connected layer coming from

00:05:54.939 --> 00:05:59.425
1,024 inputs and I'm going to say 500 for this hidden layer.

00:05:59.425 --> 00:06:04.900
And then we want to pass this through ReLu activation and

00:06:04.899 --> 00:06:06.699
then this should go through

00:06:06.699 --> 00:06:10.404
another fully connected layer and this will be our output layer.

00:06:10.404 --> 00:06:13.089
So, 500 to two,

00:06:13.089 --> 00:06:14.379
so we have cat and dog,

00:06:14.379 --> 00:06:15.935
so we want two outputs here.

00:06:15.935 --> 00:06:20.740
And finally, our output is going to be the LogSoftmax like before.

00:06:20.740 --> 00:06:24.009
Okay, and that is how we define the classifier.

00:06:24.009 --> 00:06:26.139
So now, we can take this classifier,

00:06:26.139 --> 00:06:30.500
just a classifier built from fully connected layers,

00:06:30.500 --> 00:06:37.189
and we can attach it to our model.classifier.

00:06:37.189 --> 00:06:40.475
So now, the new classifier that we built that is

00:06:40.475 --> 00:06:45.935
untrained is attached to our model and this model also has the features parts.

00:06:45.935 --> 00:06:48.769
The features parts are going to remain frozen.

00:06:48.769 --> 00:06:52.914
We're not going to update those weights but we need to train our new classifier.

00:06:52.915 --> 00:06:56.030
Now, if we want to train our network that we're using,

00:06:56.029 --> 00:06:59.929
this Densenet-121 is really deep and it has 121 layers.

00:06:59.930 --> 00:07:02.949
So, if we can try to train this on the CPU like normal,

00:07:02.949 --> 00:07:04.694
it's going to take pretty much forever.

00:07:04.694 --> 00:07:07.514
So instead, what we can do is use the GPU.

00:07:07.514 --> 00:07:12.599
GPUs are built specifically for doing a bunch of linear algebra computations in

00:07:12.600 --> 00:07:15.150
parallel and our neural networks are

00:07:15.149 --> 00:07:18.104
basically just a bunch of linear algebra computations.

00:07:18.105 --> 00:07:20.310
So if we run these on the GPU,

00:07:20.310 --> 00:07:25.170
they're done in parallel and we get something like 100 times increase speeds.

00:07:25.170 --> 00:07:29.310
In PyTorch, it's pretty straightforward to use the GPU.

00:07:29.310 --> 00:07:31.875
If you have your model, so model,

00:07:31.875 --> 00:07:35.470
the idea is that your model has all these parameters in there

00:07:35.470 --> 00:07:39.220
tensors that are sitting in your memory on your computer,

00:07:39.220 --> 00:07:44.035
but we can move them over to our GPU by saying model.cuda.

00:07:44.035 --> 00:07:48.790
So what this does is it moves the parameters for your model to the GPU

00:07:48.790 --> 00:07:53.905
and then all of the computations and the processing and are going to be done on the GPU.

00:07:53.904 --> 00:07:59.244
Similarly, if you have a tensor like your images, select images,

00:07:59.245 --> 00:08:01.869
if you want to run your images through your model,

00:08:01.869 --> 00:08:04.720
you have to make sure that the tensors that you're putting

00:08:04.720 --> 00:08:07.690
through your model or on the GPU if your model's on the GPU.

00:08:07.689 --> 00:08:09.370
So you just have to make those match up.

00:08:09.370 --> 00:08:13.209
So to do that, to move a tensor from computer to the GPU,

00:08:13.209 --> 00:08:15.699
you just, again, say images.cuda.

00:08:15.699 --> 00:08:17.834
So that will move a tensor,

00:08:17.834 --> 00:08:19.859
that's images, to the GPU.

00:08:19.860 --> 00:08:24.610
Then oftentimes, you'll want to move your model and your tensors back

00:08:24.610 --> 00:08:29.035
from the GPU to your local memory and CPU, and so, to do that,

00:08:29.035 --> 00:08:35.279
you just say like model.cpu or images.cpu,

00:08:35.279 --> 00:08:39.514
so this'll bring your tensors

00:08:39.514 --> 00:08:43.804
back from the GPU to your local computer to run on your CPU.

00:08:43.804 --> 00:08:47.419
Now, I'm going to give you a demonstration of how this all works

00:08:47.419 --> 00:08:53.860
and the amazing increased speed we get by using the GPU.

00:08:53.860 --> 00:08:58.850
So here, I'm just going to do for cuda and false, true.

00:08:58.850 --> 00:09:01.370
So this way, I'm going to be able to basically like loop

00:09:01.370 --> 00:09:04.190
through and try it once where we're not using the GPU,

00:09:04.190 --> 00:09:06.085
and once where we are using the GPU.

00:09:06.085 --> 00:09:09.045
So let's define my criterion which is going to be

00:09:09.044 --> 00:09:13.594
natural log_loss like we'd normally do, define our optimizer.

00:09:13.595 --> 00:09:19.129
So again, here, remember that we only want to update the parameters for the classifier.

00:09:19.129 --> 00:09:23.284
So we're just going to pass in model.classifier.parameters.

00:09:23.284 --> 00:09:27.799
This will work and that it's going to update the premise for our classifier but

00:09:27.799 --> 00:09:32.344
it's going to lead the parameters for the feature detector part of the model static.

00:09:32.345 --> 00:09:34.759
So I typically do is, say like, if cuda,

00:09:34.759 --> 00:09:39.004
then we want to move our model to the GPU.

00:09:39.004 --> 00:09:42.394
Otherwise, let's leave it on the CPU.

00:09:42.394 --> 00:09:46.985
And then I'm going to write a little training loop.

00:09:46.985 --> 00:09:51.110
We'll get our inputs and our labels,

00:09:51.110 --> 00:09:55.350
changes into variables like normal, then again,

00:09:55.350 --> 00:09:58.139
if we have cuda enabled,

00:09:58.139 --> 00:09:59.865
so if we have GPUs,

00:09:59.865 --> 00:10:02.705
then we can do inputs, labels,

00:10:02.705 --> 00:10:06.585
and we'll just move these over to the GPU.

00:10:06.585 --> 00:10:11.514
We're using the GPU now and we're also using this pre-trained network, but in general,

00:10:11.514 --> 00:10:15.174
you're going to do the training loop exactly the same way

00:10:15.174 --> 00:10:19.254
you have been doing it with these feed forward networks that you've been building.

00:10:19.254 --> 00:10:24.580
So first, I'm actually going to define a start time just so I can time things,

00:10:24.580 --> 00:10:28.315
then you just do your training pass like normal.

00:10:28.315 --> 00:10:33.170
So, you just do a forward pass through your model and you can calculate the loss,

00:10:33.169 --> 00:10:35.189
do your backward pass.

00:10:35.190 --> 00:10:38.760
Finally, update your weights with your optimizer.

00:10:38.759 --> 00:10:42.610
So I'm going to do here, I'm going to break

00:10:42.610 --> 00:10:47.950
this training loop after the first three iterations.

00:10:47.950 --> 00:10:53.815
So I want to time the difference between using a GPU and not using the GPU.

00:10:53.815 --> 00:10:56.440
What happens is the very first batch to go

00:10:56.440 --> 00:10:59.200
through the training loop tends to take longer than the other batches,

00:10:59.200 --> 00:11:03.070
so I'm just going to take the first three or four and then average over those

00:11:03.070 --> 00:11:08.260
just so we get a better sense of how long it actually takes to process one batch.

00:11:09.649 --> 00:11:14.439
So, that will just print out our training times.

00:11:14.440 --> 00:11:17.635
So we can see that if we're not using the GPU,

00:11:17.634 --> 00:11:23.710
then each batch takes five and a half seconds to actually go through this training step.

00:11:23.710 --> 00:11:26.410
Whereas, with the GPU,

00:11:26.409 --> 00:11:29.469
it only takes 0.012 seconds.

00:11:29.470 --> 00:11:33.095
So, I mean, this is a speedup of over 100 times.

00:11:33.095 --> 00:11:37.810
So here, I basically set cuda manually but you can also check

00:11:37.809 --> 00:11:43.134
if a GPU is available so you say torch.cuda is available,

00:11:43.134 --> 00:11:45.924
and this will give you back true or false depending if you have

00:11:45.924 --> 00:11:49.949
a GPU available that can use cuda.

00:11:49.950 --> 00:11:51.845
Okay, so from here,

00:11:51.845 --> 00:11:55.375
I'm going to let you finish training this model.

00:11:55.375 --> 00:11:58.779
So you can either continue with a DenseNet model that is already

00:11:58.779 --> 00:12:02.799
loaded or you can try ResNet which is also a good model to try out.

00:12:02.799 --> 00:12:04.689
I also really like VGGNet,

00:12:04.690 --> 00:12:06.025
I think that one's pretty good.

00:12:06.024 --> 00:12:07.799
It's really up to you. Cheers.

