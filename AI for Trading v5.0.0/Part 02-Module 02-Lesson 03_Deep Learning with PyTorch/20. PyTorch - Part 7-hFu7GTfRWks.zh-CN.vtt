WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.065
在这一段视频中 我将演示如何加载图像数据

00:00:04.065 --> 00:00:08.670
这对实际项目非常有用

00:00:08.669 --> 00:00:10.800
我们之前用过 MNIST

00:00:10.800 --> 00:00:16.125
Fashion-MNIST 是用于测试网络的样本数据集

00:00:16.125 --> 00:00:20.550
但现在要用的是全尺寸图像 它们可能是智能手机的照相机拍摄的 也可能

00:00:20.550 --> 00:00:25.475
来自深度学习网络创建的实际项目

00:00:25.475 --> 00:00:30.375
我们将使用猫狗照片的数据集 它们非常可爱

00:00:30.375 --> 00:00:33.030
这个数据集来自 Kaggle 要了解更多信息

00:00:33.030 --> 00:00:34.350
可以点击这个链接

00:00:34.350 --> 00:00:37.480
可以看出 与 MNIST 和 fashion-MNIST 中的图像相比

00:00:37.479 --> 00:00:39.599
这些图像尺寸大得多 分辨率大得多

00:00:39.600 --> 00:00:44.609
具有不同形状和尺寸

00:00:44.609 --> 00:00:49.335
第一步就是用 PyTorch 加载这些图像

00:00:49.335 --> 00:00:50.880
加载之后

00:00:50.880 --> 00:00:54.165
可以用它们训练网络

00:00:54.164 --> 00:00:58.304
加载图像数据的最简单方法是 datasets.ImageFolder

00:00:58.304 --> 00:01:01.019
这个数据集模块来自 torchvision

00:01:01.020 --> 00:01:05.480
可以将数据集的路径

00:01:05.480 --> 00:01:07.130
传入到数据所在的

00:01:07.129 --> 00:01:10.159
图像文件夹 执行 transforms

00:01:10.159 --> 00:01:11.420
我们之前讲过 transforms

00:01:11.420 --> 00:01:14.950
接下来我将详细讲解

00:01:14.950 --> 00:01:16.600
图像文件夹中的

00:01:16.599 --> 00:01:19.354
文件和目录应这样创建

00:01:19.355 --> 00:01:22.609
所有数据都应存在根目录中

00:01:22.609 --> 00:01:25.635
每个不同的类应有单独的文件夹

00:01:25.635 --> 00:01:28.020
现在有两个类

00:01:28.019 --> 00:01:29.280
狗和猫

00:01:29.280 --> 00:01:32.030
所以有两个文件夹 狗和猫

00:01:32.030 --> 00:01:34.625
MNIST 中的类更多

00:01:34.625 --> 00:01:35.659
有十个类

00:01:35.659 --> 00:01:39.450
每个不同数字都会有一个文件夹 对吧？

00:01:39.450 --> 00:01:41.385
这些就是类或标签

00:01:41.385 --> 00:01:45.660
在每个特定类文件夹内

00:01:45.659 --> 00:01:48.795
图像都属于这个类

00:01:48.795 --> 00:01:50.579
所以 狗文件夹里都是狗的图像

00:01:50.579 --> 00:01:53.939
猫文件夹里都是猫的图像

00:01:53.939 --> 00:01:56.204
如果在 workspace 内操作

00:01:56.204 --> 00:01:57.870
数据应该已经存在

00:01:57.870 --> 00:01:59.760
但是如果在本地计算机上操作

00:01:59.760 --> 00:02:01.665
可以点击这里获取数据

00:02:01.665 --> 00:02:05.220
我已经把它分成一个训练集和一个测试集

00:02:05.219 --> 00:02:07.004
在图像文件夹中加载时

00:02:07.004 --> 00:02:09.180
需要定义 transforms

00:02:09.180 --> 00:02:13.135
也就是可以缩放 剪裁

00:02:13.134 --> 00:02:17.479
也可以转换成

00:02:17.479 --> 00:02:22.060
PyTorch 张量 以 PiIlow 图像的形式加载

00:02:22.060 --> 00:02:24.580
所以 需要将图片转换成张量

00:02:24.580 --> 00:02:27.320
然后使用 transforms.compose 将这些

00:02:27.319 --> 00:02:30.489
transforms 合并成 transforms 管道

00:02:30.490 --> 00:02:34.879
如果想把图像缩放成 255*255

00:02:34.879 --> 00:02:39.500
写入 transforms.resize 255 只取中间部分

00:02:39.500 --> 00:02:43.099
裁剪成 224*224

00:02:43.099 --> 00:02:45.120
然后将其转换成张量

00:02:45.120 --> 00:02:49.295
这些 transforms 你都会用到 将其传入 ImageFolder

00:02:49.294 --> 00:02:54.224
定义用于图像的 transforms

00:02:54.224 --> 00:02:58.305
图像文件夹中有数据集之后

00:02:58.305 --> 00:03:01.830
定义 transforms 并将其传入数据加载器

00:03:01.830 --> 00:03:04.410
可以在这里定义批量大小

00:03:04.409 --> 00:03:07.680
也就是每批的图像数量 一批就是这个数据加载器中的一个循环

00:03:07.680 --> 00:03:13.125
然后可以将混排设为“真”

00:03:13.125 --> 00:03:15.134
混排就是

00:03:15.134 --> 00:03:18.509
每次开始新周期时随机排列数据

00:03:18.509 --> 00:03:23.174
这个非常有用 因为在训练网络时

00:03:23.175 --> 00:03:28.530
我们希望网络第二次看见的图像呈现不同顺序

00:03:28.530 --> 00:03:31.064
第三次看见的图像又呈现另一种顺序

00:03:31.064 --> 00:03:35.370
而不是每次都按相同顺序进行学习 因为

00:03:35.370 --> 00:03:39.944
网络对数据进行学习时 会出现伪迹

00:03:39.944 --> 00:03:41.625
请记住

00:03:41.625 --> 00:03:44.280
从这个类数据加载器中获取的数据加载器

00:03:44.280 --> 00:03:47.580
实际的数据加载器对象本身是一个生成器

00:03:47.580 --> 00:03:51.825
如需从中获得数据 必须对其进行循环

00:03:51.824 --> 00:03:56.159
例如 for 循环 或者调用 iter

00:03:56.159 --> 00:03:57.314
转换成迭代器

00:03:57.314 --> 00:04:01.259
然后调用 next 从中获取数据

00:04:01.259 --> 00:04:04.359
这个 for 循环

00:04:04.360 --> 00:04:09.160
for images, labels in dataloader 实际上将其转换成迭代器

00:04:09.159 --> 00:04:11.395
每次进行循环时 就会调用 next

00:04:11.395 --> 00:04:14.795
所以 这个 for 循环是自动进行的

00:04:14.794 --> 00:04:18.519
好了 现在请你定义 transforms

00:04:18.519 --> 00:04:23.589
创建并传入图像件夹 然后创建数据加载器

00:04:23.589 --> 00:04:25.389
完成之后

00:04:25.389 --> 00:04:29.324
会看到这样的图像

00:04:29.324 --> 00:04:32.649
这就是加载数据的方法

00:04:32.649 --> 00:04:35.389
也可以进行数据扩张

00:04:35.389 --> 00:04:41.870
它是给数据本身赋予随机性

00:04:41.870 --> 00:04:45.259
如果有一组图像

00:04:45.259 --> 00:04:49.399
可以变动猫图像的显示位置 旋转猫图像

00:04:49.399 --> 00:04:50.614
缩放猫图像

00:04:50.615 --> 00:04:52.925
剪裁不同部位

00:04:52.925 --> 00:04:55.449
也可以进行横向或竖向镜像调整

00:04:55.449 --> 00:04:58.849
这有助于网络进行泛化

00:04:58.850 --> 00:05:02.550
因为它看到的图像呈现不同比例

00:05:02.550 --> 00:05:05.500
不同方向等

00:05:05.500 --> 00:05:09.959
这有助于训练网络

00:05:09.959 --> 00:05:14.819
最终在验证测试中获得更高的准确度

00:05:14.819 --> 00:05:18.899
现在请你对训练数据定义 transforms

00:05:18.899 --> 00:05:20.879
可以进行数据扩张

00:05:20.879 --> 00:05:25.199
随机剪裁 缩放和旋转图像

00:05:25.199 --> 00:05:30.149
为测试数据集定义 transforms

00:05:30.149 --> 00:05:33.719
请记住 在测试期间进行验证时

00:05:33.720 --> 00:05:36.660
不需要进行任何数据扩张

00:05:36.660 --> 00:05:42.495
只需要缩放和剪裁图像

00:05:42.495 --> 00:05:45.949
这是因为 我们希望验证结果

00:05:45.949 --> 00:05:49.469
接近模型的最终状态

00:05:49.470 --> 00:05:50.580
训练数据时

00:05:50.579 --> 00:05:53.219
要发送猫狗的图像

00:05:53.220 --> 00:05:56.000
我们希望验证集非常接近

00:05:56.000 --> 00:06:00.370
最终输入的图像

00:06:00.370 --> 00:06:02.139
如果操作正确

00:06:02.139 --> 00:06:04.490
会看到这样的训练样本

00:06:04.490 --> 00:06:06.530
可以看出它们有没有旋转

00:06:06.529 --> 00:06:08.614
测试样本是这样的

00:06:08.615 --> 00:06:13.280
按比例缩放 没有旋转

00:06:13.279 --> 00:06:14.989
加载数据之后

00:06:14.990 --> 00:06:18.230
应尝试按照所学知识建立网络

00:06:18.230 --> 00:06:22.200
使其能够对这个数据集中的猫和狗进行分类

00:06:22.199 --> 00:06:27.599
提醒你一下 这实际是一个非常难的挑战 很可能不会成功

00:06:27.600 --> 00:06:30.450
所以 不必过于辛苦尝试

00:06:30.449 --> 00:06:33.420
你之前使用了 MNIST 和 fashion-IMNIST

00:06:33.420 --> 00:06:36.240
图像都非常简单 对吧？

00:06:36.240 --> 00:06:37.829
大小是 20*28

00:06:37.829 --> 00:06:40.979
而是都是灰度图像

00:06:40.980 --> 00:06:43.995
但是现在这些猫狗图像大得多

00:06:43.995 --> 00:06:47.204
颜色复杂 所以有三个颜色通道

00:06:47.204 --> 00:06:50.925
总体而言 建立一个能够通过全连接网络

00:06:50.925 --> 00:06:56.009
实现这一点的分类器 会非常难

00:06:56.009 --> 00:06:59.969
在下一部分 我将演示如何使用预训练网络构建模型

00:06:59.970 --> 00:07:04.130
从而对这些猫狗图像进行分类 谢谢

