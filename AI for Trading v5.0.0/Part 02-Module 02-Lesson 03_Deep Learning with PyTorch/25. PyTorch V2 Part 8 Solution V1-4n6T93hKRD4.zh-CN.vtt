WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.530
现在说说上道练习的答案

00:00:04.530 --> 00:00:05.910
这次我将采用不同的讲解方式

00:00:05.910 --> 00:00:09.900
我将一边输入代码一边讲解

00:00:09.900 --> 00:00:14.565
实际上是将在这节课所学的所有知识结合到了一起

00:00:14.565 --> 00:00:16.785
首先

00:00:16.785 --> 00:00:18.900
如果我有 GPU

00:00:18.900 --> 00:00:23.895
我将先询问 GPU 设备是否可用

00:00:23.895 --> 00:00:30.255
输入 device = torch.device 在这里添加 cuda

00:00:30.255 --> 00:00:40.290
If torch.cuda.is_available() else “cpu”

00:00:40.290 --> 00:00:42.240
这行代码的作用是

00:00:42.240 --> 00:00:44.565
如果 GPU 可用

00:00:44.565 --> 00:00:50.330
这个将为 True 在这里返回 cuda 否则返回 CPU

00:00:50.330 --> 00:00:53.990
现在我们可以将 device 传递给所有张量和模型

00:00:53.990 --> 00:00:57.700
如果 GPU 可用 则自动使用 GPU

00:00:57.700 --> 00:01:02.490
接下来获取预训练的模型

00:01:02.490 --> 00:01:04.440
我将使用 ResNet

00:01:04.440 --> 00:01:07.290
输入 model = models

00:01:07.290 --> 00:01:09.140
我们已经从 torchvision 导入 models

00:01:09.140 --> 00:01:12.850
菜单中列出了所有模型

00:01:12.850 --> 00:01:14.565
ResNet 在这里

00:01:14.565 --> 00:01:16.545
我将使用很小的模型 选择 resnet50

00:01:16.545 --> 00:01:22.905
输入 pretrained=True 这样应该就能获得该模型

00:01:22.905 --> 00:01:24.630
好了

00:01:24.630 --> 00:01:27.650
像这样输出模型

00:01:27.650 --> 00:01:31.490
就会显示出所有不同的操作和层级等

00:01:31.490 --> 00:01:36.260
向下滚动到末尾 可以看到这个 fc

00:01:36.260 --> 00:01:38.300
表示最后一层

00:01:38.300 --> 00:01:40.840
是一个充当分类器的全连接层

00:01:40.840 --> 00:01:42.480
它要求这层输入为 2,048 个单元

00:01:42.480 --> 00:01:47.660
输出为 1,000 个单元

00:01:47.660 --> 00:01:51.830
这个模型是用 ImageNet 训练的

00:01:51.830 --> 00:01:56.610
ImageNet 用有 1,000 个不同类别的图像训练而成

00:01:56.610 --> 00:01:58.720
但是我们只使用猫和狗图像

00:01:58.720 --> 00:02:02.035
因此这个分类器只需 2 个输出单元

00:02:02.035 --> 00:02:06.410
我们可以加载这样的模型

00:02:06.410 --> 00:02:08.630
确保在训练模型时冻结模型参数

00:02:08.630 --> 00:02:11.615
这样就不会更新这些参数

00:02:11.615 --> 00:02:14.275
运行这部分代码 看看是否没有任何问题

00:02:14.275 --> 00:02:19.325
现在加载模型并关闭梯度

00:02:19.325 --> 00:02:21.980
关闭模型的梯度

00:02:21.980 --> 00:02:24.965
下一步是

00:02:24.965 --> 00:02:29.975
定义新分类器

00:02:29.975 --> 00:02:31.715
这一步可以很简单

00:02:31.715 --> 00:02:34.850
输入 models= nn.sequential

00:02:34.850 --> 00:02:36.440
用很多不同的定义方式可以用

00:02:36.440 --> 00:02:39.220
我使用 nn.sequential

00:02:39.220 --> 00:02:42.145
第一个层级是线性层级

00:02:42.145 --> 00:02:47.585
我们需要 248 个输入

00:02:47.585 --> 00:02:53.080
缩减到 512 个 添加 ReLu 层、丢弃层

00:02:53.080 --> 00:02:54.840
然后是输出层

00:02:54.840 --> 00:03:01.950
512 到 2 调用 LogSoftmax

00:03:01.950 --> 00:03:05.850
应该将这个改为 classifier.

00:03:05.850 --> 00:03:09.590
Ok.定义好 classifier 将其附加到模型上

00:03:09.590 --> 00:03:13.580
输入 model.fc= classifier

00:03:13.580 --> 00:03:16.639
再次查看模型

00:03:16.639 --> 00:03:19.270
向下滚动到底部

00:03:19.270 --> 00:03:23.960
可以看出现在这个全连接层是一个序列分类器 

00:03:23.960 --> 00:03:28.550
这里是线性操作 然后是 ReLu

00:03:28.550 --> 00:03:32.740
丢弃层 另一个线性转换 然后是 log softmax

00:03:32.740 --> 00:03:36.740
接下来定义损失/条件

00:03:36.740 --> 00:03:40.700
设为负对数似然损失

00:03:40.700 --> 00:03:47.935
然后定义优化器 等于 optim.Adam

00:03:47.935 --> 00:03:52.130
我们想使用分类器中的参数

00:03:52.130 --> 00:03:57.160
分类器是这个 fc 然后设置学习速率

00:03:57.160 --> 00:04:03.640
最后一步是将模型移到可用的设备上

00:04:03.640 --> 00:04:07.825
设置好模型后 现在开始训练模型

00:04:07.825 --> 00:04:10.459
首先我将定义一些

00:04:10.459 --> 00:04:13.430
将在训练过程中使用的变量

00:04:13.430 --> 00:04:16.580
例如我将周期设为 1

00:04:16.580 --> 00:04:19.130
跟踪训练步数

00:04:19.130 --> 00:04:20.555
设为 0

00:04:20.555 --> 00:04:22.645
跟踪损失

00:04:22.645 --> 00:04:26.215
也设为 0

00:04:26.215 --> 00:04:29.270
最后设置一个循环

00:04:29.270 --> 00:04:33.820
表示在输出验证损失之前训练多少步

00:04:33.820 --> 00:04:36.960
遍历周期

00:04:36.960 --> 00:04:41.730
for epoch in range(epochs)

00:04:41.730 --> 00:04:46.245
遍历图像数据

00:04:46.245 --> 00:04:52.005
for images, labels in trainloader

00:04:52.005 --> 00:04:54.500
递增步数 每次经过一个批次

00:04:54.500 --> 00:04:56.590
步数都递增

00:04:56.590 --> 00:04:58.850
现在已经获得图像和标签

00:04:58.850 --> 00:05:04.160
如果有 GPU 则将它们移到 GPU 上

00:05:04.160 --> 00:05:13.685
= images.to(device), labels.to(device)

00:05:13.685 --> 00:05:17.820
现在编写训练循环

00:05:17.820 --> 00:05:22.680
首先清零梯度

00:05:22.680 --> 00:05:25.170
这是很重要的步骤 一定不要忘记了

00:05:25.170 --> 00:05:28.730
然后从模型中获取对数概率

00:05:28.730 --> 00:05:33.170
传入 images 获得对数概率后

00:05:33.170 --> 00:05:37.520
我们可以从 criterion 获取损失 传入 labels

00:05:37.520 --> 00:05:42.665
然后执行反向传播 最后执行优化器步骤

00:05:42.665 --> 00:05:47.630
递增 running_loss

00:05:47.630 --> 00:05:50.030
这样的话 当我们用越来越多的数据训练模型后

00:05:50.030 --> 00:05:52.440
可以跟踪训练损失好了

00:05:52.440 --> 00:05:54.075
这就是训练循环

00:05:54.075 --> 00:05:58.730
我们希望每隔一段时间输出结果 即这个 print_every 变量

00:05:58.730 --> 00:06:02.685
现在 我们要退出训练循环

00:06:02.685 --> 00:06:07.400
使用测试数据集测试网络的准确率和损失

00:06:07.400 --> 00:06:12.395
输入 for step %% print_every == 0:

00:06:12.395 --> 00:06:15.860
如果等于 0 则进入验证循环

00:06:15.860 --> 00:06:18.480
首先调用 model.eval

00:06:18.480 --> 00:06:24.965
将模型变成评估推理模式 这样会关闭丢弃

00:06:24.965 --> 00:06:28.670
从而准确地使用网络做出预测

00:06:28.670 --> 00:06:34.260
设置测试损失和准确率

00:06:34.260 --> 00:06:40.310
从测试数据中获取图像和标签

00:06:40.310 --> 00:06:42.410
执行验证循环

00:06:42.410 --> 00:06:47.030
向模型中传入图像

00:06:47.030 --> 00:06:49.480
这些图像来自测试集

00:06:49.480 --> 00:06:53.835
从测试集获取 logps

00:06:53.835 --> 00:07:01.280
通过 criterion 获取损失 输入 test_loss += loss.item() 来跟踪损失

00:07:01.280 --> 00:07:04.280
这样 在经过这些验证循环时

00:07:04.280 --> 00:07:08.200
可以跟踪测试损失

00:07:08.200 --> 00:07:12.020
接下来计算准确率

00:07:12.020 --> 00:07:17.390
Ps = torch.exp(logps)

00:07:17.390 --> 00:07:20.790
模型返回的是 log softmax

00:07:20.790 --> 00:07:25.460
表示类别的对数概率

00:07:25.460 --> 00:07:27.380
要获取实际概率 我们将使用 torch.exp

00:07:27.380 --> 00:07:34.230
top_ps, top_class = ps.topk(1)

00:07:34.230 --> 00:07:39.950
获得最大概率

00:07:39.950 --> 00:07:43.490
将维度设为 1

00:07:43.490 --> 00:07:47.215
这样可以确保沿着列查找最高概率

00:07:47.215 --> 00:07:48.760
获得最高概率后

00:07:48.760 --> 00:07:56.300
检查是否和标签匹配

00:07:56.300 --> 00:07:58.280
根据 equality 张量更新 accuracy

00:07:58.280 --> 00:08:03.155
我们可以从 equality 计算 accuracy

00:08:03.155 --> 00:08:05.660
更改为浮点数张量后

00:08:05.660 --> 00:08:08.210
就可以运行torch.mean 并获得 accuracy

00:08:08.210 --> 00:08:13.320
递增这个 accuracy 变量好了

00:08:13.320 --> 00:08:18.305
现在我们位于这个 for 循环里 for step %% print_every

00:08:18.305 --> 00:08:23.375
获得训练损失 running_loss 和测试损失 test_loss

00:08:23.375 --> 00:08:26.240
将测试数据传入模型中

00:08:26.240 --> 00:08:29.140
并衡量损失和准确率

00:08:29.140 --> 00:08:30.855
现在输出所有这些结果

00:08:30.855 --> 00:08:33.580
直接复制粘贴这段代码 手动输入的话 代码太多了

00:08:33.580 --> 00:08:37.070
在这里输出 epochs

00:08:37.070 --> 00:08:40.475
不断跟踪进度

00:08:40.475 --> 00:08:43.610
用 running_loss 除以 print_every

00:08:43.610 --> 00:08:46.640
对训练损失取平均值

00:08:46.640 --> 00:08:47.855
每次输出时

00:08:47.855 --> 00:08:49.610
都会取平均值

00:08:49.610 --> 00:08:52.910
用 test_loss 除以 testloader 的长度

00:08:52.910 --> 00:08:56.630
len(testloader) 表示

00:08:56.630 --> 00:09:00.540
我们从 testloader 获得了多少批数据

00:09:00.540 --> 00:09:03.950
因为我们对每批的损失求和

00:09:03.950 --> 00:09:05.750
所以 如果用总损失除以批次数量

00:09:05.750 --> 00:09:07.910
就能得出平均损失

00:09:07.910 --> 00:09:09.815
准确率也一样

00:09:09.815 --> 00:09:13.820
对每个批次的准确率求和

00:09:13.820 --> 00:09:18.540
然后除以批次数量 得出测试集的平均准确率

00:09:18.540 --> 00:09:19.880
最后

00:09:19.880 --> 00:09:23.600
将 running_loss 设为 0

00:09:23.600 --> 00:09:29.095
并将模型设为训练模式

00:09:29.095 --> 00:09:34.475
好了这些就是训练代码 看看能否运行

00:09:34.475 --> 00:09:38.410
这里应该是 if 而不是 for

00:09:38.410 --> 00:09:41.945
这里我忘记将张量转移到 GPU 上了

00:09:41.945 --> 00:09:48.515
这种情况很常见

00:09:48.515 --> 00:09:51.095
希望能运行好的

00:09:51.095 --> 00:09:53.805
测试准确率超过了 95%

00:09:53.805 --> 00:09:57.820
甚至速度很快

00:09:57.820 --> 00:10:00.710
我们每隔五个周期都输出结果

00:10:00.710 --> 00:10:04.400
因此总共 15 个批次

00:10:04.400 --> 00:10:06.950
我们用 15 批数据训练了模型

00:10:06.950 --> 00:10:10.850
太好了 我们学习了如何轻松地调整这些分类器

00:10:10.850 --> 00:10:15.530
并在数据集上获得超过 95% 的准确率

