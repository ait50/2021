WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.695
现在我们将讨论

00:00:01.695 --> 00:00:04.785
推理和验证过程

00:00:04.785 --> 00:00:06.915
训练好网络后

00:00:06.915 --> 00:00:09.555
我们会用它做预测

00:00:09.555 --> 00:00:11.070
这个过程称之为推理

00:00:11.070 --> 00:00:13.350
这个词来自统计学

00:00:13.350 --> 00:00:16.620
但是

00:00:16.620 --> 00:00:18.360
神经网络往往在训练数据上表现太好

00:00:18.360 --> 00:00:21.170
以至于无法泛化到网络尚未见过的数据

00:00:21.170 --> 00:00:22.940
这个问题称之为过拟合

00:00:22.940 --> 00:00:27.585
当我们在训练集上训练的时间越来越长

00:00:27.585 --> 00:00:29.720
网络会开始发现并学习一些仅适用于该训练集的关系和规律

00:00:29.720 --> 00:00:32.045
但是这些关系和规律并不适用于泛化数据集 即

00:00:32.045 --> 00:00:37.025
包含所有其他任何手写数字的数据集

00:00:37.025 --> 00:00:39.305
要检测过拟合问题

00:00:39.305 --> 00:00:45.260
我们使用非训练集中的数据衡量网络的效果

00:00:45.260 --> 00:00:48.440
这种数据通常称为验证集或测试集

00:00:48.440 --> 00:00:52.370
在用验证集衡量效果时

00:00:52.370 --> 00:00:57.545
我们还会通过丢弃等正则化方法减少过拟合现象

00:00:57.545 --> 00:00:58.895
在此 notebook 中

00:00:58.895 --> 00:01:02.705
我将演示如何查看验证集

00:01:02.705 --> 00:01:06.985
以及如何使用丢弃减少过拟合现象

00:01:06.985 --> 00:01:10.830
要从 PyTorch 中获取训练集

00:01:10.830 --> 00:01:14.855
先将 fashionMNIST 设置为 train=true

00:01:14.855 --> 00:01:16.070
要获取测试集

00:01:16.070 --> 00:01:18.395
在这里设置为 train=false

00:01:18.395 --> 00:01:21.175
在这里像之前一样定义模型

00:01:21.175 --> 00:01:24.200
验证的目标是

00:01:24.200 --> 00:01:28.190
衡量模型在非训练集中的数据上的效果

00:01:28.190 --> 00:01:31.805
效果标准由开发者来决定

00:01:31.805 --> 00:01:34.105
即由写代码的人来决定

00:01:34.105 --> 00:01:37.005
很多时候我们会使用准确率来衡量

00:01:37.005 --> 00:01:40.970
即在所有模型预测中

00:01:40.970 --> 00:01:45.340
正确预测所占的百分比

00:01:45.340 --> 00:01:48.500
其他衡量指标包括精确率和召回率

00:01:48.500 --> 00:01:50.615
以及 top-5 错误率

00:01:50.615 --> 00:01:55.475
我将演示如何衡量在验证集上的准确率

00:01:55.475 --> 00:01:58.390
首先 我将对测试集中的一批数据进行前向传播

00:01:58.390 --> 00:02:01.850
在测试集中获得概率

00:02:01.850 --> 00:02:05.210
一批数据有 64 个样本

00:02:05.210 --> 00:02:08.180
然后是 10 列 每个类别对应一列

00:02:08.180 --> 00:02:11.330
准确率衡量的是

00:02:11.330 --> 00:02:14.445
模型对给定图像的类别是否预测正确

00:02:14.445 --> 00:02:19.220
预测结果可以看做概率最高的类别

00:02:19.220 --> 00:02:24.780
我们可以对张量使用 top-k 方法

00:02:24.780 --> 00:02:27.195
它会返回前 k 个值

00:02:27.195 --> 00:02:29.265
如果传入 1

00:02:29.265 --> 00:02:33.105
那么将返回最高的值

00:02:33.105 --> 00:02:38.560
这个最高值表示网络预测的概率最高的类别

00:02:38.560 --> 00:02:40.755
对于我获取的这批测试数据

00:02:40.755 --> 00:02:45.340
这十个样本来说

00:02:45.340 --> 00:02:50.500
我们看到类别 4 和 5 是预测结果

00:02:50.500 --> 00:02:53.090
注意 这个网络尚未经过训练

00:02:53.090 --> 00:02:55.370
只是随机地做出预测

00:02:55.370 --> 00:02:58.690
因为它对数据还完全不了解

00:02:58.690 --> 00:03:01.670
top-k 返回一个包含两个张量的元组

00:03:01.670 --> 00:03:04.460
第一个张量是实际概率值

00:03:04.460 --> 00:03:07.760
第二个张量是类别索引本身

00:03:07.760 --> 00:03:10.595
通常我们希望获得这个 top_class

00:03:10.595 --> 00:03:16.220
在这里调用 topk 并将概率和类别分开

00:03:16.220 --> 00:03:18.745
接下来我们将使用这个 top_class

00:03:18.745 --> 00:03:22.850
获得网络的预测类别后

00:03:22.850 --> 00:03:25.085
我们可以用它与真实标签进行比较

00:03:25.085 --> 00:03:28.590
输入 top_class == labels

00:03:28.590 --> 00:03:31.310
这里需要注意的是

00:03:31.310 --> 00:03:34.700
需要确保 top_class 张量和 labels 张量形状一样

00:03:34.700 --> 00:03:39.520
这样才能进行相等性判断

00:03:39.520 --> 00:03:47.480
来自 testloader 的 labels 是一个一维张量 有 64 个元素

00:03:47.480 --> 00:03:52.240
但是 top_class 本身是一个二维张量 大小是 64 x 1

00:03:52.240 --> 00:03:57.845
我在这里更改了 labels 的形状

00:03:57.845 --> 00:04:01.250
使其与 top_class 的形状一样

00:04:01.250 --> 00:04:03.015
看看结果怎么样

00:04:03.015 --> 00:04:04.520
里面有大量 0 和 1

00:04:04.520 --> 00:04:05.990
0 表示不匹配

00:04:05.990 --> 00:04:07.745
1 表示匹配

00:04:07.745 --> 00:04:10.985
这个张量由大量 0 和 1 组成

00:04:10.985 --> 00:04:14.850
如果要计算准确率

00:04:14.850 --> 00:04:17.355
我们可以算出

00:04:17.355 --> 00:04:18.600
所有正确的预测数量之和

00:04:18.600 --> 00:04:20.960
然后除以预测总数

00:04:20.960 --> 00:04:23.780
如果张量全是 0 和 1

00:04:23.780 --> 00:04:25.955
就相当于取均值

00:04:25.955 --> 00:04:27.940
因此输入 torch.mean

00:04:27.940 --> 00:04:32.650
但问题是 equals 是字节张量

00:04:32.650 --> 00:04:36.100
而 torch.mean 不适用于字节张量

00:04:36.100 --> 00:04:39.335
因此我们需要将 equals 转换为浮点数张量

00:04:39.335 --> 00:04:42.050
然后可以看出

00:04:42.050 --> 00:04:45.200
这个批次的准确率是 15.6%

00:04:45.200 --> 00:04:47.180
在我们的预期范围内

00:04:47.180 --> 00:04:49.010
网络尚未训练

00:04:49.010 --> 00:04:51.590
只是随机地做出猜测

00:04:51.590 --> 00:04:56.060
因此对于任何特定图像 准确率应该约为 1/10

00:04:56.060 --> 00:05:01.910
即 只是均匀地猜测其中一个类别

00:05:01.910 --> 00:05:05.105
下面你的任务是实现这个验证循环

00:05:05.105 --> 00:05:07.970
将测试集中的数据传入网络中

00:05:07.970 --> 00:05:12.260
并计算损失和准确率

00:05:12.260 --> 00:05:15.025
要注意的一点是

00:05:15.025 --> 00:05:18.860
对于验证流程 我们不进行任何训练操作

00:05:18.860 --> 00:05:20.435
因此不需要梯度

00:05:20.435 --> 00:05:24.695
如果关闭梯度的话 代码运行速度会稍微加快

00:05:24.695 --> 00:05:26.570
通过 with torch.no_grad 设置上下文

00:05:26.570 --> 00:05:30.215
将验证流程放入这个上下文里

00:05:30.215 --> 00:05:34.435
输入 for images, labels in testloader 然后在这里执行验证流程

00:05:34.435 --> 00:05:39.215
基本就是这样

00:05:39.215 --> 00:05:43.460
这是训练流程 你需要实现验证流程

00:05:43.460 --> 00:05:45.590
然后输出准确率

00:05:45.590 --> 00:05:47.070
试试吧加油

00:05:47.070 --> 00:05:49.680
如果遇到问题或需要帮助

00:05:49.680 --> 00:05:51.600
请参阅我的解决方案

