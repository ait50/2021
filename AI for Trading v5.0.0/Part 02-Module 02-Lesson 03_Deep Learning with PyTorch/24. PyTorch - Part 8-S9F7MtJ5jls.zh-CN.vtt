WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.485
大家好 欢迎回来

00:00:01.485 --> 00:00:06.060
在这个网络中 我们将使用预训练网络

00:00:06.059 --> 00:00:11.079
解决创建猫狗图像分类器的难题

00:00:11.080 --> 00:00:14.730
这些预训练网络是在 ImageNet 上训练的

00:00:14.730 --> 00:00:19.605
ImageNet 是一个大型数据集 包含超过一百万张有标记图像 具有 1000 种不同类别

00:00:19.605 --> 00:00:27.105
可以从 torchvision 的 torchvision.models 模型中获取这些图像

00:00:27.105 --> 00:00:32.560
可以使用的架构有六种

00:00:32.560 --> 00:00:36.790
这是每个模型的性能的细分表

00:00:36.789 --> 00:00:40.644
AlexNet 显示 top-1 错误率和 top-5 错误率

00:00:40.645 --> 00:00:42.520
可以看出

00:00:42.520 --> 00:00:45.820
在这些网络中 这些数字

00:00:45.820 --> 00:00:48.335
19 11 34 等等

00:00:48.335 --> 00:00:51.429
通常表示的是模型中的层数

00:00:51.429 --> 00:00:52.600
数字越大

00:00:52.600 --> 00:00:54.085
模型越大

00:00:54.085 --> 00:00:56.634
模型越大

00:00:56.634 --> 00:00:58.734
准确度越高

00:00:58.734 --> 00:01:00.005
错误率越低

00:01:00.005 --> 00:01:01.664
同时

00:01:01.664 --> 00:01:03.255
模型越大

00:01:03.255 --> 00:01:08.310
计算预测值和训练所需的时间越长

00:01:08.310 --> 00:01:09.945
所以 使用这些模型时

00:01:09.944 --> 00:01:14.879
需要在准确度和速度之间权衡

00:01:14.879 --> 00:01:20.015
所有这些网络使用的架构称为卷积层

00:01:20.015 --> 00:01:24.269
卷积层会挖掘图像中的图案和规则性

00:01:24.269 --> 00:01:27.104
这里不做详细讲解 想要了解更多

00:01:27.105 --> 00:01:28.760
可以观看这个视频

00:01:28.760 --> 00:01:33.359
这些深度学习网络一般非常深

00:01:33.359 --> 00:01:37.489
换句话说 它们有几十个甚至几百个层

00:01:37.489 --> 00:01:40.659
并且在 ImageNet 大型数据集中对其进行了训练

00:01:40.659 --> 00:01:43.369
我们发现 对于未训练过的图像

00:01:43.370 --> 00:01:46.715
它们检测特征的效果非常好

00:01:46.715 --> 00:01:49.445
对未见过的训练集使用

00:01:49.444 --> 00:01:52.524
这种预训练网络 称为迁移学习

00:01:52.525 --> 00:01:54.620
在 ImageNet 数据集中学习的东西

00:01:54.620 --> 00:01:58.730
都会迁移到你的数据集中

00:01:58.730 --> 00:02:01.549
我们将利用迁移学习训练自己的网络

00:02:01.549 --> 00:02:04.774
从而对猫狗图像进行分类

00:02:04.775 --> 00:02:09.375
你会发现 我们需要做的很少 但是性能非常好

00:02:09.375 --> 00:02:13.145
可以从 torchvision.models 模型中下载这些模型

00:02:13.145 --> 00:02:17.170
将其添加到这里的导入内容中

00:02:17.169 --> 00:02:22.459
大多数预训练模型需要 224*224 的图像作为输入

00:02:22.460 --> 00:02:24.500
在 ImageNet 上训练这些模型时

00:02:24.500 --> 00:02:26.719
还需要匹配所使用的归一化函数

00:02:26.719 --> 00:02:29.109
所以 训练这些模型时

00:02:29.110 --> 00:02:32.370
每个颜色通道和图像都会单独归一化

00:02:32.370 --> 00:02:36.500
这些是均值 这些是标准偏差

00:02:36.500 --> 00:02:38.629
现在请你定义训练数据和

00:02:38.629 --> 00:02:42.115
测试数据的转换

00:02:42.115 --> 00:02:44.745
完成之后 可以进行下一个单元

00:02:44.745 --> 00:02:48.560
我们现在看一下 如何加载模型

00:02:48.560 --> 00:02:52.879
我将使用 Densenet-121 模型

00:02:52.879 --> 00:02:56.085
它对 ImageNet 数据集的准确度非常高

00:02:56.085 --> 00:03:03.375
121 表示它有 121 层

00:03:03.375 --> 00:03:06.064
为了把它加载到代码中并使用

00:03:06.064 --> 00:03:14.280
输入 model = models.densenet121(pretrained=True)

00:03:14.280 --> 00:03:17.360
将会下载预训练网络

00:03:17.360 --> 00:03:19.534
权重 参数本身

00:03:19.533 --> 00:03:21.594
然后加载到模型中

00:03:21.594 --> 00:03:27.335
现在可以看一下模型的架构

00:03:27.335 --> 00:03:31.515
这就是 DenseNet 架构

00:03:31.514 --> 00:03:36.500
你会发现这里有个特征部分 还有多个层

00:03:36.500 --> 00:03:39.409
这是卷积层 这里不做讲解

00:03:39.409 --> 00:03:44.025
即使不理解也可以使用

00:03:44.025 --> 00:03:46.500
我们感兴趣的主要有两个部分

00:03:46.500 --> 00:03:48.314
第一个是特征部分

00:03:48.314 --> 00:03:50.370
一直拉到底

00:03:50.370 --> 00:03:53.025
可以看到分类器部分

00:03:53.025 --> 00:03:56.010
这里可以看到分类器

00:03:56.009 --> 00:03:59.399
它被定义为线性组合层

00:03:59.400 --> 00:04:01.004
是一个全连接密集层

00:04:01.004 --> 00:04:05.324
有 1024 个输入特征 1000 个输出特征

00:04:05.324 --> 00:04:09.329
所以 ImageNet 数据集有 1000 个不同类

00:04:09.330 --> 00:04:12.420
这个网络的输出数量

00:04:12.419 --> 00:04:15.629
应该是每个类 1000 个

00:04:15.629 --> 00:04:19.540
要注意的是 整个网络是在 ImageNet 上训练的

00:04:19.540 --> 00:04:22.060
特征对其它数据集也适用

00:04:22.060 --> 00:04:26.740
但分类器本身是针对 ImageNet 训练的

00:04:26.740 --> 00:04:29.829
所以 分类器需要重新训练

00:04:29.829 --> 00:04:32.199
我们想让特征部分保持不变

00:04:32.199 --> 00:04:33.670
不更新

00:04:33.670 --> 00:04:36.225
但需要更新分类器部分

00:04:36.225 --> 00:04:41.035
首先需要冻结特征参数

00:04:41.035 --> 00:04:47.675
遍历模型中的参数

00:04:47.675 --> 00:04:54.000
然后输入 requires_grad = False

00:04:54.000 --> 00:04:59.964
这样 在模型中运行张量时

00:04:59.964 --> 00:05:03.250
不会计算梯度

00:05:03.250 --> 00:05:05.860
不会跟踪所有运算

00:05:05.860 --> 00:05:08.230
这是为了确保

00:05:08.230 --> 00:05:12.415
特征参数不被更新

00:05:12.415 --> 00:05:15.835
同时加快训练速度

00:05:15.834 --> 00:05:19.689
因为没有跟踪特征的运算

00:05:19.689 --> 00:05:23.394
现在需要把这个分类器替换成我们自己的分类器

00:05:23.394 --> 00:05:26.410
我将使用几个新东西

00:05:26.410 --> 00:05:30.525
我将使用 sequential 模型 它可以从 PyTorch 中获取

00:05:30.524 --> 00:05:32.334
给它提供一个你想进行的

00:05:32.334 --> 00:05:34.899
运算列表

00:05:34.899 --> 00:05:39.608
它会自动依次传入张量

00:05:39.608 --> 00:05:45.375
可以传入一个有序字典 对每个层进行命名

00:05:45.375 --> 00:05:47.115
我将演示如何操作

00:05:47.115 --> 00:05:49.704
需要一个全连接层

00:05:49.704 --> 00:05:51.534
将其命名为 FC1

00:05:51.535 --> 00:05:54.939
这个全连接层

00:05:54.939 --> 00:05:59.425
有 1024 个输入 隐藏层有 500 个输入

00:05:59.425 --> 00:06:04.900
然后进行 ReLu 激活

00:06:04.899 --> 00:06:06.699
然后前往

00:06:06.699 --> 00:06:10.404
另一个全连接层 即输出层

00:06:10.404 --> 00:06:13.089
500, 2

00:06:13.089 --> 00:06:14.379
我们有猫和狗的图像

00:06:14.379 --> 00:06:15.935
所以有两个输出

00:06:15.935 --> 00:06:20.740
最后的输出是 LogSoftmax 和之前一样

00:06:20.740 --> 00:06:24.009
这就是分类器的定义步骤

00:06:24.009 --> 00:06:26.139
现在可以将

00:06:26.139 --> 00:06:30.500
用全连接层构建的分类器

00:06:30.500 --> 00:06:37.189
附加到 model.classifier 中

00:06:37.189 --> 00:06:40.475
现在 构建的未训练的新分类器

00:06:40.475 --> 00:06:45.935
已附加到模型中 这个模型也具有特征部分

00:06:45.935 --> 00:06:48.769
特征部分将保持不变

00:06:48.769 --> 00:06:52.914
我们不会更新权重 但需要训练新的分类器

00:06:52.915 --> 00:06:56.030
如果想要训练正在使用的网络

00:06:56.029 --> 00:06:59.929
Densenet-121 非常深 有 121 个层

00:06:59.930 --> 00:07:02.949
如果尝试在普通 CPU 上训练

00:07:02.949 --> 00:07:04.694
将要花费很长时间

00:07:04.694 --> 00:07:07.514
所以可以使用 GPU

00:07:07.514 --> 00:07:12.599
GPU 是为了同时进行多个线性代数计算而专门构建的

00:07:12.600 --> 00:07:15.150
神经网络一般是

00:07:15.149 --> 00:07:18.104
由多个线性代数计算组成

00:07:18.105 --> 00:07:20.310
在 GPU 上

00:07:20.310 --> 00:07:25.170
这些计算会同时进行 速度会提高 100 倍

00:07:25.170 --> 00:07:29.310
在 PyTorch 中 GPU 的使用非常简单

00:07:29.310 --> 00:07:31.875
如果有模型

00:07:31.875 --> 00:07:35.470
模型的所有参数都是张量的形式

00:07:35.470 --> 00:07:39.220
位于计算机的内存中

00:07:39.220 --> 00:07:44.035
但可以通过 model.cuda 将其移动到 GPU 中

00:07:44.035 --> 00:07:48.790
这样就把模型的参数移动到 GPU 中

00:07:48.790 --> 00:07:53.905
所有的计算和处理都会在 GPU 中完成

00:07:53.904 --> 00:07:59.244
同样 如果有张量 例如 图像

00:07:59.245 --> 00:08:01.869
如果想在模型中运行图像

00:08:01.869 --> 00:08:04.720
如果模型在 GPU 中

00:08:04.720 --> 00:08:07.690
必须确保模型中的张量也在 GPU 中

00:08:07.689 --> 00:08:09.370
必须将其匹配起来

00:08:09.370 --> 00:08:13.209
如需将张量从计算机移动到 GPU

00:08:13.209 --> 00:08:15.699
可以使用 images.cuda

00:08:15.699 --> 00:08:17.834
这可以将张量

00:08:17.834 --> 00:08:19.859
也就是图像 移动到 GPU

00:08:19.860 --> 00:08:24.610
我们经常需要把模型的张量

00:08:24.610 --> 00:08:29.035
从 GPU 移回本地内存和 CPU

00:08:29.035 --> 00:08:35.279
可以使用 model.cpu 或 images.cpu

00:08:35.279 --> 00:08:39.514
这样就将张量

00:08:39.514 --> 00:08:43.804
从 GPU 移回本地计算机 从而在 CPU 上运行

00:08:43.804 --> 00:08:47.419
现在我将演示如何进行这个过程

00:08:47.419 --> 00:08:53.860
以及 GPU 对速度有多大的提升

00:08:53.860 --> 00:08:58.850
执行 for cuda in [False, True]

00:08:58.850 --> 00:09:01.370
这样就能在不使用 GPU

00:09:01.370 --> 00:09:04.190
的情况和使用 GPU 的

00:09:04.190 --> 00:09:06.085
情况之间循环

00:09:06.085 --> 00:09:09.045
像平常一样 将条件定义为

00:09:09.044 --> 00:09:13.594
nn.NLLLoss 然后定义优化器

00:09:13.595 --> 00:09:19.129
记住 我们只想更新分类器的参数

00:09:19.129 --> 00:09:23.284
所以只传入 model.classifier.parameters

00:09:23.284 --> 00:09:27.799
这样将会更新分类器的参数

00:09:27.799 --> 00:09:32.344
但模型特征检测器部分的参数保持不变

00:09:32.345 --> 00:09:34.759
输入 if cuda

00:09:34.759 --> 00:09:39.004
将模型移动到 GPU

00:09:39.004 --> 00:09:42.394
否则将其保留在 CPU

00:09:42.394 --> 00:09:46.985
然后编写一个简短的训练循环

00:09:46.985 --> 00:09:51.110
像平常一样 将输入和标签

00:09:51.110 --> 00:09:55.350
转换成变量

00:09:55.350 --> 00:09:58.139
如果启用了 cuda

00:09:58.139 --> 00:09:59.865
如果有 GPU

00:09:59.865 --> 00:10:02.705
那么可以将输入 标签

00:10:02.705 --> 00:10:06.585
移动到 GPU

00:10:06.585 --> 00:10:11.514
我们使用了 GPU 也使用了预训练网络

00:10:11.514 --> 00:10:15.174
但是一般来说 训练循环应该和

00:10:15.174 --> 00:10:19.254
你建立的前馈网络中使用的完全相同

00:10:19.254 --> 00:10:24.580
首先 定义一个起始时间 便于计时

00:10:24.580 --> 00:10:28.315
然后像平常一样进行训练时的完整遍历

00:10:28.315 --> 00:10:33.170
在模型中进行前向传播遍历 然后计算损失

00:10:33.169 --> 00:10:35.189
进行反向传播遍历

00:10:35.190 --> 00:10:38.760
最后 更新优化器的权重

00:10:38.759 --> 00:10:42.610
在前三次迭代之后

00:10:42.610 --> 00:10:47.950
我现在将中断这个训练循环

00:10:47.950 --> 00:10:53.815
我想对使用 GPU 和不使用 GPU 的两种情况之间的差别进行计时

00:10:53.815 --> 00:10:56.440
结果表明 训练循环中的

00:10:56.440 --> 00:10:59.200
第一批花费的时间多于其它批

00:10:59.200 --> 00:11:03.070
所以取前三批或前四批 取其平均值

00:11:03.070 --> 00:11:08.260
以便更好分析处理一批实际所花费的时间

00:11:09.649 --> 00:11:14.439
这一步会打印出训练次数

00:11:14.440 --> 00:11:17.635
可以看出 如果不使用 GPU

00:11:17.634 --> 00:11:23.710
每批进行训练步骤实际花费的时间是五秒半

00:11:23.710 --> 00:11:26.410
但在使用 GPU 时

00:11:26.409 --> 00:11:29.469
只需 0.012 秒

00:11:29.470 --> 00:11:33.095
这意味着速度提升了 100 倍以上

00:11:33.095 --> 00:11:37.810
我是手动设置 cuda 的 你也可以检查

00:11:37.809 --> 00:11:43.134
GPU 是否可用 输入 torch.cuda.is_available

00:11:43.134 --> 00:11:45.924
根据是否有可以使用 cuda 的 GPU

00:11:45.924 --> 00:11:49.949
将会返回“真”或“假”

00:11:49.950 --> 00:11:51.845
从现在开始

00:11:51.845 --> 00:11:55.375
请你完成这个模型的训练

00:11:55.375 --> 00:11:58.779
可以继续使用已经加载的 DenseNet 模型

00:11:58.779 --> 00:12:02.799
也可以尝试 ResNet

00:12:02.799 --> 00:12:04.689
我也喜欢用 VGGNet

00:12:04.690 --> 00:12:06.025
这个也很不错

00:12:06.024 --> 00:12:07.799
具体由你决定 谢谢

