WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:05.670
欢迎回来下面说说我是如何使用丢弃构建和训练此网络的

00:00:05.670 --> 00:00:06.975
首先

00:00:06.975 --> 00:00:10.590
将丢弃模块设为 self.dropout

00:00:10.590 --> 00:00:14.985
self.dropout = nn.dropout 设定丢弃概率

00:00:14.985 --> 00:00:16.320
我设为 20%

00:00:16.320 --> 00:00:20.895
添加到 forward 方法中 经过每个隐藏层

00:00:20.895 --> 00:00:23.960
验证代码看起来和之前的基本一样

00:00:23.960 --> 00:00:26.750
但是现在我们使用 model.eval

00:00:26.750 --> 00:00:29.315
将模型变成评估/推理模式

00:00:29.315 --> 00:00:32.725
这样会关闭丢弃

00:00:32.725 --> 00:00:34.890
然后和之前一样

00:00:34.890 --> 00:00:37.255
传入测试集中的数据

00:00:37.255 --> 00:00:40.820
计算损失和准确率

00:00:40.820 --> 00:00:44.465
然后运行 model.train 将模型设回训练模式

00:00:44.465 --> 00:00:47.080
开启丢弃

00:00:47.080 --> 00:00:48.860
继续训练更多数据

00:00:48.860 --> 00:00:52.775
现在我们使用了丢弃

00:00:52.775 --> 00:00:57.460
查看这些周期之后的训练损失和验证损失

00:00:57.460 --> 00:01:00.140
可以看出当我们继续训练之后

00:01:00.140 --> 00:01:03.445
验证损失和训练损失很接近

00:01:03.445 --> 00:01:07.805
因此使用丢弃后 至少减少了过拟合现象

00:01:07.805 --> 00:01:15.395
虽然验证损失没有达到不使用丢弃时那么低

00:01:15.395 --> 00:01:17.610
但是依然降低了

00:01:17.610 --> 00:01:19.840
如果我们训练更长时间

00:01:19.840 --> 00:01:25.600
很有可能验证损失会比不使用丢弃时更低

