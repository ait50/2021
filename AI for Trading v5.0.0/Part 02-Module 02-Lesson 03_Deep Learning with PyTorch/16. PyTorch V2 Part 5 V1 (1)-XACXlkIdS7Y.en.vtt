WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.695
Hey there. So now,

00:00:01.695 --> 00:00:04.785
we're going to start talking about inference and validation.

00:00:04.785 --> 00:00:06.915
So, when you have your trained network,

00:00:06.915 --> 00:00:09.554
you typically want to use it for making predictions.

00:00:09.554 --> 00:00:11.070
This is called inference,

00:00:11.070 --> 00:00:13.349
it's a term borrowed from statistics.

00:00:13.349 --> 00:00:16.620
However, neural networks have a tendency to perform too well on

00:00:16.620 --> 00:00:18.359
your training data and they aren't able to

00:00:18.359 --> 00:00:21.169
generalize the data that your network hasn't seen before.

00:00:21.170 --> 00:00:22.940
This is called overfitting.

00:00:22.940 --> 00:00:27.585
This happens because as you're training more and more and more on your training set,

00:00:27.585 --> 00:00:29.719
your network starts to pick up correlations and

00:00:29.719 --> 00:00:32.045
patterns that are in your training set but they aren't

00:00:32.045 --> 00:00:37.025
in the more general dataset of all possible handwritten digits.

00:00:37.024 --> 00:00:39.304
So, to test for overfitting,

00:00:39.304 --> 00:00:45.259
we measure the performance of the network on data that isn't in the training set.

00:00:45.259 --> 00:00:48.439
This data is usually called the validation set or the test set.

00:00:48.439 --> 00:00:52.369
So, while we measure the performance on the validation set,

00:00:52.369 --> 00:00:57.544
we also tried to reduce overfitting through regularization such as dropout.

00:00:57.545 --> 00:00:58.895
So, in this notebook,

00:00:58.895 --> 00:01:02.705
I'll show you how we can both look at

00:01:02.704 --> 00:01:06.984
our validation set and also use dropout to reduce overfitting.

00:01:06.984 --> 00:01:10.829
So, to get the training set for your data like from PyTorch,

00:01:10.829 --> 00:01:14.855
then we say train equals true and for fashionMNIST.

00:01:14.855 --> 00:01:16.070
To get our test set,

00:01:16.069 --> 00:01:18.394
we're actually going to set train equals false here.

00:01:18.394 --> 00:01:21.174
Here, I'm just defining the model like we did before.

00:01:21.174 --> 00:01:24.200
So, the goal of validation is to measure

00:01:24.200 --> 00:01:28.189
our model's performance on data that is not part of our training set.

00:01:28.189 --> 00:01:31.804
But what we mean by performance is up to you,

00:01:31.805 --> 00:01:34.105
up to the developer, the person who's writing the code.

00:01:34.105 --> 00:01:37.005
A lot of times, it'll just be the accuracy.

00:01:37.004 --> 00:01:40.969
So, like how many correct classifications did

00:01:40.969 --> 00:01:45.340
our model make compared to all of the predictions?

00:01:45.340 --> 00:01:48.500
And other options for metrics are precision and recall,

00:01:48.500 --> 00:01:50.614
and the top five error rate.

00:01:50.614 --> 00:01:55.474
So here, I'll show you how to actually measure the accuracy on the validation set.

00:01:55.474 --> 00:01:58.390
So first, I'm going to do a forward pass that is one batch from the test set.

00:01:58.390 --> 00:02:01.849
So, see in our test set we get our probabilities.

00:02:01.849 --> 00:02:05.209
So, just 64 examples in a batch.

00:02:05.209 --> 00:02:08.180
Then 10 columns like one for each of the classes.

00:02:08.180 --> 00:02:11.330
So, the accuracy, we want to see if our model made

00:02:11.330 --> 00:02:14.445
the correct prediction of the class given the image.

00:02:14.444 --> 00:02:19.219
The prediction we can consider it to be whichever class has the highest probability.

00:02:19.219 --> 00:02:24.780
So, for this, we can use this top-k method on our tensors.

00:02:24.780 --> 00:02:27.194
This returns the k highest values.

00:02:27.194 --> 00:02:29.264
So, if we pass in one,

00:02:29.264 --> 00:02:33.104
then this is going to give us the one highest value.

00:02:33.104 --> 00:02:38.560
This one highest value is the most likely class that our network is predicting.

00:02:38.560 --> 00:02:40.754
So, for the first ten examples,

00:02:40.754 --> 00:02:45.340
and this batch of test data that I grabbed,

00:02:45.340 --> 00:02:50.500
we see that the class four and class five are what are being predicted for these.

00:02:50.500 --> 00:02:53.090
So, remember that this network actually hasn't been trained yet,

00:02:53.090 --> 00:02:55.370
and so it's just making these guesses randomly because

00:02:55.370 --> 00:02:58.689
it doesn't really know anything about the data yet.

00:02:58.689 --> 00:03:01.669
So, top-k actually returns a tuple with two tensors.

00:03:01.669 --> 00:03:04.459
So, the first tensor is the actual probability values,

00:03:04.460 --> 00:03:07.760
and the second tensor are the class indices themselves.

00:03:07.759 --> 00:03:10.594
So typically, we just want this top class here.

00:03:10.594 --> 00:03:16.219
So, I'm calling top-k here and I'm separating out the probabilities in the classes.

00:03:16.219 --> 00:03:18.745
So, we'll just use this top class going forward.

00:03:18.745 --> 00:03:22.849
So, now that we have the predicted classes from our network,

00:03:22.849 --> 00:03:25.085
we can compare that with the true labels.

00:03:25.085 --> 00:03:28.590
So, we say, we can say like top class equals equals labels.

00:03:28.590 --> 00:03:31.310
The only trick here is that we need to make

00:03:31.310 --> 00:03:34.699
sure our top class tensor and the labels tensor has the same shape.

00:03:34.699 --> 00:03:39.519
So, this equality actually operates appropriately like we expect.

00:03:39.520 --> 00:03:47.480
So, labels from the test loader is actually a 1D tensor with 64 elements,

00:03:47.479 --> 00:03:52.239
but top class itself is a 2D tensor, 64 by one.

00:03:52.240 --> 00:03:57.844
So here, I'm just like changing the shape of labels to match the shape of top class.

00:03:57.844 --> 00:04:01.250
This gives us this equals tensor.

00:04:01.250 --> 00:04:03.014
We can actually see it looks like.

00:04:03.014 --> 00:04:04.519
So, it gives us a bunch of zeros and ones.

00:04:04.520 --> 00:04:05.990
So, zeros are where they don't match,

00:04:05.990 --> 00:04:07.745
and then ones are where they do match.

00:04:07.745 --> 00:04:10.985
Now, we have this tensor that's all just a bunch of zeros and ones.

00:04:10.985 --> 00:04:14.850
So, if we want to know the accuracy, right?

00:04:14.849 --> 00:04:17.355
We can just sum up all the correct things,

00:04:17.355 --> 00:04:18.600
all the correct predictions,

00:04:18.600 --> 00:04:20.960
and then divide by the total number of predictions.

00:04:20.959 --> 00:04:23.779
If you're tensor is all zeros and ones,

00:04:23.779 --> 00:04:25.954
that's actually equivalent to taking the mean.

00:04:25.954 --> 00:04:27.939
So for that, we can do torch.mean,

00:04:27.939 --> 00:04:32.649
but the problem is that equals is actually a byte tensor,

00:04:32.649 --> 00:04:36.099
and torch.mean won't work on byte tensors.

00:04:36.100 --> 00:04:39.335
So, we actually need to convert equals until a float tensor.

00:04:39.334 --> 00:04:42.049
If we do that, then we can actually see our accuracy for

00:04:42.050 --> 00:04:45.199
this one particular batch is 15.6 percent.

00:04:45.199 --> 00:04:47.180
So, this is roughly what we expect.

00:04:47.180 --> 00:04:49.009
So, our network hasn't been trained yet.

00:04:49.009 --> 00:04:51.589
It's making pretty much random guesses.

00:04:51.589 --> 00:04:56.060
That means that we should see our accuracy be about one in ten for

00:04:56.060 --> 00:05:01.910
any particular image because it's just uniformly guessing one of the classes, okay?

00:05:01.910 --> 00:05:05.105
So here, I'm going to have you actually implement this validation loop,

00:05:05.105 --> 00:05:07.970
where you'll pass in data from

00:05:07.970 --> 00:05:12.260
the test set through the network and calculate the loss and the accuracy.

00:05:12.259 --> 00:05:15.024
So, one thing to note, I think I mentioned this before.

00:05:15.024 --> 00:05:18.859
For the validation paths, we're not actually going to be doing any training.

00:05:18.860 --> 00:05:20.435
So, we don't need the gradients.

00:05:20.435 --> 00:05:24.694
So, you can actually speed up your code a little bit if you turn off the gradients.

00:05:24.694 --> 00:05:26.569
So, using this context,

00:05:26.569 --> 00:05:30.214
so with torch.no_grad, then you can put your validation pass in here.

00:05:30.214 --> 00:05:34.435
So, for images and labels in your test loader and then do the validation pass here.

00:05:34.435 --> 00:05:39.214
So, I've basically built a classifier for you, set all this up.

00:05:39.214 --> 00:05:43.459
Here's the training pass, and then it's up to you to implement the validation pass,

00:05:43.459 --> 00:05:45.589
and then print out the accuracy.

00:05:45.589 --> 00:05:47.069
All right. Good luck,

00:05:47.069 --> 00:05:49.680
and if you get stuck or want any help,

00:05:49.680 --> 00:05:51.600
be sure to check out my solution.

