WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:01.080
在上个视频中

00:00:01.080 --> 00:00:02.625
我们的练习是

00:00:02.625 --> 00:00:05.610
要求你自己来构建神经网络

00:00:05.610 --> 00:00:09.015
并对这个数据集中的服饰进行分类

00:00:09.015 --> 00:00:12.900
现在说说我的构建方式

00:00:12.900 --> 00:00:14.685
首先构建网络

00:00:14.685 --> 00:00:18.270
从 PyTorch 中导入正常的模块

00:00:18.270 --> 00:00:19.665
导入 nn 和 optim

00:00:19.665 --> 00:00:21.630
nn 使我们能够构建网络

00:00:21.630 --> 00:00:23.565
optim 可以为我们提供优化器

00:00:23.565 --> 00:00:26.100
我们必须导入这个函数式模块

00:00:26.100 --> 00:00:30.015
这样才能使用 ReLU 和 log_softmax 等函数

00:00:30.015 --> 00:00:33.810
我决定使用类定义网络架构

00:00:33.810 --> 00:00:36.150
设为 nn.module 子类

00:00:36.150 --> 00:00:37.650
称为 classifier

00:00:37.650 --> 00:00:41.270
然后创建四个不同的线性转换

00:00:41.270 --> 00:00:45.935
即三个隐藏层和一个输出层

00:00:45.935 --> 00:00:49.190
第一个隐藏层有 256 个单元

00:00:49.190 --> 00:00:50.990
第二个隐藏层有 128 个单元

00:00:50.990 --> 00:00:52.560
第三个有 64 个单元

00:00:52.560 --> 00:00:55.200
输出有 10 个单元

00:00:55.200 --> 00:00:57.330
在前向传播里我执行的操作有所不同

00:00:57.330 --> 00:01:01.385
我在这里扁平化了输入张量

00:01:01.385 --> 00:01:06.050
这样你就不用在训练循环中扁平化输入张量了

00:01:06.050 --> 00:01:08.335
在前向传播里就会扁平化

00:01:08.335 --> 00:01:10.305
输入 x.view

00:01:10.305 --> 00:01:12.645
它将更改形状

00:01:12.645 --> 00:01:16.185
x.shape[0] 表示批次大小

00:01:16.185 --> 00:01:19.460
这里的 -1

00:01:19.460 --> 00:01:21.590
将决定第二个维度的大小

00:01:21.590 --> 00:01:24.320
同时使元素总数量保持不变

00:01:24.320 --> 00:01:27.530
这样会生成另一个张量

00:01:27.530 --> 00:01:30.560
它是输入张量的扁平化版本

00:01:30.560 --> 00:01:33.455
经过这些线性转换

00:01:33.455 --> 00:01:36.025
然后经过 ReLU 激活函数

00:01:36.025 --> 00:01:40.550
最后是 log_softmax 维度设为 1

00:01:40.550 --> 00:01:43.205
这就是输出 从 forward 函数中返回它

00:01:43.205 --> 00:01:44.585
定义好模型后

00:01:44.585 --> 00:01:46.970
在这里输入 model = classifier

00:01:46.970 --> 00:01:48.460
这样就会创建模型

00:01:48.460 --> 00:01:53.435
然后将 criterion 设为负对数似然损失

00:01:53.435 --> 00:01:56.300
我将模型输入设为 log_softmax

00:01:56.300 --> 00:02:00.010
并将 criterion 设为 NLLLoss

00:02:00.010 --> 00:02:03.150
然后使用 Adam 优化器

00:02:03.150 --> 00:02:07.070
它和随机梯度下降法基本一样

00:02:07.070 --> 00:02:10.265
但是具有一些优势

00:02:10.265 --> 00:02:14.570
它会使用动力加速拟合流程

00:02:14.570 --> 00:02:21.610
它还会调整模型中每个参数的学习速率

00:02:21.610 --> 00:02:24.465
这是训练循环

00:02:24.465 --> 00:02:26.674
我同样使用了 5 个周期

00:02:26.674 --> 00:02:28.670
for e in range(epoch):

00:02:28.670 --> 00:02:31.955
这样会遍历数据集五次

00:02:31.955 --> 00:02:35.090
使用 running_loss 跟踪损失

00:02:35.090 --> 00:02:36.900
在这里初始化它

00:02:36.900 --> 00:02:38.565
然后获取图像

00:02:38.565 --> 00:02:41.175
for images, labels in trainloader

00:02:41.175 --> 00:02:45.635
通过将图像传入模型里获取对数概率

00:02:45.635 --> 00:02:48.020
要注意的一点是 这里有个捷径

00:02:48.020 --> 00:02:51.320
如果将 model 当做函数并将图像直接传入 model 中

00:02:51.320 --> 00:02:53.810
model 将运行 forward 方法

00:02:53.810 --> 00:02:59.635
这是对模型进行前向传播的简便方式

00:02:59.635 --> 00:03:02.060
然后使用对数概率和标签

00:03:02.060 --> 00:03:03.560
计算损失

00:03:03.560 --> 00:03:06.110
在这里清理梯度

00:03:06.110 --> 00:03:09.485
在这里运行 loss_backward() 以计算梯度

00:03:09.485 --> 00:03:11.890
获得梯度后 执行优化器步骤

00:03:11.890 --> 00:03:14.210
我们会看到

00:03:14.210 --> 00:03:17.645
五个周期后 损失开始下降了

00:03:17.645 --> 00:03:18.860
训练好网络后

00:03:18.860 --> 00:03:20.555
我们可以测试网络

00:03:20.555 --> 00:03:24.965
向模型中传入数据 计算概率

00:03:24.965 --> 00:03:28.130
在这里对模型进行前向传播

00:03:28.130 --> 00:03:31.510
获得对数概率

00:03:31.510 --> 00:03:33.980
然后计算指数以获得实际概率

00:03:33.980 --> 00:03:38.875
然后传入到我编写的这个 view_classify 辅助函数里

00:03:38.875 --> 00:03:40.365
可以看到

00:03:40.365 --> 00:03:42.110
如果我们传入衬衫图像

00:03:42.110 --> 00:03:44.195
它将告诉我们这是衬衫

00:03:44.195 --> 00:03:47.975
初步看来 网络学习的效果还不错

00:03:47.975 --> 00:03:50.800
能判断出数据集里的内容是什么

