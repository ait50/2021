WEBVTT
Kind: captions
Language: zh-CN

00:00:00.000 --> 00:00:04.620
下面介绍如何实现训练流程

00:00:04.620 --> 00:00:07.620
在这里正常地定义模型

00:00:07.620 --> 00:00:10.110
在这里设置负对数似然损失

00:00:10.110 --> 00:00:13.095
使用随机梯度下降法 传入参数

00:00:13.095 --> 00:00:15.510
这是训练流程

00:00:15.510 --> 00:00:18.150
对于 trainloader 中的每个图像和标签

00:00:18.150 --> 00:00:23.190
我们会先扁平化 然后使用 optimizer.zero_grad 清理梯度

00:00:23.190 --> 00:00:26.970
使图像在模型里前向传播 获得输出

00:00:26.970 --> 00:00:28.820
然后计算损失

00:00:28.820 --> 00:00:31.130
执行反向传播

00:00:31.130 --> 00:00:32.960
最后使用梯度执行优化器步骤

00:00:32.960 --> 00:00:36.260
运行这个单元格 

00:00:36.260 --> 00:00:40.305
会看到损失逐渐降低 对吧

00:00:40.305 --> 00:00:41.925
一共训练 5 个周期

00:00:41.925 --> 00:00:43.380
在第一个周期

00:00:43.380 --> 00:00:47.430
损失很高 为 1.9 继续训练 我们会看到损失不断降低

00:00:47.430 --> 00:00:51.950
5 个周期之后 损失已经降低了很多

00:00:51.950 --> 00:00:54.950
如果我们不断训练网络

00:00:54.950 --> 00:00:58.445
它将越来越了解数据 训练损失变得更低

00:00:58.445 --> 00:01:00.740
训练好网络后

00:01:00.740 --> 00:01:05.655
可以看看网络对这些图像的预测效果

00:01:05.655 --> 00:01:08.700
传入一个图像

00:01:08.700 --> 00:01:11.630
例如图像 2

00:01:11.630 --> 00:01:14.610
这是现在网络的预测结果

00:01:14.610 --> 00:01:19.190
太棒了

00:01:19.190 --> 00:01:23.480
概率最高的类别是数字 2

00:01:23.480 --> 00:01:29.460
再试一遍 传入数字 8 再次预测出 8

00:01:29.460 --> 00:01:31.655
我们的网络已经训练完成

00:01:31.655 --> 00:01:34.970
可以对数字做出正确的预测

00:01:34.970 --> 00:01:37.730
下一步你将编写代码 用一个更复杂的数据集训练神经网络

00:01:37.730 --> 00:01:41.420
你会需要自己完成整个流程

00:01:41.420 --> 00:01:46.070
包括定义模型 运行训练循环 等等加油！

