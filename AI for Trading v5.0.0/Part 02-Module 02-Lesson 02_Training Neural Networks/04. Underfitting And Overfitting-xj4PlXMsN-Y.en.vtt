WEBVTT
Kind: captions
Language: en

00:00:00.000 --> 00:00:01.710
So, let's talk about life.

00:00:01.710 --> 00:00:04.650
In life, there are two mistakes one can make.

00:00:04.650 --> 00:00:08.330
One is to try to kill Godzilla using a flyswatter.

00:00:08.330 --> 00:00:12.330
The other one is to try to kill a fly using a bazooka.

00:00:12.330 --> 00:00:16.125
What's the problem with trying to kill Godzilla with a flyswatter?

00:00:16.125 --> 00:00:18.114
That we're oversimplifying the problem.

00:00:18.114 --> 00:00:22.379
We're trying a solution that is too simple and won't do the job.

00:00:22.379 --> 00:00:25.539
In machine learning, this is called underfitting.

00:00:25.539 --> 00:00:29.442
And what's the problem with trying to kill a fly with a bazooka?

00:00:29.443 --> 00:00:32.850
It's overly complicated and it will lead to bad solutions and

00:00:32.850 --> 00:00:37.840
extra complexity when we can use a much simpler solution instead.

00:00:37.840 --> 00:00:41.160
In machine learning, this is called overfitting Let's look at how

00:00:41.159 --> 00:00:45.049
overfitting and underfitting can occur in a classification problem.

00:00:45.049 --> 00:00:46.875
Let's say we have the following data,

00:00:46.875 --> 00:00:49.259
and we need to classify it.

00:00:49.259 --> 00:00:52.324
So what is the rule that will do the job here?

00:00:52.325 --> 00:00:54.435
Seems like an easy problem, right?

00:00:54.435 --> 00:00:59.820
The ones in the right are dogs while the ones in the left are anything but dogs.

00:00:59.820 --> 00:01:02.310
Now what if we use the following rule?

00:01:02.310 --> 00:01:04.394
We say that the ones in the right are

00:01:04.394 --> 00:01:08.280
animals and the ones in the left are anything but animals.

00:01:08.280 --> 00:01:10.644
Well, that solution is not too good, right?

00:01:10.644 --> 00:01:11.819
What is the problem?

00:01:11.819 --> 00:01:15.729
It's too simple. It doesn't even get the whole data set right.

00:01:15.730 --> 00:01:21.270
See? It misclassified this cat over here since the cat is an animal.

00:01:21.269 --> 00:01:23.170
This is underfitting.

00:01:23.170 --> 00:01:26.200
It's like trying to kill Godzilla with a flyswatter.

00:01:26.200 --> 00:01:30.174
Sometimes, we'll refer to it as error due to bias.

00:01:30.174 --> 00:01:32.769
Now, what about the following rule?

00:01:32.769 --> 00:01:37.185
We'll say that the ones in the right are dogs that are yellow, orange,

00:01:37.185 --> 00:01:43.900
or grey, and the ones in the left are anything but dogs that are yellow, orange, or grey.

00:01:43.900 --> 00:01:49.285
Well, technically, this is correct as it classifies the data correctly.

00:01:49.284 --> 00:01:51.924
There is a feeling that we went too specific since

00:01:51.924 --> 00:01:55.390
just saying dogs and not dogs would have done the job.

00:01:55.390 --> 00:01:58.087
But this problem is more conceptual, right?

00:01:58.087 --> 00:02:00.605
How can we see the problem here?

00:02:00.605 --> 00:02:05.512
Well, one way to see this is by introducing a testing set.

00:02:05.512 --> 00:02:08.159
If our testing set is this dog over here,

00:02:08.159 --> 00:02:12.805
then we'd imagine that a good classifier would put it on the right with the other dogs.

00:02:12.805 --> 00:02:19.599
But this classifier will put it on the left since the dog is not yellow, orange, or grey.

00:02:19.599 --> 00:02:21.984
So, the problem here, as we said,

00:02:21.985 --> 00:02:25.105
is that the classifier is too specific.

00:02:25.104 --> 00:02:29.519
It will fit the data well but it will fail to generalize.

00:02:29.520 --> 00:02:31.390
This is overfitting.

00:02:31.389 --> 00:02:35.009
It's like trying to kill a fly with a bazooka.

00:02:35.009 --> 00:02:39.264
Sometimes, we'll refer to overfitting as error due to variance.

00:02:39.264 --> 00:02:44.489
The way I like to picture underfitting and overfitting is when studying for an exam.

00:02:44.490 --> 00:02:47.665
Underfitting, it's like not studying enough and failing.

00:02:47.664 --> 00:02:52.179
A good model is like studying well and doing well in the exam.

00:02:52.180 --> 00:02:54.254
Overfitting is like instead of studying,

00:02:54.254 --> 00:02:57.359
we memorize the entire textbook word by word.

00:02:57.360 --> 00:03:00.750
We may be able to regurgitate any questions in the textbook but we won't

00:03:00.750 --> 00:03:05.125
be able to generalize properly and answer the questions in the test.

00:03:05.125 --> 00:03:08.324
But now, let's see how this would look like in neural networks.

00:03:08.324 --> 00:03:10.334
So let's say this data where, again,

00:03:10.335 --> 00:03:14.099
the blue points are labeled positive and the red points are labeled negative.

00:03:14.099 --> 00:03:18.219
And here, we have the three little bears.

00:03:18.219 --> 00:03:22.504
In the middle, we have a good model which fits the data well.

00:03:22.504 --> 00:03:26.424
On the left, we have a model that underfits since it's too simple.

00:03:26.425 --> 00:03:30.788
It tries to fit the data with the line but the data is more complicated than that.

00:03:30.788 --> 00:03:33.270
And on the right, we have a model that overfits since it

00:03:33.270 --> 00:03:36.870
tries to fit the data with an overly complicated curve.

00:03:36.870 --> 00:03:42.465
Notice that the model in the right fits the data really well since it makes no mistakes,

00:03:42.465 --> 00:03:46.344
whereas the one in the middle makes this mistake over here.

00:03:46.344 --> 00:03:50.789
But we can see that the model in the middle will probably generalize better.

00:03:50.789 --> 00:03:54.584
The model in the middle looks at this point as noise

00:03:54.585 --> 00:03:59.564
while the one in the right gets confused by it and tries to feed it too well.

00:03:59.564 --> 00:04:01.859
Now the model in the middle will probably be

00:04:01.860 --> 00:04:05.685
a neural network with a slightly complex architecture like this one.

00:04:05.685 --> 00:04:10.284
The one in the left will probably be an overly simplistic architecture.

00:04:10.284 --> 00:04:12.210
Here, for example, the entire neural network is

00:04:12.210 --> 00:04:15.366
just one preceptors since the model is linear.

00:04:15.366 --> 00:04:17.160
The model in the right is probably

00:04:17.160 --> 00:04:21.790
a highly complex neural network with more layers and weights than we need.

00:04:21.790 --> 00:04:23.250
Now here's the bad news.

00:04:23.250 --> 00:04:27.274
It's really hard to find the right architecture for a neural network.

00:04:27.274 --> 00:04:29.250
We're always going to end either with

00:04:29.250 --> 00:04:32.730
an overly simplistic architecture like the one in

00:04:32.730 --> 00:04:37.110
the left or an overly complicated one like the one in the right.

00:04:37.110 --> 00:04:39.270
Now the question is, what do we do?

00:04:39.269 --> 00:04:43.519
Well, this is like trying to fit in a pair of pants.

00:04:43.519 --> 00:04:45.389
If we can't find our size,

00:04:45.389 --> 00:04:49.435
do we go for bigger pants or smaller pants?

00:04:49.435 --> 00:04:51.540
Well, it seems like it's less bad to go for

00:04:51.540 --> 00:04:53.610
a slightly bigger pants and then try to get

00:04:53.610 --> 00:04:56.918
a belt or something that will make them fit better,

00:04:56.918 --> 00:04:58.574
and that's what we're going to do.

00:04:58.574 --> 00:05:00.509
We'll err on the side of

00:05:00.509 --> 00:05:03.389
an overly complicated models and then we'll

00:05:03.389 --> 00:05:07.000
apply certain techniques to prevent overfitting on it.

